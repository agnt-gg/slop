Directory Structure:
+ examples
  + javascript
    + advanced-examples
      + multi-agent
        - multi-agent.js
      + pdf-bot-with-stream
        + client
          - client.html
        - README.md
        + server
          - server.js
    - README.md
    - slop.js
  + python
    + advanced-examples
      - multi-agent.py
    - README.md
    - requirements.txt
    - slop.py
  + replit
    - index.html
    - index.js
    - README.md
  + streamlit
    - Makefile
    - README.md
    - requirements.txt
    - slop_with_models.py
    + static
      - openapi.yaml
    - streamlit_slop_with_models.py
    - vars.sh.example
  + typescript
    - deno.json
    + docs
      - SCOPE_PERMISSIONS.md
    - local-client.ts
    - local-server.ts
    - README.md
    - slop.ts
- LICENSE
- README.md
- spec.md

File Contents:
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\MULTI-AGENT\MULTI-AGENT.JS
----------------------
import { OpenAI } from "openai";
import express from "express";
import dotenv from "dotenv";

dotenv.config();

const app = express();
app.use(express.json());
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Memory storage
const memory = {};

// ======= SIMPLE AGENT SYSTEM =======

// Router Agent - decides which specialized agent to use
async function routerAgent(query) {
  const completion = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: "You are a router that categorizes queries and selects the best specialized agent to handle them." },
      { role: "user", content: `Classify this query and select ONE agent: "${query}"` }
    ],
    functions: [{
      name: "route_query",
      description: "Route the query to the appropriate agent",
      parameters: {
        type: "object",
        properties: {
          agent: {
            type: "string",
            enum: ["researcher", "creative", "technical", "summarizer"],
            description: "The agent best suited to handle this query"
          },
          reason: {
            type: "string",
            description: "Brief reason for this routing decision"
          }
        },
        required: ["agent", "reason"]
      }
    }],
    function_call: { name: "route_query" }
  });
  
  const args = JSON.parse(completion.choices[0].message.function_call.arguments);
  console.log(`ðŸ”€ Routing to: ${args.agent} (${args.reason})`);
  return args;
}

// Create agent factory
const createAgent = (role, temperature = 0.7) => async (query) => {
  const completion = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: role },
      { role: "user", content: query }
    ],
    temperature
  });
  return completion.choices[0].message.content;
};

// Specialized Agents
const agents = {
  researcher: createAgent("You are a research agent providing factual information with sources.", 0.3),
  creative: createAgent("You are a creative agent generating imaginative content.", 0.9),
  technical: createAgent("You are a technical agent providing precise, detailed explanations.", 0.2),
  summarizer: createAgent("You are a summarization agent that creates concise summaries.", 0.3)
};

// ======= SLOP API IMPLEMENTATION =======

// 1. CHAT endpoint - main entry point
app.post('/chat', async (req, res) => {
  try {
    const { messages, pattern } = req.body;
    const userQuery = messages[0].content;
    let response;

    if (pattern) {
      switch (pattern) {
        case 'sequential':
          // Research â†’ Summarize pattern
          const research = await agents.researcher(userQuery);
          response = await agents.summarizer(research);
          break;

        case 'parallel':
          // Get multiple perspectives simultaneously
          const [researchView, creativeView] = await Promise.all([
            agents.researcher(userQuery),
            agents.creative(userQuery)
          ]);
          response = `Research perspective:\n${researchView}\n\nCreative perspective:\n${creativeView}`;
          break;

        case 'branching':
          // Use router to select best agent
          const route = await routerAgent(userQuery);
          response = await agents[route.agent](userQuery);
          break;

        default:
          // Default to router behavior
          const defaultRoute = await routerAgent(userQuery);
          response = await agents[defaultRoute.agent](userQuery);
      }
    } else {
      // Default to router behavior
      const route = await routerAgent(userQuery);
      response = await agents[route.agent](userQuery);
    }

    // Store in memory
    const sessionId = `session_${Date.now()}`;
    memory[sessionId] = {
      query: userQuery,
      pattern: pattern || 'router',
      response
    };

    res.json({
      message: {
        role: "assistant",
        content: response,
        metadata: {
          session_id: sessionId,
          pattern: pattern || 'router'
        }
      }
    });
  } catch (error) {
    console.error("Error:", error);
    res.status(500).json({ error: error.message });
  }
});

// 2. TOOLS endpoint
app.get('/tools', (req, res) => {
  res.json({
    tools: [
      { id: "researcher", description: "Finds factual information" },
      { id: "creative", description: "Generates imaginative content" },
      { id: "technical", description: "Provides technical explanations" },
      { id: "summarizer", description: "Creates concise summaries" }
    ],
    patterns: [
      { id: "sequential", description: "Research then summarize" },
      { id: "parallel", description: "Multiple perspectives at once" },
      { id: "branching", description: "Route to best agent (default)" }
    ]
  });
});

// 3. MEMORY endpoints
app.post('/memory', (req, res) => {
  const { key, value } = req.body;
  memory[key] = value;
  res.json({ status: 'stored' });
});

app.get('/memory/:key', (req, res) => {
  const { key } = req.params;
  res.json({ value: memory[key] || null });
});

// 4. RESOURCES endpoint
app.get('/resources', (req, res) => {
  res.json({
    patterns: {
      sequential: "Chain agents: Research â†’ Summarize",
      parallel: "Multiple agents work simultaneously",
      branching: "Route to specialized agents"
    },
    examples: {
      sequential: {
        description: "Research a topic and create a summary",
        request: {
          messages: [{ content: "Explain quantum computing" }],
          pattern: "sequential"
        }
      },
      parallel: {
        description: "Get multiple perspectives on a topic",
        request: {
          messages: [{ content: "Benefits of meditation" }],
          pattern: "parallel"
        }
      },
      branching: {
        description: "Route to the most appropriate agent",
        request: {
          messages: [{ content: "How do I write a React component?" }],
          pattern: "branching"
        }
      }
    }
  });
});

// 5. PAY endpoint (simple mock)
app.post('/pay', (req, res) => {
  const { amount } = req.body;
  const txId = `tx_${Date.now()}`;
  memory[txId] = { amount, status: 'completed' };
  res.json({ transaction_id: txId });
});

// Start server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`ðŸ¤– SLOP Multi-Agent API running on port ${PORT}`);
});

/* Example usage:

1. Basic query (uses router):
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [{ "content": "What are black holes?" }]
}'

2. Sequential pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [{ "content": "Explain quantum computing" }],
  "pattern": "sequential"
}'

3. Parallel pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
  "messages": [{ "content": "Benefits of meditation" }],
  "pattern": "parallel"
}'

4. Store in memory:
curl -X POST http://localhost:3000/memory \
-H "Content-Type: application/json" \
-d '{
  "key": "test",
  "value": "hello world"
}'

5. Get from memory:
curl -X GET http://localhost:3000/memory/test

6. List tools:
curl -X GET http://localhost:3000/tools

7. Get resources:
curl -X GET http://localhost:3000/resources

8. Process payment:
curl -X POST http://localhost:3000/pay \
-H "Content-Type: application/json" \
-d '{
  "amount": 10
}'
*/
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\PDF-BOT-WITH-STREAM\CLIENT\CLIENT.HTML
----------------------
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLOP Client</title>
    <!-- Add Showdown library for Markdown to HTML conversion -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/showdown/2.1.0/showdown.min.js"></script>
    
    <!-- Add KaTeX CSS and JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

    <link href="https://fonts.googleapis.com/css2?family=League+Spartan:wght@400;500;600;700&display=swap" rel="stylesheet">

    <style>
        * {
            font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* if SLOPPY mode is enabled use comic sans, else league spartan */
        }
        body {
            font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* if SLOPPY mode is enabled use comic sans, else league spartan */
            line-height: 150%;
            background: var(--color-black-navy, #070710);
            color: var(--color-light-med-navy, #d1d1db);
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            height: 100vh;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        header {
            text-align: center;
            margin-bottom: 30px;
        }
        h1 {
            color: var(--color-blue, #12e0ff);
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
            padding-bottom: 24px;
        }
        .upload-panel {
            background-color: var(--color-dark-navy, #10101f);
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
            border: 1px solid var(--color-navy, #131322);
        }
        .upload-form {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        .upload-form-row {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .upload-btn {
            background-color: var(--color-pink, #e53d8f);
            color: var(--color-white, #f7f8f0);
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .upload-btn:hover {
            background-color: var(--color-blue, #12e0ff);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(18, 224, 255, 0.3);
        }
        .file-counter {
            font-size: var(--font-size-sm, 14px);
            color: var(--color-med-navy, #7f8193);
        }
        .upload-status {
            margin-top: 10px;
            font-size: var(--font-size-sm, 14px);
            color: var(--color-light-med-navy, #d1d1db);
        }
        .resources-panel {
            background-color: var(--color-dark-navy, #10101f);
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
            border: 1px solid var(--color-navy, #131322);
        }
        .resources-list {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            margin-bottom: 10px;
        }
        .resource-btn {
            background-color: var(--color-navy, #131322);
            color: var(--color-light-med-navy, #d1d1db);
            border: 1px solid var(--color-duller-navy, #3e405a);
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            font-size: var(--font-size-sm, 14px);
        }
        .resource-btn:hover {
            background-color: var(--color-blue, #12e0ff);
            color: var(--color-white, #f7f8f0);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(18, 224, 255, 0.3);
        }
        .resource-btn.selected {
            background-color: var(--color-green, #19ef83);
            color: var(--color-dark-navy, #10101f);
            border-color: var(--color-green, #19ef83);
            font-weight: bold;
        }
        .resource-icon {
            margin-right: 5px;
            font-size: 16px;
        }
        .chat-container {
            flex-grow: 1;
            display: flex;
            flex-direction: column;
            border: 1px solid var(--color-navy, #131322);
            border-radius: 8px;
            overflow: hidden;
            background: var(--color-ultra-dark-navy, #0b0b17);
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
        }
        .messages {
            flex-grow: 1;
            padding: 15px;
            overflow-y: auto;
            max-height: calc(100vh - 300px);
        }
        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }
        .user-message {
            background-color: var(--color-navy, #131322);
            color: var(--color-light-med-navy, #d1d1db);
            align-self: flex-end;
            margin-left: 20%;
            border: 1px solid var(--color-blue, #12e0ff);
            border-radius: 16px 16px 4px 16px;
        }
        .assistant-message {
            background-color: var(--color-dark-navy, #10101f);
            color: var(--color-light-med-navy, #d1d1db);
            align-self: flex-start;
            margin-right: 20%;
            border: 1px solid var(--color-duller-navy, #3e405a);
            border-radius: 16px 16px 16px 4px;
        }
        .message pre {
            background-color: var(--color-black-navy, #070710);
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
            border: 1px solid var(--color-navy, #131322);
        }
        .message code {
            font-family: 'Comic Sans MS', 'Comic Sans', cursive; /* if SLOPPY mode is enabled use comic sans, else monospace */
            background-color: var(--color-black-navy, #070710);
            color: var(--color-green, #19ef83);
            padding: 2px 4px;
            border-radius: 3px;
        }
        .input-area {
            display: flex;
            padding: 15px;
            background-color: var(--color-dark-navy, #10101f);
            border-top: 1px solid var(--color-navy, #131322);
            gap: 10px;
        }
        #message-input {
            flex-grow: 1;
            padding: 12px;
            border: 1px solid var(--color-duller-navy, #3e405a);
            border-radius: 4px;
            font-size: var(--font-size-md, 16px);
            transition: all 0.3s ease;
            background-color: var(--color-black-navy, #070710);
            color: var(--color-light-med-navy, #d1d1db);
        }
        #message-input:focus {
            outline: none;
            border-color: var(--color-blue, #12e0ff);
            box-shadow: 0 0 0 2px rgba(18, 224, 255, 0.1);
        }
        #send-btn {
            background-color: var(--color-green, #19ef83);
            color: var(--color-black-navy, #070710);
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }
        #send-btn:hover {
            background-color: var(--color-blue, #12e0ff);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(18, 224, 255, 0.3);
        }
        .controls-panel {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: 10px;
        }
        #streaming-toggle {
            display: flex;
            align-items: center;
            font-size: var(--font-size-sm, 14px);
            gap: 5px;
            color: var(--color-light-med-navy, #d1d1db);
        }
        #streaming-toggle input[type="checkbox"] {
            accent-color: var(--color-green, #19ef83);
        }
        .clear-chat-btn {
            background-color: var(--color-red, #fe4e4e);
            color: var(--color-white, #f7f8f0);
            border: none;
            padding: 5px 10px;
            border-radius: 4px;
            font-size: var(--font-size-sm, 14px);
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .clear-chat-btn:hover {
            background-color: var(--color-pink, #e53d8f);
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(229, 61, 143, 0.3);
        }
        .cursor {
            display: inline-block;
            width: 8px;
            height: 16px;
            background-color: var(--color-blue, #12e0ff);
            animation: blink 1s infinite;
            margin-left: 2px;
        }
        @keyframes blink {
            50% { opacity: 0; }
        }
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid var(--color-navy, #131322);
            border-radius: 50%;
            border-top-color: var(--color-blue, #12e0ff);
            animation: spin 1s ease-in-out infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        .katex-display {
            overflow-x: auto;
            overflow-y: hidden;
            padding: 10px 0;
            color: var(--color-light-med-navy, #d1d1db);
        }
        .katex {
            font-size: 1.1em;
        }
        
        /* Style scrollbar for Webkit browsers */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        ::-webkit-scrollbar-track {
            background: var(--color-black-navy, #070710);
        }
        ::-webkit-scrollbar-thumb {
            background: var(--color-duller-navy, #3e405a);
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: var(--color-blue, #12e0ff);
        }

        #sloppy-toggle {
            display: flex;
            align-items: center;
            font-size: var(--font-size-sm, 14px);
            gap: 5px;
            color: var(--color-light-med-navy, #d1d1db);
            margin-left: 20px;
        }

        #sloppy-toggle input[type="checkbox"] {
            accent-color: var(--color-pink, #e53d8f);
        }

        /* Add CSS variables for fonts */
        :root {
            --font-primary: 'League Spartan', -apple-system, BlinkMacSystemFont, sans-serif;
            --font-code: monospace;
        }

        :root[data-sloppy="true"] {
            --font-primary: 'Comic Sans MS', 'Comic Sans', cursive;
            --font-code: 'Comic Sans MS', 'Comic Sans', cursive;
        }

        /* Update font-family rules to use variables */
        * {
            font-family: var(--font-primary);
        }

        body {
            font-family: var(--font-primary);
            /* ... rest of body styles ... */
        }

        .message code {
            font-family: var(--font-code);
            /* ... rest of code styles ... */
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>SLOP PDF Bot With Streaming ðŸ“„</h1>
            <p>Interactive interface for the Simple Language Open Protocol</p>
        </header>

        <div class="upload-panel">
            <h3>Upload Documents</h3>
            <p>Upload PDFs, DOCXs, TXT, MD files, images, and more to chat with their content</p>
            <div class="upload-form">
                <div class="upload-form-row">
                    <input type="file" id="file-input" multiple accept=".pdf,.txt,.md,.docx,.csv,.html,.js,.png,.jpg,.jpeg,.gif,.webp" />
                    <span id="file-counter" class="file-counter">No files selected</span>
                    <button id="upload-btn" class="upload-btn">Upload</button>
                </div>
                <div id="upload-status" class="upload-status"></div>
            </div>
        </div>

        <div class="resources-panel">
            <h3>Available Resources</h3>
            <div class="resources-list" id="resources-list">
                <div class="loading"></div>
            </div>
            <div class="controls-panel">
                <div id="streaming-toggle">
                    <input type="checkbox" id="use-streaming" checked>
                    <label for="use-streaming">Use streaming responses</label>
                </div>
                <div id="sloppy-toggle">
                    <input type="checkbox" id="use-sloppy">
                    <label for="use-sloppy">SLOPPY Mode</label>
                </div>
                <button id="clear-chat-btn" class="clear-chat-btn">Clear Chat</button>
            </div>
        </div>

        <div class="chat-container">
            <div class="messages" id="messages">
                <div class="message assistant-message">
                    <p>Hello! I'm your SLOP assistant. How can I help you today? Upload documents and I can answer questions about them!</p>
                </div>
            </div>
            <div class="input-area">
                <input type="text" id="message-input" placeholder="Type your message here...">
                <button id="send-btn">Send</button>
            </div>
        </div>
    </div>

    <script>
        // Initialize Showdown converter for Markdown to HTML
        const converter = new showdown.Converter({
            tables: true,
            simplifiedAutoLink: true,
            strikethrough: true,
            tasklists: true,
            ghCodeBlocks: true,
            // Add custom LaTeX delimiter handling
            extensions: [{
                type: 'lang',
                regex: /\\\((.*?)\\\)/g,
                replace: (_, match) => `<span class="inline-latex">${match}</span>`
            }, {
                type: 'lang',
                regex: /\\\[(.*?)\\\]/g,
                replace: (_, match) => `<div class="display-latex">${match}</div>`
            }]
        });

        // Add function to render LaTeX in an element
        function renderLatex(element) {
            // Find all LaTeX elements
            const inlineElements = element.getElementsByClassName('inline-latex');
            const displayElements = element.getElementsByClassName('display-latex');
            
            // Render inline LaTeX
            Array.from(inlineElements).forEach(el => {
                try {
                    katex.render(el.textContent, el, {
                        displayMode: false,
                        throwOnError: false
                    });
                } catch (error) {
                    console.error('LaTeX rendering error:', error);
                    el.textContent = `[LaTeX Error: ${error.message}]`;
                }
            });
            
            // Render display LaTeX
            Array.from(displayElements).forEach(el => {
                try {
                    katex.render(el.textContent, el, {
                        displayMode: true,
                        throwOnError: false
                    });
                } catch (error) {
                    console.error('LaTeX rendering error:', error);
                    el.textContent = `[LaTeX Error: ${error.message}]`;
                }
            });
        }

        // Base URL for API
        const API_BASE_URL = 'http://localhost:3000';
        let serverConnected = false;

        // Track currently selected resource
        let selectedResourceId = null;
        
        // Show connection status
        const checkServerConnection = async () => {
            try {
                const response = await fetch(`${API_BASE_URL}/resources`, { method: 'GET' });
                if (response.ok) {
                    serverConnected = true;
                    document.querySelector('header p').textContent = 'Connected to SLOP server';
                    document.querySelector('header p').style.color = 'green';
                    return true;
                }
                return false;
            } catch (error) {
                serverConnected = false;
                document.querySelector('header p').textContent = 'Server disconnected - please start the server';
                document.querySelector('header p').style.color = 'red';
                return false;
            }
        };
        
        // Get file icon based on MIME type
        const getFileIcon = (fileType) => {
            if (!fileType) return 'ðŸ“„';
            
            if (fileType.startsWith('image/')) return 'ðŸ–¼ï¸';
            
            switch (fileType) {
                case 'application/pdf':
                    return 'ðŸ“•';
                case 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
                    return 'ðŸ“';
                case 'text/plain':
                    return 'ðŸ“„';
                case 'text/markdown':
                    return 'ðŸ“‘';
                case 'text/csv':
                    return 'ðŸ“Š';
                case 'text/html':
                    return 'ðŸŒ';
                case 'text/javascript':
                    return 'ðŸ“œ';
                default:
                    return 'ðŸ“„';
            }
        };
        
        // Handle file input change
        const fileInput = document.getElementById('file-input');
        const fileCounter = document.getElementById('file-counter');
        
        fileInput.addEventListener('change', () => {
            const fileCount = fileInput.files.length;
            if (fileCount === 0) {
                fileCounter.textContent = 'No files selected';
            } else if (fileCount === 1) {
                fileCounter.textContent = '1 file selected';
            } else {
                fileCounter.textContent = `${fileCount} files selected`;
            }
        });
        
        // Handle file upload
        const uploadBtn = document.getElementById('upload-btn');
        const uploadStatus = document.getElementById('upload-status');
        
        uploadBtn.addEventListener('click', async () => {
            if (!serverConnected) {
                await checkServerConnection();
                if (!serverConnected) {
                    alert('Cannot upload: Server is not connected. Please start the server.');
                    return;
                }
            }
            
            const files = fileInput.files;
            if (files.length === 0) {
                uploadStatus.textContent = 'Please select at least one file to upload.';
                uploadStatus.style.color = 'red';
                return;
            }
            
            // Show loading state
            uploadStatus.textContent = `Uploading ${files.length} file(s)...`;
            uploadStatus.style.color = 'blue';
            
            const formData = new FormData();
            for (const file of files) {
                formData.append('files', file);
            }
            
            try {
                const response = await fetch(`${API_BASE_URL}/resources/upload`, {
                    method: 'POST',
                    body: formData
                });
                
                const data = await response.json();
                
                if (response.ok) {
                    uploadStatus.textContent = `Successfully uploaded ${data.resources.length} file(s)`;
                    uploadStatus.style.color = 'green';
                    
                    // Clear file input
                    fileInput.value = '';
                    fileCounter.textContent = 'No files selected';
                    
                    // Refresh resources list
                    await loadResources();
                    
                    // Select the first resource if available
                    if (data.resources.length > 0) {
                        selectedResourceId = data.resources[0].id;
                        
                        // Add a system message about the upload
                        const messageElement = document.createElement('div');
                        messageElement.classList.add('message', 'assistant-message');
                        
                        if (data.resources.length === 1) {
                            messageElement.innerHTML = `<p>I've loaded <strong>${data.resources[0].title}</strong>. You can now ask me questions about it!</p>`;
                        } else {
                            const fileNames = data.resources.map(r => r.title).join(', ');
                            messageElement.innerHTML = `<p>I've loaded ${data.resources.length} files: <strong>${fileNames}</strong>. The first file is selected. You can now ask me questions about it!</p>`;
                        }
                        
                        document.getElementById('messages').appendChild(messageElement);
                        document.getElementById('messages').scrollTop = document.getElementById('messages').scrollHeight;
                    }
                } else {
                    uploadStatus.textContent = `Error: ${data.error || 'Unknown error'}`;
                    uploadStatus.style.color = 'red';
                }
            } catch (error) {
                console.error('Error uploading files:', error);
                uploadStatus.textContent = 'Error uploading files. Please try again.';
                uploadStatus.style.color = 'red';
            }
        });
        
        // Function to load resources
        const loadResources = async () => {
            if (!await checkServerConnection()) {
                document.getElementById('resources-list').innerHTML = '<p>Server not connected</p>';
                return;
            }
            
            try {
                const response = await fetch(`${API_BASE_URL}/resources`);
                const data = await response.json();
                
                // Display resources as clickable buttons
                const resourcesList = document.getElementById('resources-list');
                resourcesList.innerHTML = '';
                
                data.resources.forEach(resource => {
                    const button = document.createElement('button');
                    button.classList.add('resource-btn');
                    
                    // Add icon based on file type
                    const icon = document.createElement('span');
                    icon.classList.add('resource-icon');
                    icon.textContent = getFileIcon(resource.fileType);
                    button.appendChild(icon);
                    
                    // Add resource title
                    const titleSpan = document.createElement('span');
                    titleSpan.textContent = resource.title;
                    button.appendChild(titleSpan);
                    
                    button.dataset.id = resource.id;
                    
                    // If this is the currently selected resource, mark it as selected
                    if (selectedResourceId === resource.id) {
                        button.classList.add('selected');
                    }
                    
                    button.addEventListener('click', () => {
                        // Toggle selection
                        if (selectedResourceId === resource.id) {
                            selectedResourceId = null;
                            button.classList.remove('selected');
                        } else {
                            // Deselect any previously selected button
                            document.querySelectorAll('.resource-btn.selected').forEach(btn => {
                                btn.classList.remove('selected');
                            });
                            
                            selectedResourceId = resource.id;
                            button.classList.add('selected');
                            
                            // Add a message indicating the selection
                            const messageElement = document.createElement('div');
                            messageElement.classList.add('message', 'assistant-message');
                            messageElement.innerHTML = `<p>You've selected <strong>${resource.title}</strong>. What would you like to know about it?</p>`;
                            document.getElementById('messages').appendChild(messageElement);
                            
                            // Scroll to bottom
                            document.getElementById('messages').scrollTop = document.getElementById('messages').scrollHeight;
                        }
                    });
                    
                    resourcesList.appendChild(button);
                });
                
                if (data.resources.length === 0) {
                    resourcesList.innerHTML = '<p>No resources available</p>';
                }
            } catch (error) {
                console.error('Error fetching resources:', error);
                document.getElementById('resources-list').innerHTML = '<p>Error loading resources</p>';
            }
        };
        
        // Handle clear chat button
        const clearChatBtn = document.getElementById('clear-chat-btn');
        clearChatBtn.addEventListener('click', () => {
            // Clear all messages except the welcome message
            const messagesContainer = document.getElementById('messages');
            messagesContainer.innerHTML = '';
            
            // Add welcome message
            const welcomeMessage = document.createElement('div');
            welcomeMessage.classList.add('message', 'assistant-message');
            welcomeMessage.innerHTML = '<p>Chat history cleared. How can I help you today?</p>';
            messagesContainer.appendChild(welcomeMessage);
        });
        
        // Fetch available resources when page loads
        document.addEventListener('DOMContentLoaded', loadResources);
        
        // Set up message sending
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-btn');
        const messagesContainer = document.getElementById('messages');
        const streamingToggle = document.getElementById('use-streaming');
        
        const sendMessage = async () => {
            if (!serverConnected) {
                await checkServerConnection();
                if (!serverConnected) {
                    alert('Cannot send message: Server is not connected. Please start the server.');
                    return;
                }
            }

            const messageContent = messageInput.value.trim();
            if (!messageContent) return;
            
            // Add user message to UI
            const userMessageElement = document.createElement('div');
            userMessageElement.classList.add('message', 'user-message');
            userMessageElement.innerHTML = `<p>${messageContent}</p>`;
            messagesContainer.appendChild(userMessageElement);
            
            // Clear input
            messageInput.value = '';
            
            // Add loading indicator for assistant response
            const loadingElement = document.createElement('div');
            loadingElement.classList.add('message', 'assistant-message');
            loadingElement.innerHTML = '<div class="loading"></div>';
            messagesContainer.appendChild(loadingElement);
            
            // Scroll to bottom
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
            
            // Check if streaming is enabled
            const useStreaming = streamingToggle.checked;
            
            if (useStreaming) {
                // Use streaming endpoint
                await streamingChat(messageContent, loadingElement);
            } else {
                // Use regular chat endpoint
                await regularChat(messageContent, loadingElement);
            }
        };
        
        // Regular chat function (non-streaming)
        const regularChat = async (messageContent, loadingElement) => {
            try {
                // Send request to SLOP server
                const payload = {
                    messages: [{ role: 'user', content: messageContent }]
                };
                
                // Include resource_id if a resource is selected
                if (selectedResourceId) {
                    payload.resource_id = selectedResourceId;
                }
                
                const response = await fetch(`${API_BASE_URL}/chat`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(payload)
                });
                
                const data = await response.json();
                
                // Convert Markdown to HTML using Showdown
                const htmlContent = converter.makeHtml(data.message.content);
                
                // Update the loading element with the response
                loadingElement.innerHTML = htmlContent;
                
                // Render any LaTeX in the response
                renderLatex(loadingElement);
                
                // Scroll to bottom
                messagesContainer.scrollTop = messagesContainer.scrollHeight;
            } catch (error) {
                console.error('Error sending message:', error);
                loadingElement.innerHTML = '<p>Error: Failed to get a response. Please try again.</p>';
            }
        };
        
        // Streaming chat function
        const streamingChat = async (messageContent, loadingElement) => {
            try {
                // Prepare for streaming response
                loadingElement.innerHTML = '<div class="streaming-response"></div><div class="cursor"></div>';
                const streamingResponseElement = loadingElement.querySelector('.streaming-response');
                
                // Create payload
                const payload = {
                    messages: [{ role: 'user', content: messageContent }]
                };
                
                // Include resource_id if a resource is selected
                if (selectedResourceId) {
                    payload.resource_id = selectedResourceId;
                }
                
                let accumulatedMarkdown = '';

                // Create an AbortController to handle timeouts and manual aborts
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), 30000); // 30-second timeout
                
                // Use fetch with streaming response handling
                try {
                    const response = await fetch(`${API_BASE_URL}/chat/stream`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(payload),
                        signal: controller.signal
                    });
                    
                    // Clear the timeout since we got a response
                    clearTimeout(timeoutId);
                    
                    // Check for successful response
                    if (!response.ok) {
                        throw new Error(`Server returned ${response.status}: ${response.statusText}`);
                    }
                    
                    // Set up reader for the response stream
                    const reader = response.body.getReader();
                    const decoder = new TextDecoder('utf-8');
                    
                    // Define a function to process the data chunks
                    const processStream = async () => {
                        while (true) {
                            const { done, value } = await reader.read();
                            
                            if (done) {
                                // Remove cursor when we're done
                                const cursor = loadingElement.querySelector('.cursor');
                                if (cursor) cursor.remove();
                                break;
                            }
                            
                            // Decode the chunk
                            const chunk = decoder.decode(value, { stream: true });
                            
                            // Process the SSE data format (data: {...}\n\n)
                            const lines = chunk.split('\n\n');
                            
                            for (const line of lines) {
                                if (line.trim() === '') continue;
                                
                                // Extract JSON from the line (remove 'data: ' prefix)
                                const jsonStr = line.replace(/^data: /, '').trim();
                                if (!jsonStr) continue;
                                
                                try {
                                    const data = JSON.parse(jsonStr);
                                    
                                    switch (data.event) {
                                        case 'start':
                                            console.log('Streaming started');
                                            break;
                                            
                                        case 'content':
                                            // Append new content
                                            accumulatedMarkdown += data.content;
                                            // Convert to HTML and update the UI
                                            const htmlContent = converter.makeHtml(accumulatedMarkdown);
                                            streamingResponseElement.innerHTML = htmlContent;
                                            // Render any LaTeX in the response
                                            renderLatex(streamingResponseElement);
                                            // Scroll to bottom
                                            messagesContainer.scrollTop = messagesContainer.scrollHeight;
                                            break;
                                            
                                        case 'end':
                                            console.log('Streaming ended');
                                            // Remove cursor now that we're done
                                            const cursor = loadingElement.querySelector('.cursor');
                                            if (cursor) cursor.remove();
                                            break;
                                            
                                        case 'error':
                                            console.error('Streaming error:', data.error);
                                            loadingElement.innerHTML = `<p>Error: ${data.error}</p>`;
                                            return;
                                    }
                                } catch (err) {
                                    console.error('Error parsing SSE data:', err, jsonStr);
                                }
                            }
                        }
                    };
                    
                    // Start processing the stream
                    await processStream();
                    
                } catch (fetchError) {
                    console.error('Fetch error:', fetchError);
                    loadingElement.innerHTML = `<p>Error: ${fetchError.message}</p>`;
                    
                    // Clean up the timeout if needed
                    clearTimeout(timeoutId);
                }
                
            } catch (error) {
                console.error('Error in streaming chat:', error);
                loadingElement.innerHTML = '<p>Error: Failed to start streaming. Please try again.</p>';
            }
        };
        
        // Handle send button click
        sendButton.addEventListener('click', sendMessage);
        
        // Handle Enter key press
        messageInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });

        // Handle SLOPPY Mode toggle
        const sloppyToggle = document.getElementById('use-sloppy');
        sloppyToggle.addEventListener('change', (e) => {
            document.documentElement.setAttribute('data-sloppy', e.target.checked);
            
            // Add a fun message when toggling
            const messageElement = document.createElement('div');
            messageElement.classList.add('message', 'assistant-message');
            if (e.target.checked) {
                messageElement.innerHTML = "<p>ðŸŽ¨ SLOPPY Mode activated! Everything is more fun in Comic Sans!</p>";
            } else {
                messageElement.innerHTML = "<p>ðŸŽ¯ Back to professional mode with League Spartan.</p>";
            }
            messagesContainer.appendChild(messageElement);
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        });
    </script>
</body>
</html>
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\PDF-BOT-WITH-STREAM\README.MD
----------------------
# ðŸš€ SLOP: Advanced Streaming AI Chat Platform
> A sophisticated, resource-aware AI chat interface with dynamic memory management and intelligent document handling

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![OpenAI](https://img.shields.io/badge/AI-OpenAI%20GPT-brightgreen)
![Streaming](https://img.shields.io/badge/Streaming-SSE-orange)
![Memory](https://img.shields.io/badge/Memory-Dynamic-purple)

<div align="center">
  <img src="https://github.com/agnt-gg/slop/blob/main/examples/javascript/advanced-examples/pdf-bot-with-stream/screenshot.PNG?raw=true" alt="SLOP PDF Bot Interface" width="100%"/>
  <p><em>SLOP PDF Bot with Dynamic Resource Management and Real-time Streaming</em></p>
</div>

## ðŸ› ï¸ Quick Installation

### Prerequisites
- Node.js >= 16.0.0
- NPM or Yarn
- OpenAI API key

### Installation Steps

1. **Clone and Install Dependencies**
```bash
# Clone the repository (or download)
git clone https://github.com/agnt-gg/slop
cd examples/javascript/pdf-bot-with-stream

# Install server dependencies
cd server
npm install

# Optional: If you need DOCX support
npm install mammoth

# Create environment file
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

2. **Start the Server**
```bash
npm start
# Server will start on http://localhost:3000
```

3. **Access the Client**
- Open your browser to `http://localhost:3000/client`
- Or serve the client folder separately using any static file server

### Dependencies Overview

#### Server Dependencies
```json
{
  "dependencies": {
    "crypto-js": "^4.2.0",
    "dotenv": "^16.4.7",
    "express": "^4.18.2",
    "multer": "^1.4.5-lts.1",
    "openai": "^4.86.2",
    "pdfreader": "^3.0.7"
  },
  "optionalDependencies": {
    "mammoth": "^1.9.0"
  }
}
```

#### Client Dependencies (CDN)
- Showdown (Markdown parsing)
- KaTeX (LaTeX rendering)
- League Spartan font

### Environment Variables
```env
OPENAI_API_KEY=your_api_key_here
PORT=3000 # Optional, defaults to 3000
```

### Docker Support (Optional)
```bash
# Build the image
docker build -t slop-pdf-bot .

# Run the container
docker run -p 3000:3000 -e OPENAI_API_KEY=your_key_here slop-pdf-bot
```

---

## âœ¨ SLOP Bot Features

- Modern User Interface
- SLOP Schema Compatible
- Real-time Streaming
- Rich Markdown Support
- LaTeX Math Integration
- Dynamic File Management
- Chat Interface
- Controls & Settings

---

## ðŸ”§ Configuration

### Server Configuration
- Maximum file size: 50MB
- Cache size: 100 items
- Cache cleanup interval: 1 hour
- Supported file types: PDF, DOCX, TXT, MD, CSV, HTML, JS, Images

### Client Configuration
- Streaming toggle
- Resource selection
- Chat history management
- LaTeX rendering options

## ðŸŒŸ Key Endpoints

- `/chat` - Main chat endpoint
- `/chat/stream` - Streaming chat endpoint
- `/resources` - Resource management
- `/resources/upload` - File upload endpoint
- `/memory` - Conversation memory management
- `/tools` - Tool integration (extensible)
- `/pay` - Payment integration (placeholder)

## ðŸ’¡ Usage Examples

### Upload and Query Documents
```javascript
// Upload a PDF
const formData = new FormData();
formData.append('files', pdfFile);
await fetch('/resources/upload', { method: 'POST', body: formData });

// Chat about the document
const response = await fetch('/chat', {
  method: 'POST',
  body: JSON.stringify({
    messages: [{ role: 'user', content: 'Summarize the PDF' }],
    resource_id: 'resource_123'
  })
});
```

### LaTeX Math Support
```markdown
Inline math: \(E = mc^2\)
Display math: \[\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}\]
```

## ðŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.

## ðŸ“œ License

MIT License - feel free to use this in your own projects!

## ðŸ™ Acknowledgments

- OpenAI for the GPT API
- KaTeX for LaTeX rendering
- Showdown for Markdown processing
- Express.js team
- PDF and DOCX processing libraries

---

## ðŸŒ API Endpoints

### Chat Endpoints

#### POST `/chat`
Regular chat endpoint for non-streaming responses.

```javascript
// Request
{
  "messages": [{ "role": "user", "content": "Analyze this document" }],
  "resource_id": "resource_123",  // Optional
  "use_tools": true,             // Optional
  "conversation_id": "conv_456"   // Optional
}

// Response
{
  "message": {
    "role": "assistant",
    "content": "Analysis response..."
  },
  "available_resources": ["resource_123", "resource_456"],
  "tools_available": true,
  "conversation_id": "conv_456",
  "message_count": 5
}
```

#### POST `/chat/stream`
Streaming chat endpoint using Server-Sent Events (SSE).

```javascript
// Request (same format as /chat)
{
  "messages": [{ "role": "user", "content": "Analyze this document" }],
  "resource_id": "resource_123",
  "use_tools": true,
  "conversation_id": "conv_456"
}

// SSE Response Events
data: {"event": "start"}
data: {"event": "content", "content": "Analysis"}
data: {"event": "content", "content": " in progress..."}
data: {"event": "end", "conversation_id": "conv_456", "message_count": 6}
```

### Resource Management

#### GET `/resources`
List all available resources.

```javascript
// Response
{
  "resources": [
    {
      "id": "resource_123",
      "title": "Annual Report.pdf",
      "fileType": "application/pdf",
      "fileSize": 1048576,
      "uploadedAt": "2024-03-15T12:00:00Z"
    }
  ]
}
```

#### GET `/resources/:id`
Get specific resource details.

```javascript
// Response
{
  "id": "resource_123",
  "title": "Annual Report.pdf",
  "content": "Document content...",
  "fileType": "application/pdf",
  "fileSize": 1048576,
  "uploadedAt": "2024-03-15T12:00:00Z"
}
```

#### POST `/resources/upload`
Upload multiple files (up to 5 files, 50MB each).

```javascript
// Multipart form data
files: [File1, File2, ...]

// Response
{
  "success": true,
  "resources": [
    {
      "id": "resource_789",
      "title": "New Document.pdf",
      "fileType": "application/pdf",
      "fileSize": 1048576,
      "uploadedAt": "2024-03-15T12:00:00Z"
    }
  ],
  "message": "2 file(s) uploaded and resources created successfully"
}
```

### Memory Management

#### POST `/memory`
Manage conversation memory.

```javascript
// Request - Clear memory
{
  "conversation_id": "conv_456",
  "operation": "clear"
}

// Request - Get memory
{
  "conversation_id": "conv_456",
  "operation": "get"
}

// Response
{
  "status": "cleared",
  "conversation_id": "conv_456"
}
```

#### GET `/debug/conversations/:id?`
Debug endpoint for conversation inspection.

```javascript
// Response (specific conversation)
{
  "conversation_id": "conv_456",
  "messages": [
    { "role": "user", "content": "Hello" },
    { "role": "assistant", "content": "Hi there!" }
  ]
}

// Response (all conversations)
{
  "conversation_count": 2,
  "conversation_ids": ["conv_456", "conv_789"]
}
```

## ðŸ’¡ Usage Examples

### Complete Chat Flow

```javascript
// 1. Upload documents
const formData = new FormData();
formData.append('files', pdfFile);
formData.append('files', docxFile);

const uploadResponse = await fetch('/resources/upload', {
  method: 'POST',
  body: formData
});
const { resources } = await uploadResponse.json();

// 2. Regular chat about documents
const chatResponse = await fetch('/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    messages: [{ 
      role: 'user', 
      content: 'Compare these documents and summarize key differences' 
    }],
    resource_id: resources[0].id
  })
});
const { message } = await chatResponse.json();
```

### Streaming Chat with Error Handling

```javascript
const streamChat = async (message) => {
  const response = await fetch('/chat/stream', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      messages: [{ role: 'user', content: message }],
      use_tools: true
    })
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const chunk = decoder.decode(value);
      const events = chunk.split('\n\n');
      
      for (const event of events) {
        if (!event.trim()) continue;
        const data = JSON.parse(event.replace('data: ', ''));
        
        switch (data.event) {
          case 'start':
            console.log('Stream started');
            break;
          case 'content':
            updateUI(data.content);
            break;
          case 'end':
            console.log('Stream ended');
            break;
          case 'error':
            handleError(data.error);
            break;
        }
      }
    }
  } catch (error) {
    console.error('Stream error:', error);
  }
};
```

### Resource Management

```javascript
// List all resources
const resources = await fetch('/resources').then(r => r.json());

// Get specific resource
const resource = await fetch('/resources/resource_123').then(r => r.json());

// Clear conversation memory
await fetch('/memory', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    conversation_id: 'conv_456',
    operation: 'clear'
  })
});
```

### Advanced File Upload with Progress

```javascript
const uploadWithProgress = async (files) => {
  const formData = new FormData();
  Array.from(files).forEach(file => {
    formData.append('files', file);
  });

  const xhr = new XMLHttpRequest();
  xhr.upload.onprogress = (event) => {
    const percent = (event.loaded / event.total) * 100;
    updateProgressBar(percent);
  };

  return new Promise((resolve, reject) => {
    xhr.onload = () => resolve(JSON.parse(xhr.response));
    xhr.onerror = () => reject(xhr.statusText);
    xhr.open('POST', '/resources/upload');
    xhr.send(formData);
  });
};
```

## ðŸ”§ Configuration Options

```javascript
// Server configuration
const config = {
  MAX_FILE_SIZE: 50 * 1024 * 1024,  // 50MB
  MAX_FILES: 5,
  CACHE_SIZE: 100,
  CACHE_CLEANUP_INTERVAL: 60 * 60 * 1000,  // 1 hour
  SUPPORTED_MIME_TYPES: [
    'application/pdf',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'text/plain',
    'text/markdown',
    'text/csv',
    'text/html',
    'text/javascript',
    'image/jpeg',
    'image/png',
    'image/gif',
    'image/webp'
  ]
};
```

## ðŸ” Debugging

```javascript
// Get all conversations
const debug = await fetch('/debug/conversations').then(r => r.json());

// Inspect specific conversation
const conv = await fetch('/debug/conversations/conv_456').then(r => r.json());
```

## ðŸš¨ Error Handling

The API uses standard HTTP status codes:
- 200: Success
- 400: Bad Request
- 401: Unauthorized
- 404: Not Found
- 413: Payload Too Large
- 500: Server Error

Error responses include detailed messages:
```javascript
{
  "error": "File size exceeds maximum limit of 50MB",
  "code": "FILE_TOO_LARGE"
}
```
Built with ðŸ”¥ passion and â˜• coffee by SLOPPY developers who love clean code
----------------------
EXAMPLES\JAVASCRIPT\ADVANCED-EXAMPLES\PDF-BOT-WITH-STREAM\SERVER\SERVER.JS
----------------------
import express from 'express';
import dotenv from 'dotenv';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import multer from 'multer';
import { fileURLToPath } from 'url';
import crypto from 'crypto';
import mammoth from 'mammoth';
import { PdfReader } from 'pdfreader';

// Get current directory
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config();

const app = express();
app.use(express.json());

// Simple file content cache
const fileContentCache = {};

// Add these near the top where other cache declarations are
const fileHashCache = new Map(); // Cache for file hashes
const pdfTextCache = new Map();  // Cache for extracted PDF text
const MAX_CACHE_SIZE = 100;      // Maximum number of items to keep in cache

// Configure multer for file uploads
const uploadsDir = path.join(__dirname, 'uploads');
if (!fs.existsSync(uploadsDir)) {
  fs.mkdirSync(uploadsDir, { recursive: true });
}

const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, uploadsDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    const ext = path.extname(file.originalname);
    cb(null, file.fieldname + '-' + uniqueSuffix + ext);
  }
});

const upload = multer({ 
  storage,
  fileFilter: (req, file, cb) => {
    // Accept more file types
    const allowedTypes = [
      'application/pdf', 
      'text/plain', 
      'text/markdown',
      'text/csv',
      'text/html',
      'text/javascript',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document', // docx
      'application/octet-stream',
      'image/jpeg',
      'image/png',
      'image/gif',
      'image/webp'
    ];
    
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error(`Unsupported file type: ${file.mimetype}`), false);
    }
  },
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB max file size
  }
});

// Helper to compute file hash for caching
function computeFileHash(buffer) {
  return crypto.createHash('md5').update(buffer).digest('hex');
}

// Helper to trim text to a word limit
function trimToWordLimit(text, wordLimit) {
  const words = text.split(/\s+/);
  if (words.length <= wordLimit) return text;
  return words.slice(0, wordLimit).join(' ') + '... [Content truncated due to length]';
}

// Add this function to manage cache size
function trimCache(cache) {
  if (cache.size > MAX_CACHE_SIZE) {
    const keysIterator = cache.keys();
    const deleteCount = cache.size - MAX_CACHE_SIZE;
    for (let i = 0; i < deleteCount; i++) {
      cache.delete(keysIterator.next().value);
    }
  }
}

// Update the extractTextFromFile function
async function extractTextFromFile(file) {
  const { originalname, path: filePath, mimetype, size } = file;
  const fileBuffer = fs.readFileSync(filePath);
  
  // Generate hash once and cache it
  let fileHash = fileHashCache.get(filePath);
  if (!fileHash) {
    fileHash = computeFileHash(fileBuffer);
    fileHashCache.set(filePath, fileHash);
    trimCache(fileHashCache);
  }
  
  // Check PDF cache first
  if (pdfTextCache.has(fileHash)) {
    console.log(`Using cached PDF content for ${originalname}`);
    return pdfTextCache.get(fileHash);
  }
  
  let extractedText = '';
  
  try {
    if (mimetype.startsWith('image/')) {
      extractedText = `[This is an image file: ${originalname}]`;
    } else {
      switch (mimetype) {
        case 'application/pdf':
          try {
            // First check if we have it in cache
            if (pdfTextCache.has(fileHash)) {
              extractedText = pdfTextCache.get(fileHash);
              console.log(`PDF cache hit for ${originalname}`);
            } else {
              console.log(`PDF cache miss for ${originalname}, extracting text...`);
              extractedText = await getRawTextFromPDFBuffer(fileBuffer);
              
              // Cache the extracted text with size limit (e.g., 1MB)
              if (extractedText.length < 1024 * 1024) {
                pdfTextCache.set(fileHash, extractedText);
                trimCache(pdfTextCache);
                console.log(`Cached PDF content for ${originalname}`);
              }
            }
          } catch (pdfError) {
            console.error(`Error extracting text from PDF ${originalname}:`, pdfError);
            extractedText = `[Error extracting text from PDF: ${originalname}]`;
          }
          break;
          
        case 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
          try {
            extractedText = await getRawTextFromDocxBuffer(fileBuffer);
          } catch (docxError) {
            console.error(`Error extracting text from DOCX ${originalname}:`, docxError);
            extractedText = `[Error extracting text from DOCX: ${originalname}]`;
          }
          break;
          
        case 'text/plain':
        case 'text/csv':
        case 'text/html':
        case 'text/javascript':
        case 'text/markdown':
        case 'application/octet-stream':
          extractedText = fileBuffer.toString('utf-8');
          break;
          
        default:
          extractedText = `[Unsupported file type: ${mimetype}]`;
      }
    }
    
    return extractedText;
    
  } catch (error) {
    console.error(`Error extracting text from ${originalname}:`, error);
    return `[Error extracting text from file: ${originalname}]`;
  } finally {
    // Clean up the file from disk after processing
    try {
      fs.unlinkSync(filePath);
      console.log(`Cleaned up temporary file: ${filePath}`);
    } catch (cleanupError) {
      console.error(`Error cleaning up file ${filePath}:`, cleanupError);
    }
  }
}

// Add these utility functions right after the imports and before the app setup
async function getRawTextFromPDFBuffer(pdfBuffer) {
  try {
    return new Promise((resolve, reject) => {
      let textContent = '';
      new PdfReader().parseBuffer(pdfBuffer, (err, item) => {
        if (err) {
          reject(err);
        } else if (item && item.text) {
          textContent += item.text + ' ';
        } else if (!item) {
          // End of PDF file
          resolve(textContent);
        }
      });
    });
  } catch (error) {
    console.error('Error reading PDF file:', error);
    throw error;
  }
}

async function getRawTextFromDocxBuffer(docxBuffer) {
  try {
    const result = await mammoth.extractRawText({ buffer: docxBuffer });
    return result.value;
  } catch (error) {
    console.error('Error reading docx file:', error);
    throw error;
  }
}

// Add this function near the top with other utility functions
async function shouldIncludeResource(message, resourceId) {
  if (!resourceId || !resources[resourceId]) return false;
  
  const resourceCheckPrompt = `Given the user's message: "${message}"
and the fact that they have selected a document titled "${resources[resourceId].title}",
determine if the message is likely asking about or referring to the document's content.
Reply with just "true" or "false".

Example "true" cases:
- "What does the document say about X?"
- "Summarize this"
- "Can you explain the part about X?"
- "What's mentioned in the file?"

Example "false" cases:
- "How are you?"
- "What's the weather like?"
- "Tell me a joke"
- General questions not related to documents`;

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini", // You might want to use a smaller/faster model here
      messages: [
        { role: "system", content: "You are a classifier that responds with only 'true' or 'false'." },
        { role: "user", content: resourceCheckPrompt }
      ],
      temperature: 0.1, // Low temperature for more consistent results
      max_tokens: 10
    });

    const response = completion.choices[0]?.message?.content.toLowerCase().trim();
    return response === 'true';
  } catch (error) {
    console.error('Error in resource check:', error);
    return true; // Default to including resource if check fails
  }
}

// Enable CORS for all routes
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept');
  res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
  if (req.method === 'OPTIONS') {
    return res.sendStatus(200);
  }
  next();
});

// Setup OpenAI
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Read slop.txt for resource_1
let slopContent = "This is an example resource doc for SLOP. The SLOP spec defines 5 endpoints: /chat, /tools, /memory, /resources, and /pay.";
try {
  const slopPath = path.join(process.cwd(), 'slop.txt');
  if (fs.existsSync(slopPath)) {
    slopContent = fs.readFileSync(slopPath, 'utf8');
    console.log('Successfully loaded slop.txt content for resource_1');
  } else {
    console.log('slop.txt not found, using default content for resource_1');
  }
} catch (error) {
  console.error('Error reading slop.txt:', error);
}

// Simple in-memory "resources" store
const resources = {
  "resource_1": {
    id: "resource_1",
    title: "Simple SLOP Reference",
    content: slopContent
  }
};

// Simple in-memory conversation store
const conversations = {};
let lastConversationId = null; // Track the most recent conversation

// GET /resources - Return all available resources
app.get('/resources', (req, res) => {
  res.json({ resources: Object.values(resources) });
});

// GET /resources/:id - Return a specific resource
app.get('/resources/:id', (req, res) => {
  const resource = resources[req.params.id];
  if (!resource) {
    return res.status(404).json({ error: 'Resource not found' });
  }
  res.json(resource);
});

// POST /resources/upload - Enhanced file upload with multiple file support
app.post('/resources/upload', upload.array('files', 5), async (req, res) => {
  try {
    if (!req.files || req.files.length === 0) {
      return res.status(400).json({ error: 'No files uploaded' });
    }

    const uploadedResources = [];
    
    // Process each uploaded file
    for (const file of req.files) {
      console.log(`\n\n==== PROCESSING UPLOADED FILE ====`);
      console.log(`File name: ${file.originalname}`);
      console.log(`File type: ${file.mimetype}`);
      console.log(`File size: ${(file.size / 1024).toFixed(2)} KB`);
      
      // Generate a unique resource ID
      const resourceId = `resource_${Date.now()}_${Math.floor(Math.random() * 1000)}`;
      
      // Extract content from the file
      console.log(`Extracting content from file...`);
      const content = await extractTextFromFile(file);
      console.log(`Extracted content length: ${content.length} characters`);
      console.log(`Content preview: ${content.substring(0, 300)}...`);
      
      // Trim content if it's too long
      const trimmedContent = trimToWordLimit(content, 8000); // Limiting to 8000 words
      console.log(`Trimmed content length: ${trimmedContent.length} characters`);
      
      // Create a new resource
      resources[resourceId] = {
        id: resourceId,
        title: file.originalname,
        content: trimmedContent,
        fileType: file.mimetype,
        fileSize: file.size,
        uploadedAt: new Date().toISOString()
      };
      
      console.log(`Created new resource: ${resourceId} from file: ${file.originalname}`);
      console.log(`==== END PROCESSING UPLOADED FILE ====\n\n`);
      
      uploadedResources.push(resources[resourceId]);
    }
    
    res.json({ 
      success: true, 
      resources: uploadedResources,
      message: `${uploadedResources.length} file(s) uploaded and resources created successfully` 
    });
    
  } catch (error) {
    console.error('Error uploading files:', error);
    res.status(500).json({ error: error.message });
  }
});

// POST /chat - Enhanced main endpoint with access to resources, tools and memory
app.post('/chat', async (req, res) => {
  try {
    const { messages, resource_id, use_tools, conversation_id } = req.body;
    
    // Use provided ID, or last conversation ID, or create new one
    const conversationId = conversation_id || lastConversationId || `conv_${Date.now()}`;
    lastConversationId = conversationId; // Update the last used conversation
    
    if (!conversations[conversationId]) {
      conversations[conversationId] = [];
      console.log(`Created new conversation: ${conversationId}`);
    } else {
      console.log(`Using existing conversation: ${conversationId} with ${conversations[conversationId].length} messages`);
    }
    
    // Get existing conversation history
    const conversationHistory = conversations[conversationId];
    
    // Add the new user message to history (only if it's not already there)
    if (messages && messages.length > 0) {
      const latestMessage = messages[messages.length - 1];
      if (latestMessage.role === 'user') {
        // Check if this message is already in the history to avoid duplicates
        const isDuplicate = conversationHistory.some(
          msg => msg.role === 'user' && msg.content === latestMessage.content
        );
        
        if (!isDuplicate) {
          conversationHistory.push(latestMessage);
          console.log(`Added user message to history: ${latestMessage.content}`);
        }
      }
    }

    // Build context with resources - Modified section
    let resourceContext = '';
    let includeResource = false;
    
    if (resource_id && messages && messages.length > 0) {
      // Check if we should include the resource
      includeResource = await shouldIncludeResource(
        messages[messages.length - 1].content,
        resource_id
      );
      
      if (includeResource) {
        resourceContext = `Resource: ${resources[resource_id].title}\n${resources[resource_id].content}\n\n`;
        console.log(`\n\n==== RESOURCE CONTENT BEING SENT TO AI ====`);
        console.log(`Resource ID: ${resource_id}`);
        console.log(`Resource Title: ${resources[resource_id].title}`);
        console.log(`Content Length: ${resources[resource_id].content.length} characters`);
        console.log(`First 500 chars: ${resources[resource_id].content.substring(0, 500)}...`);
        console.log(`==== END RESOURCE CONTENT PREVIEW ====\n\n`);
      } else {
        console.log(`Skipping resource content as query doesn't seem to need it`);
        resourceContext = "Note: You have access to documents but this query doesn't seem to need them.\n";
      }
    } else {
      resourceContext = "Available resources:\n";
      Object.values(resources).forEach(resource => {
        resourceContext += `- ${resource.title} (ID: ${resource.id})\n`;
      });
    }

    // Build system prompt with resources and tool availability
    const systemPrompt = `You are a helpful assistant${includeResource ? ' with access to the following resource:' : ''}.
${resourceContext}
${use_tools ? "You can use tools to help answer the query if needed." : ""}
Answer user queries thoughtfully based on this information.
IMPORTANT: When users ask about things they've previously mentioned in this conversation, 
use that information to provide personalized responses.`;

    console.log(`\n\n==== SYSTEM PROMPT BEING SENT TO AI ====`);
    console.log(systemPrompt.substring(0, 1000) + (systemPrompt.length > 1000 ? '...' : ''));
    console.log(`==== END SYSTEM PROMPT PREVIEW (${systemPrompt.length} characters total) ====\n\n`);

    console.log(`\n\nFull conversation history (${conversationHistory.length} messages):\n\n`, 
      JSON.stringify(conversationHistory));

    // Send to OpenAI with full conversation history
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: systemPrompt },
        ...conversationHistory
      ],
      temperature: 0.7,
      max_tokens: 4000
    });

    // Get AI response
    const aiResponse = completion.choices[0]?.message?.content || '';
    console.log(`AI response: ${aiResponse}`);
    
    // Format the response for consistency (remove excess whitespace/newlines)
    const formattedResponse = aiResponse.trim();
    
    // Add AI response to conversation history
    conversationHistory.push({ role: "assistant", content: formattedResponse });
    
    // Return AI response with additional context
    res.json({ 
      message: { role: "assistant", content: formattedResponse },
      available_resources: Object.keys(resources),
      tools_available: use_tools,
      conversation_id: conversationId,
      message_count: conversationHistory.length
    });
  } catch (err) {
    console.error("Error in chat endpoint:", err);
    res.status(500).json({ error: err.message });
  }
});

// POST /chat/stream - Streaming version of the chat endpoint
app.post('/chat/stream', async (req, res) => {
  try {
    const { messages, resource_id, use_tools, conversation_id } = req.body;
    
    // Set headers for SSE
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('X-Accel-Buffering', 'no'); // Important for Nginx
    res.setHeader('Transfer-Encoding', 'chunked');
    
    // Disable response buffering
    res.flushHeaders();
    
    // Use provided ID, or last conversation ID, or create new one
    const conversationId = conversation_id || lastConversationId || `conv_${Date.now()}`;
    lastConversationId = conversationId; // Update the last used conversation
    
    if (!conversations[conversationId]) {
      conversations[conversationId] = [];
      console.log(`Created new conversation: ${conversationId}`);
    } else {
      console.log(`Using existing conversation: ${conversationId} with ${conversations[conversationId].length} messages`);
    }
    
    // Get existing conversation history
    const conversationHistory = conversations[conversationId];
    
    // Add the new user message to history (only if it's not already there)
    if (messages && messages.length > 0) {
      const latestMessage = messages[messages.length - 1];
      if (latestMessage.role === 'user') {
        // Check if this message is already in the history to avoid duplicates
        const isDuplicate = conversationHistory.some(
          msg => msg.role === 'user' && msg.content === latestMessage.content
        );
        
        if (!isDuplicate) {
          conversationHistory.push(latestMessage);
          console.log(`Added user message to history: ${latestMessage.content}`);
        }
      }
    }

    // Build context with resources - Modified section
    let resourceContext = '';
    let includeResource = false;
    
    if (resource_id && messages && messages.length > 0) {
      // Check if we should include the resource
      includeResource = await shouldIncludeResource(
        messages[messages.length - 1].content,
        resource_id
      );
      
      if (includeResource) {
        resourceContext = `Resource: ${resources[resource_id].title}\n${resources[resource_id].content}\n\n`;
        console.log(`\n\n==== RESOURCE CONTENT BEING SENT TO AI (STREAM) ====`);
        console.log(`Resource ID: ${resource_id}`);
        console.log(`Resource Title: ${resources[resource_id].title}`);
        console.log(`Content Length: ${resources[resource_id].content.length} characters`);
        console.log(`First 500 chars: ${resources[resource_id].content.substring(0, 500)}...`);
        console.log(`==== END RESOURCE CONTENT PREVIEW ====\n\n`);
      } else {
        console.log(`Skipping resource content as query doesn't seem to need it`);
        resourceContext = "Note: You have access to documents but this query doesn't seem to need them.\n";
      }
    } else {
      resourceContext = "Available resources:\n";
      Object.values(resources).forEach(resource => {
        resourceContext += `- ${resource.title} (ID: ${resource.id})\n`;
      });
    }

    // Build system prompt with resources and tool availability
    const systemPrompt = `You are a helpful assistant${includeResource ? ' with access to the following resource:' : ''}.
${resourceContext}
${use_tools ? "You can use tools to help answer the query if needed." : ""}
Answer user queries thoughtfully based on this information.
IMPORTANT: When users ask about things they've previously mentioned in this conversation, 
use that information to provide personalized responses.`;

    console.log(`\n\n==== SYSTEM PROMPT BEING SENT TO AI (STREAM) ====`);
    console.log(systemPrompt.substring(0, 1000) + (systemPrompt.length > 1000 ? '...' : ''));
    console.log(`==== END SYSTEM PROMPT PREVIEW (${systemPrompt.length} characters total) ====\n\n`);

    console.log(`\n\nFull conversation history (${conversationHistory.length} messages):\n\n`, 
      JSON.stringify(conversationHistory));

    // Send a message to inform the client we're starting
    res.write(`data: ${JSON.stringify({ event: 'start' })}\n\n`);

    // Create a full response string to store the complete response
    let fullResponse = '';

    try {
      // Stream the response from OpenAI
      const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          ...conversationHistory
        ],
        temperature: 0.7,
        stream: true,
        max_tokens: 4000
      });

      // Process each chunk as it arrives
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          fullResponse += content;
          // Send each content chunk to the client
          res.write(`data: ${JSON.stringify({ event: 'content', content })}\n\n`);
        }
      }

      // Add the complete response to conversation history
      conversationHistory.push({ role: "assistant", content: fullResponse });
      
    } catch (streamError) {
      console.error("Error streaming from OpenAI:", streamError);
      res.write(`data: ${JSON.stringify({ event: 'error', error: streamError.message })}\n\n`);
    }
    
    // Send a message to inform the client we're done
    res.write(`data: ${JSON.stringify({ 
      event: 'end',
      conversation_id: conversationId,
      message_count: conversationHistory.length
    })}\n\n`);
    
    // End the response
    res.end();
    
  } catch (err) {
    console.error("Error in streaming chat endpoint:", err);
    // Send error to client if we can
    try {
      res.write(`data: ${JSON.stringify({ event: 'error', error: err.message })}\n\n`);
      res.end();
    } catch (e) {
      console.error("Could not send error to client:", e);
    }
  }
});

// Create a separate endpoint to receive stream parameters via GET
app.get('/chat/stream', (req, res) => {
  // Set up SSE headers
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('X-Accel-Buffering', 'no'); // Important for Nginx
  
  // Send a message to inform the client that a POST request is needed
  res.write(`data: ${JSON.stringify({ 
    event: 'error', 
    error: 'Please use POST /chat/stream with your message and parameters in the body'
  })}\n\n`);
  
  res.end();
});

// Add a debug endpoint to check conversations
app.get('/debug/conversations/:id?', (req, res) => {
  const { id } = req.params;
  
  if (id) {
    // Return specific conversation
    if (conversations[id]) {
      res.json({ conversation_id: id, messages: conversations[id] });
    } else {
      res.status(404).json({ error: "Conversation not found" });
    }
  } else {
    // Return list of all conversation IDs
    res.json({ 
      conversation_count: Object.keys(conversations).length,
      conversation_ids: Object.keys(conversations)
    });
  }
});

// Update memory endpoint to actually do something
app.post('/memory', (req, res) => {
  const { conversation_id, operation } = req.body;
  
  if (operation === 'clear' && conversation_id && conversations[conversation_id]) {
    // Clear specific conversation
    conversations[conversation_id] = [];
    res.json({ status: "cleared", conversation_id });
  } 
  else if (operation === 'get' && conversation_id && conversations[conversation_id]) {
    // Retrieve specific conversation
    res.json({ 
      status: "retrieved", 
      conversation_id,
      messages: conversations[conversation_id]
    });
  }
  else {
    res.json({ status: "no operation performed" });
  }
});

// Minimal endpoints for SLOP compliance:

// POST /tools (dummy)
app.post('/tools', (req, res) => {
  res.json({ result: "Tool used (dummy response)." });
});

// POST /pay (dummy)
app.post('/pay', (req, res) => {
  res.json({ transaction_id: `tx_${Date.now()}`, status: "success" });
});

// Start server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Simple SLOP chatbot running on port ${PORT}`);
  console.log(`Open your browser to http://localhost:${PORT}/client to access the SLOP client`);
});

// Serve the client
app.get('/client', (req, res) => {
  res.sendFile(process.cwd() + '/../SLOP-CLIENT/index.html');
});

// Add a cleanup function for the caches
function clearOldCaches() {
  const ONE_HOUR = 60 * 60 * 1000;
  setInterval(() => {
    fileHashCache.clear();
    pdfTextCache.clear();
    console.log('Cleared PDF and file hash caches');
  }, ONE_HOUR);
}

// Call this after your app is initialized
clearOldCaches();

----------------------
EXAMPLES\JAVASCRIPT\README.MD
----------------------
# SLOP JavaScript Example

A simple implementation of the [SLOP](https://github.com/agnt-gg/slop) pattern in JavaScript.

## JavaScript Quick Start

```bash
# Clone the repo
git clone https://github.com/agnt-gg/slop
cd slop/javascript

# Install dependencies
npm install

# Run it
npm start
```

## Endpoints

```javascript
// CHAT - Talk to AI
POST /chat
{
  "messages": [{ "content": "Hello SLOP!" }]
}

// TOOLS - Use tools
GET /tools
POST /tools/calculator { "expression": "2 + 2" }
POST /tools/greet { "name": "SLOP" }

// MEMORY - Store data
POST /memory { "key": "test", "value": "hello" }
GET /memory/test

// RESOURCES - Get knowledge
GET /resources
GET /resources/hello

// PAY - Handle payments
POST /pay { "amount": 10 }
```

## Structure

- `slop.js` - The entire implementation
- `package.json` - Dependencies and scripts

That's it. Just two files.

## Dependencies

- `express` - For clean routing
- `axios` - For clean HTTP requests

## Try It

After starting the server, it automatically runs tests for all endpoints. Watch the magic happen!

```bash
npm start

# Output:
âœ¨ SLOP running on http://localhost:3000

ðŸ“ Testing chat...
You said: Hello SLOP!

ðŸ”§ Testing tools...
2 + 2 = 4
Hello, SLOP!

ðŸ’¾ Testing memory...
Stored value: hello world

ðŸ“š Testing resources...
Resource content: Hello, SLOP!

ðŸ’° Testing pay...
Transaction: tx_1234567890

âœ… All tests passed!
```

## Learn More

Check out the [main SLOP repository](https://github.com/agnt-gg/slop) for:
- Full specification
- Other language examples
- Core concepts
- Best practices

Remember: SLOP is just a pattern. This is a simple implementation example to show how it works.
----------------------
EXAMPLES\JAVASCRIPT\SLOP.JS
----------------------
// JavaScript implementation of the SLOP pattern
import express from 'express';
import axios from 'axios';

// Available tools and resources
const tools = {
  calculator: {
    id: 'calculator',
    description: 'Basic math',
    execute: params => ({ result: eval(params.expression) })
  },
  greet: {
    id: 'greet',
    description: 'Says hello',
    execute: params => ({ result: `Hello, ${params.name}!` })
  }
};

const resources = {
  hello: { id: 'hello', content: 'Hello, SLOP!' }
};

// Setup server
const app = express();
app.use(express.json());

// In-memory storage
const memory = new Map();

// CHAT
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || 'nothing';
  res.json({
    message: {
      role: 'assistant',
      content: `You said: ${message}`
    }
  });
});

// TOOLS
app.get('/tools', (_, res) => res.json({ tools: Object.values(tools) }));
app.post('/tools/:id', (req, res) => {
  const tool = tools[req.params.id];
  if (!tool) return res.status(404).json({ error: 'Tool not found' });
  res.json(tool.execute(req.body));
});

// MEMORY
app.post('/memory', (req, res) => {
  const { key, value } = req.body;
  memory.set(key, value);
  res.json({ status: 'stored' });
});

app.get('/memory/:key', (req, res) => {
  res.json({ value: memory.get(req.params.key) });
});

// RESOURCES
app.get('/resources', (_, res) => res.json({ resources: Object.values(resources) }));
app.get('/resources/:id', (req, res) => {
  const resource = resources[req.params.id];
  if (!resource) return res.status(404).json({ error: 'Resource not found' });
  res.json(resource);
});

// PAY
app.post('/pay', (_, res) => {
  res.json({
    transaction_id: 'tx_' + Date.now(),
    status: 'success'
  });
});

// Start server and run tests
app.listen(3000, async () => {
  console.log('âœ¨ SLOP running on http://localhost:3000\n');
  
  const api = axios.create({ baseURL: 'http://localhost:3000' });
  
  try {
    // Test chat
    console.log('ðŸ“ Testing chat...');
    const chat = await api.post('/chat', {
      messages: [{ content: 'Hello SLOP!' }]
    });
    console.log(chat.data.message.content, '\n');

    // Test tools
    console.log('ðŸ”§ Testing tools...');
    const calc = await api.post('/tools/calculator', {
      expression: '2 + 2'
    });
    console.log('2 + 2 =', calc.data.result);

    const greet = await api.post('/tools/greet', {
      name: 'SLOP'
    });
    console.log(greet.data.result, '\n');

    // Test memory
    console.log('ðŸ’¾ Testing memory...');
    await api.post('/memory', {
      key: 'test',
      value: 'hello world'
    });
    const memory = await api.get('/memory/test');
    console.log('Stored value:', memory.data.value, '\n');

    // Test resources
    console.log('ðŸ“š Testing resources...');
    const hello = await api.get('/resources/hello');
    console.log('Resource content:', hello.data.content, '\n');

    // Test pay
    console.log('ðŸ’° Testing pay...');
    const pay = await api.post('/pay', {
      amount: 10
    });
    console.log('Transaction:', pay.data.transaction_id, '\n');

    console.log('âœ… All tests passed!');
  } catch (error) {
    console.error('âŒ Test failed:', error.response?.data || error.message);
  }
});
----------------------
EXAMPLES\PYTHON\ADVANCED-EXAMPLES\MULTI-AGENT.PY
----------------------
import os
import json
import time
from flask import Flask, request, jsonify
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict, Any
import asyncio

# Load environment variables
load_dotenv()

# Initialize Flask app
app = Flask(__name__)

# Initialize OpenAI client
openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Memory storage
memory = {}

# ======= SIMPLE AGENT SYSTEM =======

# Router Agent - decides which specialized agent to use
def router_agent(query: str) -> Dict[str, str]:
    completion = openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a router that categorizes queries and selects the best specialized agent to handle them."},
            {"role": "user", "content": f'Classify this query and select ONE agent: "{query}"'}
        ],
        tools=[{
            "type": "function",
            "function": {
                "name": "route_query",
                "description": "Route the query to the appropriate agent",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "agent": {
                            "type": "string",
                            "enum": ["researcher", "creative", "technical", "summarizer"],
                            "description": "The agent best suited to handle this query"
                        },
                        "reason": {
                            "type": "string",
                            "description": "Brief reason for this routing decision"
                        }
                    },
                    "required": ["agent", "reason"]
                }
            }
        }],
        tool_choice={"type": "function", "function": {"name": "route_query"}}
    )
    
    tool_call = completion.choices[0].message.tool_calls[0]
    args = json.loads(tool_call.function.arguments)
    print(f"ðŸ”€ Routing to: {args['agent']} ({args['reason']})")
    return args

# Create agent factory
def create_agent(role: str, temperature: float = 0.7):
    async def agent(query: str) -> str:
        completion = await asyncio.to_thread(
            openai.chat.completions.create,
            model="gpt-4",
            messages=[
                {"role": "system", "content": role},
                {"role": "user", "content": query}
            ],
            temperature=temperature
        )
        return completion.choices[0].message.content
    return agent

# Specialized Agents
agents = {
    "researcher": create_agent("You are a research agent providing factual information with sources.", 0.3),
    "creative": create_agent("You are a creative agent generating imaginative content.", 0.9),
    "technical": create_agent("You are a technical agent providing precise, detailed explanations.", 0.2),
    "summarizer": create_agent("You are a summarization agent that creates concise summaries.", 0.3)
}

# ======= SLOP API IMPLEMENTATION =======

# 1. CHAT endpoint - main entry point
@app.route('/chat', methods=['POST'])
async def chat():
    try:
        data = request.json
        messages = data.get('messages', [])
        pattern = data.get('pattern')
        user_query = messages[0]['content'] if messages else ""
        
        response = None

        if pattern:
            if pattern == 'sequential':
                # Research then summarize
                research = await agents["researcher"](user_query)
                response = await agents["summarizer"](research)
            
            elif pattern == 'parallel':
                # Get multiple perspectives simultaneously
                research_task = agents["researcher"](user_query)
                creative_task = agents["creative"](user_query)
                results = await asyncio.gather(research_task, creative_task)
                response = f"Research perspective:\n{results[0]}\n\nCreative perspective:\n{results[1]}"
            
            elif pattern == 'branching':
                route = router_agent(user_query)
                response = await agents[route['agent']](user_query)
            
            else:
                # Default to router behavior
                route = router_agent(user_query)
                response = await agents[route['agent']](user_query)
        else:
            # Default to router behavior
            route = router_agent(user_query)
            response = await agents[route['agent']](user_query)
        
        # Store in memory
        session_id = f"session_{int(time.time())}"
        memory[session_id] = {
            "query": user_query,
            "pattern": pattern or "router",
            "response": response
        }
        
        return jsonify({
            "message": {
                "role": "assistant",
                "content": response,
                "metadata": {
                    "session_id": session_id,
                    "pattern": pattern or "router"
                }
            }
        })
    except Exception as e:
        print(f"Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# 2. TOOLS endpoint
@app.route('/tools', methods=['GET'])
def list_tools():
    return jsonify({
        "tools": [
            {"id": "researcher", "description": "Finds factual information"},
            {"id": "creative", "description": "Generates imaginative content"},
            {"id": "technical", "description": "Provides technical explanations"},
            {"id": "summarizer", "description": "Creates concise summaries"}
        ],
        "patterns": [
            {"id": "sequential", "description": "Research then summarize"},
            {"id": "parallel", "description": "Multiple perspectives at once"},
            {"id": "branching", "description": "Route to best agent (default)"}
        ]
    })

# 3. MEMORY endpoints
@app.route('/memory', methods=['POST'])
def store_memory():
    data = request.json
    key = data.get('key')
    value = data.get('value')
    memory[key] = value
    return jsonify({"status": "stored"})

@app.route('/memory/<key>', methods=['GET'])
def get_memory(key):
    return jsonify({"value": memory.get(key)})

# 4. RESOURCES endpoint
@app.route('/resources', methods=['GET'])
def get_resources():
    return jsonify({
        "patterns": {
            "sequential": "Chain agents: Research â†’ Summarize",
            "parallel": "Multiple agents work simultaneously",
            "branching": "Route to specialized agents"
        },
        "examples": {
            "sequential": {
                "description": "Research a topic and create a summary",
                "request": {
                    "messages": [{"content": "Explain quantum computing"}],
                    "pattern": "sequential"
                }
            },
            "parallel": {
                "description": "Get multiple perspectives on a topic",
                "request": {
                    "messages": [{"content": "Benefits of meditation"}],
                    "pattern": "parallel"
                }
            },
            "branching": {
                "description": "Route to the most appropriate agent",
                "request": {
                    "messages": [{"content": "How do I write a Python class?"}],
                    "pattern": "branching"
                }
            }
        }
    })

# 5. PAY endpoint (simple mock)
@app.route('/pay', methods=['POST'])
def process_payment():
    data = request.json
    tx_id = f"tx_{int(time.time())}"
    memory[tx_id] = {"amount": data.get('amount'), "status": "completed"}
    return jsonify({"transaction_id": tx_id})

if __name__ == "__main__":
    port = int(os.getenv("PORT", 3000))
    print(f"ðŸ¤– SLOP Multi-Agent API running on port {port}")
    app.run(host="0.0.0.0", port=port, debug=True)

"""
Example usage:

1. Basic query (uses router):
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
    "messages": [{"content": "What are black holes?"}]
}'

2. Sequential pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
    "messages": [{"content": "Explain quantum computing"}],
    "pattern": "sequential"
}'

3. Parallel pattern:
curl -X POST http://localhost:3000/chat \
-H "Content-Type: application/json" \
-d '{
    "messages": [{"content": "Benefits of meditation"}],
    "pattern": "parallel"
}'

4. Store in memory:
curl -X POST http://localhost:3000/memory \
-H "Content-Type: application/json" \
-d '{
    "key": "test",
    "value": "hello world"
}'

5. Get from memory:
curl -X GET http://localhost:3000/memory/test

6. List tools:
curl -X GET http://localhost:3000/tools

7. Get resources:
curl -X GET http://localhost:3000/resources

8. Process payment:
curl -X POST http://localhost:3000/pay \
-H "Content-Type: application/json" \
-d '{
    "amount": 10
}'
"""
----------------------
EXAMPLES\PYTHON\README.MD
----------------------
# SLOP Python Example

A simple implementation of the [SLOP](https://github.com/agnt-gg/slop) pattern in Python.

## Python Quick Start

```bash
# Clone the repo
git clone https://github.com/agnt-gg/slop
cd slop/python

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run it
python slop.py
```

## Endpoints

```python
# CHAT - Talk to AI
POST /chat
{
  "messages": [{ "content": "Hello SLOP!" }]
}

# TOOLS - Use tools
GET /tools
POST /tools/calculator { "expression": "2 + 2" }
POST /tools/greet { "name": "SLOP" }

# MEMORY - Store data
POST /memory { "key": "test", "value": "hello" }
GET /memory/test

# RESOURCES - Get knowledge
GET /resources
GET /resources/hello

# PAY - Handle payments
POST /pay { "amount": 10 }
```

## Structure

- `slop.py` - The entire implementation
- `requirements.txt` - Dependencies

That's it. Just two files.

## Dependencies

- `flask` - For clean routing
- `requests` - For testing endpoints

## Try It

After starting the server, it automatically runs tests for all endpoints:

```bash
python slop.py

# Output:
âœ¨ SLOP running on http://localhost:5000
ðŸš€ Running tests...

ðŸ“ Testing chat...
You said: Hello SLOP!

ðŸ”§ Testing tools...
2 + 2 = 4
Hello, SLOP!

ðŸ’¾ Testing memory...
Stored value: hello world

ðŸ“š Testing resources...
Resource content: Hello, SLOP!

ðŸ’° Testing pay...
Transaction: tx_1234567890

âœ… All tests passed!
```

## Learn More

Check out the [main SLOP repository](https://github.com/agnt-gg/slop) for:
- Full specification
- Other language examples
- Core concepts
- Best practices

Remember: SLOP is just a pattern. This is a simple implementation example to show how it works.
----------------------
EXAMPLES\PYTHON\REQUIREMENTS.TXT
----------------------
flask==3.0.2
requests==2.31.0
----------------------
EXAMPLES\PYTHON\SLOP.PY
----------------------
# Python implementation of the SLOP pattern

from flask import Flask, request, jsonify
import requests
from datetime import datetime

# Initialize Flask app
app = Flask(__name__)

# Available tools and resources
tools = {
    'calculator': {
        'id': 'calculator',
        'description': 'Basic math',
        'execute': lambda params: {'result': eval(params['expression'])}
    },
    'greet': {
        'id': 'greet',
        'description': 'Says hello',
        'execute': lambda params: {'result': f"Hello, {params['name']}!"}
    }
}

resources = {
    'hello': {'id': 'hello', 'content': 'Hello, SLOP!'}
}

# In-memory storage
memory = {}

# CHAT
@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    message = data.get('messages', [{}])[0].get('content', 'nothing')
    return jsonify({
        'message': {
            'role': 'assistant',
            'content': f'You said: {message}'
        }
    })

# TOOLS
@app.route('/tools', methods=['GET'])
def list_tools():
    return jsonify({'tools': list(tools.values())})

@app.route('/tools/<tool_id>', methods=['POST'])
def use_tool(tool_id):
    if tool_id not in tools:
        return jsonify({'error': 'Tool not found'}), 404
    return jsonify(tools[tool_id]['execute'](request.json))

# MEMORY
@app.route('/memory', methods=['POST'])
def store_memory():
    data = request.json
    memory[data['key']] = data['value']
    return jsonify({'status': 'stored'})

@app.route('/memory/<key>', methods=['GET'])
def get_memory(key):
    return jsonify({'value': memory.get(key)})

# RESOURCES
@app.route('/resources', methods=['GET'])
def list_resources():
    return jsonify({'resources': list(resources.values())})

@app.route('/resources/<resource_id>', methods=['GET'])
def get_resource(resource_id):
    if resource_id not in resources:
        return jsonify({'error': 'Resource not found'}), 404
    return jsonify(resources[resource_id])

# PAY
@app.route('/pay', methods=['POST'])
def pay():
    return jsonify({
        'transaction_id': f'tx_{int(datetime.now().timestamp())}',
        'status': 'success'
    })

def test_endpoints():
    """Test all SLOP endpoints"""
    base = 'http://localhost:5000'
    
    try:
        # Test chat
        print('ðŸ“ Testing chat...')
        chat = requests.post(f'{base}/chat', json={
            'messages': [{'content': 'Hello SLOP!'}]
        }).json()
        print(chat['message']['content'], '\n')

        # Test tools
        print('ðŸ”§ Testing tools...')
        calc = requests.post(f'{base}/tools/calculator', json={
            'expression': '2 + 2'
        }).json()
        print('2 + 2 =', calc['result'])

        greet = requests.post(f'{base}/tools/greet', json={
            'name': 'SLOP'
        }).json()
        print(greet['result'], '\n')

        # Test memory
        print('ðŸ’¾ Testing memory...')
        requests.post(f'{base}/memory', json={
            'key': 'test',
            'value': 'hello world'
        })
        memory = requests.get(f'{base}/memory/test').json()
        print('Stored value:', memory['value'], '\n')

        # Test resources
        print('ðŸ“š Testing resources...')
        hello = requests.get(f'{base}/resources/hello').json()
        print('Resource content:', hello['content'], '\n')

        # Test pay
        print('ðŸ’° Testing pay...')
        pay = requests.post(f'{base}/pay', json={
            'amount': 10
        }).json()
        print('Transaction:', pay['transaction_id'], '\n')

        print('âœ… All tests passed!')
    except Exception as e:
        print('âŒ Test failed:', str(e))

if __name__ == '__main__':
    import threading
    import time
    
    # Start server in a thread
    threading.Thread(target=app.run, daemon=True).start()
    
    # Wait for server to start
    print('âœ¨ SLOP running on http://localhost:5000')
    time.sleep(1)
    print('ðŸš€ Running tests...\n')
    
    # Run tests
    test_endpoints()
----------------------
EXAMPLES\REPLIT\INDEX.HTML
----------------------
<!doctype html>
<html>
  <head>
    <title>My SLOP Chat</title>
    <style>
      body {
        font-family: Arial;
        max-width: 600px;
        margin: 0 auto;
        padding: 20px;
        background-color: #f9f9f9;
      }
      h1 {
        color: #2c3e50;
        text-align: center;
      }
      #chat-container {
        border: 1px solid #ddd;
        border-radius: 8px;
        height: 350px;
        overflow-y: auto;
        padding: 15px;
        margin-bottom: 15px;
        background-color: white;
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      }
      #chat-container div {
        margin-bottom: 10px;
        padding: 8px;
        border-radius: 5px;
      }
      #chat-container div:nth-child(odd) {
        background-color: #f1f1f1;
      }
      #user-input {
        width: 75%;
        padding: 10px;
        border: 1px solid #ddd;
        border-radius: 4px;
        font-size: 16px;
      }
      button {
        padding: 10px 20px;
        background: #3498db;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        font-size: 16px;
        transition: background 0.3s;
      }
      button:hover {
        background: #2980b9;
      }
      ul {
        padding-left: 20px;
      }
      li {
        margin: 5px 0;
      }
    </style>
  </head>
  <body>
    <div
      style="
        margin-top: 20px;
        background-color: #e9f7fe;
        padding: 10px;
        border-radius: 5px;
      "
    >
      <p><strong>SLOP Compatibility</strong></p>
      <p>
        This server implements the Simple Language Open Protocol (SLOP) with all
        standard endpoints:
      </p>
      <ul>
        <li><code>POST /chat</code> - Talk to the trivia bot</li>
        <li><code>GET /tools</code> - Get available tools</li>
        <li><code>POST /tools/:tool_id</code> - Use a specific tool</li>
        <li><code>POST /memory</code> - Store key-value data</li>
        <li><code>GET /memory/:key</code> - Retrieve stored data</li>
        <li><code>GET /resources</code> - Get available resources</li>
        <li><code>GET /resources/:id</code> - Get specific resource</li>
        <li><code>POST /pay</code> - Mock payment processing</li>
      </ul>
      <p style="text-align: center; margin-top: 15px">
        <a
          href="/test-slop.html"
          style="
            display: inline-block;
            padding: 10px 20px;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-weight: bold;
          "
        >
          Test All SLOP Endpoints
        </a>
      </p>
    </div>
  </body>
</html>

----------------------
EXAMPLES\REPLIT\INDEX.JS
----------------------

const express = require('express');
const app = express();
app.use(express.json());

// Serve static files from the 'public' directory
app.use(express.static('public'));

// Trivia game data
const triviaQuestions = [
  {
    question: "What is the capital of France?",
    answer: "paris",
    hint: "It's known as the City of Light."
  },
  {
    question: "Which planet is known as the Red Planet?",
    answer: "mars",
    hint: "It's named after the Roman god of war."
  },
  {
    question: "What is the largest mammal in the world?",
    answer: "blue whale",
    hint: "It lives in the ocean and can weigh up to 200 tons."
  },
  {
    question: "Who painted the Mona Lisa?",
    answer: "leonardo da vinci",
    hint: "He was an Italian polymath from the Renaissance period."
  },
  {
    question: "What is the chemical symbol for gold?",
    answer: "au",
    hint: "It comes from the Latin word 'aurum'."
  }
];

// Game state
let currentGame = {
  active: false,
  currentQuestion: null,
  score: 0,
  askedQuestions: [],
  hintUsed: false
};

// In-memory storage for SLOP
const memory = new Map();

// 1. CHAT ENDPOINT - SLOP compatible
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || '';
  const lowerMessage = message.toLowerCase();
  
  // Response based on game state and message
  let response = '';

  // Trivia game commands
  if (lowerMessage.includes('start trivia') || lowerMessage.includes('play trivia')) {
    currentGame = {
      active: true,
      currentQuestion: null,
      score: 0,
      askedQuestions: [],
      hintUsed: false
    };
    response = "Welcome to Trivia Challenge! I'll ask you questions and you try to answer them. Say 'next question' to begin!";
  } 
  else if (currentGame.active && (lowerMessage.includes('next question') || lowerMessage.includes('new question'))) {
    // Get a question that hasn't been asked yet
    const availableQuestions = triviaQuestions.filter(q => !currentGame.askedQuestions.includes(q.question));
    
    if (availableQuestions.length === 0) {
      response = `Game over! Your final score is ${currentGame.score}/${triviaQuestions.length}. Say 'start trivia' to play again!`;
      currentGame.active = false;
    } else {
      currentGame.currentQuestion = availableQuestions[Math.floor(Math.random() * availableQuestions.length)];
      currentGame.askedQuestions.push(currentGame.currentQuestion.question);
      currentGame.hintUsed = false;
      response = `Question: ${currentGame.currentQuestion.question} (Say 'hint' if you need help)`;
    }
  }
  else if (currentGame.active && lowerMessage.includes('hint') && currentGame.currentQuestion) {
    currentGame.hintUsed = true;
    response = `Hint: ${currentGame.currentQuestion.hint}`;
  }
  else if (currentGame.active && currentGame.currentQuestion && lowerMessage.includes('skip')) {
    response = `The answer was: ${currentGame.currentQuestion.answer}. Say 'next question' for another one!`;
    currentGame.currentQuestion = null;
  }
  else if (currentGame.active && currentGame.currentQuestion) {
    // Check if the answer is correct
    if (lowerMessage.includes(currentGame.currentQuestion.answer.toLowerCase())) {
      currentGame.score += currentGame.hintUsed ? 0.5 : 1; // Half point if hint was used
      response = currentGame.hintUsed ? 
        `Correct! You get half a point for using a hint. Your score is now ${currentGame.score}. Say 'next question' to continue!` :
        `Correct! Your score is now ${currentGame.score}. Say 'next question' to continue!`;
      currentGame.currentQuestion = null;
    } else {
      response = "Sorry, that's not correct. Try again, say 'hint' for a clue, or 'skip' to move on.";
    }
  }
  else if (lowerMessage.includes('stop trivia') || lowerMessage.includes('end trivia')) {
    response = `Game ended. Your final score was ${currentGame.score}. Thanks for playing!`;
    currentGame.active = false;
  }
  // Standard responses if not in game mode
  else if (lowerMessage.includes('hello')) {
    response = "Hello there! Want to play a trivia game? Say 'start trivia' to begin!";
  } else if (lowerMessage.includes('weather')) {
    response = "I don't have real-time weather data, but I hope it's sunny where you are!";
  } else if (lowerMessage.includes('name')) {
    response = "I'm a Trivia Bot. Nice to meet you! Say 'start trivia' to play a game.";
  } else {
    response = `You said: "${message}". Try saying 'start trivia' to play a fun trivia game!`;
  }

  res.json({ message: { role: 'assistant', content: response } });
});

// 2. TOOLS ENDPOINT - SLOP compatible
app.get('/tools', (req, res) => {
  res.json({ 
    tools: [
      { 
        id: 'trivia', 
        description: 'Play a trivia game with questions on various subjects' 
      },
      { 
        id: 'hint', 
        description: 'Get a hint for the current question in the trivia game' 
      },
      { 
        id: 'score', 
        description: 'Check your current score in the trivia game' 
      }
    ] 
  });
});

// Tool execution endpoint
app.post('/tools/:tool_id', (req, res) => {
  const toolId = req.params.tool_id;
  
  // Ensure req.body is initialized even if no JSON body is sent
  req.body = req.body || {};
  
  switch(toolId) {
    case 'trivia':
      if (!currentGame.active) {
        currentGame = {
          active: true,
          currentQuestion: null,
          score: 0,
          askedQuestions: [],
          hintUsed: false
        };
        res.json({ result: "Trivia game started! Say 'next question' to begin." });
      } else {
        res.json({ result: "You're already in a trivia game! Say 'next question' for a new question or 'end trivia' to stop." });
      }
      break;
      
    case 'hint':
      if (currentGame.active && currentGame.currentQuestion) {
        currentGame.hintUsed = true;
        res.json({ result: `Hint: ${currentGame.currentQuestion.hint}` });
      } else {
        res.json({ result: "No active question to give a hint for. Start a game with 'start trivia' first!" });
      }
      break;
      
    case 'score':
      if (currentGame.active) {
        res.json({ 
          result: `Your current score is ${currentGame.score}. You've answered ${currentGame.askedQuestions.length} questions.` 
        });
      } else {
        res.json({ result: "No active game. Start a new game with 'start trivia'!" });
      }
      break;
      
    default:
      res.status(404).json({ error: "Tool not found" });
  }
});

// 3. MEMORY ENDPOINT - SLOP compatible
app.post('/memory', (req, res) => {
  const { key, value } = req.body;
  if (key && value !== undefined) {
    memory.set(key, value);
    res.json({ status: 'stored' });
  } else {
    res.status(400).json({ error: 'Both key and value are required' });
  }
});

app.get('/memory/:key', (req, res) => {
  const { key } = req.params;
  if (memory.has(key)) {
    res.json({ value: memory.get(key) });
  } else {
    res.status(404).json({ error: 'Key not found' });
  }
});

app.get('/memory', (req, res) => {
  const keys = Array.from(memory.keys()).map(key => ({
    key,
    created_at: new Date().toISOString()
  }));
  res.json({ keys });
});

// 4. RESOURCES ENDPOINT - SLOP compatible
app.get('/resources', (req, res) => {
  res.json({ 
    resources: [
      { 
        id: 'trivia-questions', 
        title: 'Available Trivia Questions',
        type: 'collection' 
      },
      { 
        id: 'commands', 
        title: 'Trivia Game Commands',
        type: 'guide' 
      }
    ] 
  });
});

app.get('/resources/:id', (req, res) => {
  const resourceId = req.params.id;
  
  switch (resourceId) {
    case 'trivia-questions':
      // Return number of available questions and categories
      res.json({
        id: 'trivia-questions',
        title: 'Available Trivia Questions',
        content: `There are ${triviaQuestions.length} questions available covering topics like geography, science, art, and more.`,
        metadata: {
          count: triviaQuestions.length,
          last_updated: new Date().toISOString()
        }
      });
      break;
      
    case 'commands':
      res.json({
        id: 'commands',
        title: 'Trivia Game Commands',
        content: "Available commands: 'start trivia', 'next question', 'hint', 'skip', 'end trivia'",
        metadata: {
          command_count: 5,
          last_updated: new Date().toISOString()
        }
      });
      break;
      
    default:
      res.status(404).json({ error: 'Resource not found' });
  }
});

// Simple search for resources
app.get('/resources/search', (req, res) => {
  const query = req.query.q?.toLowerCase() || '';
  
  const results = [];
  
  if (query.includes('trivia') || query.includes('question')) {
    results.push({
      id: 'trivia-questions',
      title: 'Available Trivia Questions',
      type: 'collection',
      score: 0.95
    });
  }
  
  if (query.includes('command') || query.includes('help')) {
    results.push({
      id: 'commands',
      title: 'Trivia Game Commands',
      type: 'guide',
      score: 0.90
    });
  }
  
  res.json({ results });
});

// 5. PAY ENDPOINT - SLOP compatible (mock implementation)
app.post('/pay', (req, res) => {
  // Simple mock implementation
  const transactionId = `tx_${Date.now()}`;
  
  // Store transaction in memory
  memory.set(transactionId, {
    amount: req.body.amount || 0,
    currency: req.body.currency || 'USD',
    description: req.body.description || 'Trivia game usage',
    status: 'success',
    created_at: new Date().toISOString()
  });
  
  res.json({
    transaction_id: transactionId,
    status: 'success',
    receipt_url: `https://api.example.com/receipts/${transactionId}`
  });
});

app.get('/pay/:id', (req, res) => {
  const { id } = req.params;
  
  if (memory.has(id)) {
    const transaction = memory.get(id);
    res.json({
      transaction_id: id,
      ...transaction
    });
  } else {
    res.status(404).json({ error: 'Transaction not found' });
  }
});

// Start the server
app.listen(3000, '0.0.0.0', () => console.log('âœ¨ SLOP running on port 3000'));

----------------------
EXAMPLES\REPLIT\README.MD
----------------------
# 2 Minute SLOP Server Implementation in Replit ðŸš€

This guide helps non-developers create and run a SLOP (Simple Language Open Protocol) server with a public URL in less than 5 minutes using Replit - no coding experience required!

## What is SLOP?

SLOP (Simple Language Open Protocol) is a pattern for AI APIs with 5 basic endpoints:
- `POST /chat` - Talk to AI
- `POST /tools` - Use tools
- `POST /memory` - Remember stuff
- `GET /resources` - Get knowledge/files/data
- `POST /pay` - Handle money

It's designed to make AI services work through plain web requests using patterns we've used for decades.

## Step 1: Create a Replit Account

1. Go to [replit.com](https://replit.com) and sign up for a free account

## Step 2: Create a New Repl

1. Click the "+ Create" button in the top-left corner
2. Select "Template" and search for "Node.js"
3. Name your project something like "my-slop-server"
4. Click "Create Repl"

## Step 3: Copy the SLOP Server Code

1. Delete any existing code in the main file (usually `index.js`)
2. Paste this minimal SLOP server code:

```javascript
const express = require('express');
const app = express();
app.use(express.json());

// Serve static files from the 'public' directory
app.use(express.static('public'));

// Minimum viable SLOP endpoints
app.post('/chat', (req, res) => {
  // Get the message from the request
  const message = req.body.messages?.[0]?.content || '';
  
  // Simple response - you can make this more interactive!
  const response = `You said: "${message}". This is your SLOP server responding!`;
  
  res.json({ message: { role: 'assistant', content: response } });
});

app.get('/tools', (req, res) => {
  res.json({ tools: [{ id: 'greeter', description: 'Says hello' }] });
});

app.post('/memory', (req, res) => {
  res.json({ status: 'stored' });
});

app.get('/resources', (req, res) => {
  res.json({ resources: [{ id: 'greeting', content: 'Hello, world!' }] });
});

app.post('/pay', (req, res) => {
  res.json({ transaction_id: 'tx_hello_world' });
});

app.listen(3000, () => console.log('âœ¨ SLOP running on port 3000'));
```

## Step 4: Install Required Package

1. In the Shell (console at the bottom), type this command and hit Enter:
```
npm install express
```

## Step 5: Create a Simple HTML Interface

1. In your Replit project, click the "Files" panel (left side)
2. Click the "+" button to create a new file
3. Name it `public/index.html` (Replit will create the public folder automatically)
4. Paste this code into your new `index.html` file:

```html
<!DOCTYPE html>
<html>
<head>
  <title>My SLOP Chat</title>
  <style>
    body { font-family: Arial; max-width: 600px; margin: 0 auto; padding: 20px; }
    #chat-container { border: 1px solid #ccc; height: 300px; overflow-y: auto; padding: 10px; margin-bottom: 10px; }
    #user-input { width: 80%; padding: 8px; }
    button { padding: 8px 16px; background: #4CAF50; color: white; border: none; cursor: pointer; }
  </style>
</head>
<body>
  <h1>SLOP Chat</h1>
  <div id="chat-container"></div>
  <input type="text" id="user-input" placeholder="Type your message...">
  <button onclick="sendMessage()">Send</button>

  <script>
    function addMessage(role, content) {
      const chatContainer = document.getElementById('chat-container');
      const messageDiv = document.createElement('div');
      messageDiv.innerHTML = `<strong>${role}:</strong> ${content}`;
      chatContainer.appendChild(messageDiv);
      chatContainer.scrollTop = chatContainer.scrollHeight;
    }

    async function sendMessage() {
      const input = document.getElementById('user-input');
      const message = input.value.trim();
      
      if (!message) return;
      
      // Display user message
      addMessage('You', message);
      input.value = '';
      
      try {
        // Send to chat endpoint
        const response = await fetch('/chat', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            messages: [{ role: 'user', content: message }]
          })
        });
        
        const data = await response.json();
        
        // Display assistant message
        addMessage('Assistant', data.message.content);
      } catch (error) {
        addMessage('Error', 'Failed to get response');
        console.error(error);
      }
    }

    // Allow sending with Enter key
    document.getElementById('user-input').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') sendMessage();
    });
  </script>
</body>
</html>
```

## Step 6: Run Your Server

1. Click the "Run" button at the top of Replit
2. Wait for the server to start (you'll see "âœ¨ SLOP running on port 3000")

## Step 7: Access Your Public URL

1. Look at the top-right side of the Replit interface for the "Webview" tab
2. Click on it to see your running app with the chat interface
3. The URL in the browser tab is your public SLOP server address!

## Testing Your SLOP Server

You can test your server in several ways:

1. Use the web interface to chat with your server
2. Add `/tools` to the end of your public URL to see the available tools:
   - Your URL will look like: `https://my-slop-server.yourusername.repl.co/tools`

## Using the Replit Console to Test Endpoints

You can use the built-in Replit console to test your other endpoints:

```bash
# In the Replit Shell, test your chat endpoint
curl -X POST https://my-slop-server.yourusername.repl.co/chat -H "Content-Type: application/json" -d '{"messages":[{"content":"Hello SLOP!"}]}'

# Test tools endpoint
curl https://my-slop-server.yourusername.repl.co/tools

# Test memory endpoint
curl -X POST https://my-slop-server.yourusername.repl.co/memory -H "Content-Type: application/json" -d '{"key":"test","value":"hello world"}'

# Test resources endpoint
curl https://my-slop-server.yourusername.repl.co/resources

# Test pay endpoint
curl -X POST https://my-slop-server.yourusername.repl.co/pay -H "Content-Type: application/json" -d '{}'
```

## Making It More Interesting

To make your SLOP server more interesting, you can modify the response in the `/chat` endpoint to do different things:

```javascript
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || '';
  
  // Simple keyword response system
  let response = '';
  
  if (message.toLowerCase().includes('hello')) {
    response = "Hello there! How can I help you today?";
  } else if (message.toLowerCase().includes('weather')) {
    response = "I don't have real-time weather data, but I hope it's sunny where you are!";
  } else if (message.toLowerCase().includes('name')) {
    response = "I'm a simple SLOP server. Nice to meet you!";
  } else {
    response = `You said: "${message}". What else would you like to talk about?`;
  }
  
  res.json({ message: { role: 'assistant', content: response } });
});
```

Just update this part of your code, click "Run" again, and you'll have a slightly smarter chat interface!

## Congratulations!

You now have a working SLOP server with a public URL and a web interface that anyone can access! The URL is persistent as long as you keep your Replit account.

Replit automatically gives you a public URL for your server, making it incredibly easy to share your SLOP implementation with others without needing to understand deployment, hosting, or server management!

## Learn More About SLOP

To learn more about the SLOP protocol, visit the [SLOP GitHub repository](https://github.com/agnt-gg/slop).

----------------------
EXAMPLES\STREAMLIT\MAKEFILE
----------------------
# Makefile

# Variables
PYTHON = python3
FLASK_APP = slop_with_models.py
STREAMLIT_APP = streamlit_slop_with_models.py
VARS_FILE = vars.sh

# Default target
.PHONY: all
all: setup

# Setup virtual environment and install dependencies (optional)
.PHONY: setup
setup:
	$(PYTHON) -m venv venv
	./venv/bin/pip install --upgrade pip
	./venv/bin/pip install -r requirements.txt

# Run Flask server with environment variables
.PHONY: slop-flask
slop-flask:
	source $(VARS_FILE) && $(PYTHON) $(FLASK_APP)

# Run Streamlit app
.PHONY: slop-streamlit
slop-streamlit:
	./venv/bin/streamlit run $(STREAMLIT_APP)

# Clean up virtual environment
.PHONY: clean
clean:
	rm -rf venv

----------------------
EXAMPLES\STREAMLIT\README.MD
----------------------
# SLOP Streamlit Example

Streamlit-based SLOP example with dynamic model endpoints. It explains the purpose, setup, usage, and structure in a clear and concise way.

This is a Python implementation of the [SLOP pattern](https://github.com/agnt-gg/slop) using Flask as a backend server and Streamlit as a frontend interface. It dynamically discovers and utilizes language models from OpenAI-compatible endpoints (e.g., vLLM, Ollama, etc.) specified via environment variables.

## Features

- **Chat**: Send messages to dynamically discovered AI models.
- **Tools**: Use simple tools like a calculator and greeter.
- **Memory**: Store and retrieve key-value pairs.
- **Resources**: Access predefined static content.
- **Pay**: Simulate a payment transaction.

## Prerequisites

- Python 3.8+
- A terminal to run commands
- Optional: Access to OpenAI-compatible model endpoints (e.g., `https://hermes.ai.unturf.com/v1`)

## Setup

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/agnt-gg/slop
   cd slop/examples/streamlit
   ```

2. **Set Up Virtual Environment**:

   ```bash
   make setup
   ```
   This creates a virtual environment (`venv`) and installs dependencies from `requirements.txt`.

3. **Configure Model Endpoints**:
   Edit `vars.sh` to specify your model endpoints:

   ```bash
   # vars.sh
   export MODEL_ENDPOINT_0=https://hermes.ai.unturf.com/v1
   export MODEL_ENDPOINT_1=https://node2.naptha.ai/inference
   export MODEL_ENDPOINT_2=https://node3.naptha.ai/inference
   ```
   - Gaps in numbering (e.g., skipping `MODEL_ENDPOINT_1`) are supported.
   - API keys are optional; defaults to `"not-needed"` if unset (e.g., `export MODEL_API_KEY_0=your-key`).

## Usage

1. **Run the Flask Server**:
   Open a terminal and start the backend:

   ```bash
   make slop-flask
   ```
   - This sources `vars.sh` and runs `slop_with_models.py` on `http://localhost:31337`.
   - Logs will show model discovery (e.g., `Loaded models: [model1, endpoint_7:default]`).

2. **Run the Streamlit App**:
   Open a second terminal and start the frontend:

   ```bash
   make slop-streamlit
   ```
   - Opens in your browser at `http://localhost:8501`.
   - Displays a UI with Chat, Tools, Memory, Resources, and Pay sections.

3. **Interact**:
   - **Chat**: Select a model from the dropdown and send a message.
   - **Tools**: Use the calculator or greeter.
   - **Memory**: Store/retrieve values.
   - **Resources**: View static content.
   - **Pay**: Simulate a transaction.

4. **Clean Up** (optional):

   ```bash
   make clean
   ```
   Removes the virtual environment.

## Files

- **`slop_with_models.py`**: Flask server implementing the SLOP pattern with dynamic model discovery.
- **`streamlit_slop_with_models.py`**: Streamlit frontend for user interaction.
- **`Makefile`**: Simplifies ``make setup`` and running with ``make slop-flask`` and ``make slop-streamlit``.
- **`vars.sh`**: Environment variables for model endpoints. Feel free to start with ``vars.sh.sample``!
- **`requirements.txt`**: Dependencies

## How It Works

1. **Model Discovery**:
   - The Flask server scans `MODEL_ENDPOINT_0` to `MODEL_ENDPOINT_999` from `vars.sh`.
   - Queries each endpointâ€™s `/v1/models` using the OpenAI client.
   - Maps model IDs to their respective clients

2. **API Endpoints**:
   - `/models`: Returns the list of discovered models.
   - `/chat`: Handles chat completions with the selected model.
   - `/tools`, `/memory`, `/resources`, `/pay`: Implement SLOP pattern features.

3. **Frontend**:
   - Streamlit fetches the model list from `/models` and provides a dropdown.
   - Sends requests to Flask for chat and other functionalities.

## Troubleshooting

- **No Models in Dropdown**:
  - Check Flask logs (`make slop-flask`) for errors (e.g., `Failed to list models for endpoint_X`).
  - Test endpoints with `curl <endpoint>/v1/models` to ensure theyâ€™re OpenAI-compatible.
- **Server Not Responding**:
  - Ensure Flask is running (`make slop-flask`) before starting Streamlit.
- **Environment Variables**:
  - Verify `vars.sh` is correct and sourced (`source vars.sh; echo $MODEL_ENDPOINT_0`).

## Dependencies

Listed in `requirements.txt`:
- `flask`: Backend server
- `streamlit`: Frontend UI
- `openai`: Client for model endpoints
- `requests`: HTTP requests in Streamlit

## Learn More

- [SLOP Specification](https://github.com/agnt-gg/slop)

This example demonstrates a flexible, extensible SLOP implementation with a modern UI. Contributions and feedback are welcome!

---

This is research into the genesis of of the future https://slop.unturf.com/

The code in this example is Public Domain.

----------------------
EXAMPLES\STREAMLIT\REQUIREMENTS.TXT
----------------------
flask
streamlit
openai
requests
flask_swagger_ui

----------------------
EXAMPLES\STREAMLIT\SLOP_WITH_MODELS.PY
----------------------
# slop_with_models.py
from flask import Flask, request, jsonify
from datetime import datetime
import os
from openai import OpenAI
import logging
from flask_swagger_ui import get_swaggerui_blueprint

# Configure logging
logging.basicConfig(
    level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Swagger UI setup
SWAGGER_URL = "/openapi"  # URL for Swagger UI
API_URL = "/static/openapi.yaml"  # Path to the OpenAPI spec file
swaggerui_blueprint = get_swaggerui_blueprint(
    SWAGGER_URL, API_URL, config={"app_name": "SLOP API"}
)
app.register_blueprint(swaggerui_blueprint, url_prefix=SWAGGER_URL)

# Global model-to-client map and memory
MODEL_CLIENT_MAP = {}
memory = {}

# Load endpoints
ENDPOINTS = []
for i in range(1000):
    endpoint = os.getenv(f"MODEL_ENDPOINT_{i}")
    if endpoint:
        ENDPOINTS.append(
            {
                "name": f"endpoint_{i}",
                "base_url": endpoint,
                "api_key": os.getenv(f"MODEL_API_KEY_{i}", "not-needed"),
            }
        )


def initialize_model_map():
    MODEL_CLIENT_MAP.clear()
    logger.info("Initializing model map...")
    if not ENDPOINTS:
        logger.warning("No endpoints configured.")
        return
    for ep in ENDPOINTS:
        base_url = ep["base_url"]
        api_key = ep["api_key"]
        endpoint_name = ep["name"]
        logger.info(f"Querying endpoint: {endpoint_name} ({base_url})")
        client = OpenAI(base_url=base_url, api_key=api_key)
        try:
            response = client.models.list()
            model_list = response.data
            logger.debug(
                f"{endpoint_name} returned models: {[m.id for m in model_list]}"
            )
        except Exception as e:
            logger.error(
                f"Skipping, Failed to list models for {endpoint_name}: {str(e)}"
            )
            continue
        for m in model_list:
            model_id = m.id
            if model_id:
                if model_id in MODEL_CLIENT_MAP:
                    logger.warning(f"Duplicate model ID '{model_id}' found.")
                else:
                    MODEL_CLIENT_MAP[model_id] = client
                    logger.info(f"Added model '{model_id}'")
            else:
                logger.warning(f"Encountered model with no ID from {endpoint_name}")
    logger.info(f"Loaded models: {list(MODEL_CLIENT_MAP.keys())}")


# SLOP components
tools = {
    "calculator": {
        "id": "calculator",
        "description": "Basic math",
        "execute": lambda params: {"result": eval(params["expression"])},
    },
    "greet": {
        "id": "greet",
        "description": "Says hello",
        "execute": lambda params: {"result": f"Hello, {params['name']}!"},
    },
}
resources = {"hello": {"id": "hello", "content": "Hello, SLOP!"}}


# Endpoints
@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    message = data["messages"][0]["content"] if data.get("messages") else "nothing"
    model_id = data.get("model") or (
        list(MODEL_CLIENT_MAP.keys())[0] if MODEL_CLIENT_MAP else None
    )
    if not model_id or model_id not in MODEL_CLIENT_MAP:
        logger.error(f"Invalid or missing model_id: {model_id}")
        return jsonify({"error": "Model not found"}), 404
    client = MODEL_CLIENT_MAP[model_id]
    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in data.get("messages", [])
            ]
            or [{"role": "user", "content": message}],
        )
        logger.debug(
            f"Chat response for model {model_id}: {response.choices[0].message.content}"
        )
        return (
            jsonify(
                {
                    "choices": [
                        {"message": {"content": response.choices[0].message.content}}
                    ]
                }
            ),
            200,
        )
    except Exception as e:
        logger.error(f"Chat error with model {model_id}: {str(e)}")
        return jsonify({"error": str(e)}), 500


@app.route("/models", methods=["GET"])
def list_models():
    models = list(MODEL_CLIENT_MAP.keys())
    logger.debug(f"Returning models: {models}")
    return jsonify({"models": models}), 200


@app.route("/tools", methods=["GET"])
def list_tools():
    return (
        jsonify(
            {
                "tools": [
                    {"id": k, "description": v["description"]} for k, v in tools.items()
                ]
            }
        ),
        200,
    )


@app.route("/tools/<tool_id>", methods=["POST"])
def use_tool(tool_id):
    if tool_id not in tools:
        return jsonify({"error": "Tool not found"}), 404
    data = request.json or {}
    if tool_id == "calculator" and "expression" not in data:
        return jsonify({"error": "Missing 'expression'"}), 400
    if tool_id == "greet" and "name" not in data:
        return jsonify({"error": "Missing 'name'"}), 400
    result = tools[tool_id]["execute"](data)
    return jsonify(result), 200


@app.route("/memory", methods=["POST"])
def store_memory():
    data = request.json
    memory[data["key"]] = data["value"]
    return jsonify({"status": "stored"}), 200


@app.route("/memory/<key>", methods=["GET"])
def get_memory(key):
    return jsonify({"value": memory.get(key)}), 200


@app.route("/memory", methods=["GET"])
def list_memory():
    return jsonify({"keys": list(memory.keys())}), 200


@app.route("/memory/<key>", methods=["DELETE"])
def delete_memory(key):
    if key not in memory:
        return jsonify({"error": "Key not found"}), 404
    del memory[key]
    return jsonify({"status": "deleted"}), 200


@app.route("/resources", methods=["GET"])
def list_resources():
    return jsonify({"resources": list(resources.values())}), 200


@app.route("/resources/<resource_id>", methods=["GET"])
def get_resource(resource_id):
    if resource_id not in resources:
        return jsonify({"error": "Resource not found"}), 404
    return jsonify(resources[resource_id]), 200


@app.route("/pay", methods=["POST"])
def pay():
    return (
        jsonify(
            {
                "transaction_id": f"tx_{int(datetime.now().timestamp())}",
                "status": "success",
            }
        ),
        200,
    )


if __name__ == "__main__":
    initialize_model_map()
    app.run(debug=True, port=31337)

----------------------
EXAMPLES\STREAMLIT\STATIC\OPENAPI.YAML
----------------------
openapi: 3.0.0
info:
  title: SLOP API
  description: A SLOP pattern implementation with dynamic model endpoints
  version: 1.0.0
servers:
  - url: http://localhost:31337
    description: Local development server
paths:
  /chat:
    post:
      summary: Send a message to an AI model
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatRequest'
      responses:
        '200':
          description: Successful response with AI message
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatResponse'
        '404':
          description: Model not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /models:
    get:
      summary: List available models
      tags:
        - Models
      responses:
        '200':
          description: List of model IDs
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelsResponse'
  /tools:
    get:
      summary: List available tools
      tags:
        - Tools
      responses:
        '200':
          description: List of tools
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ToolsResponse'
  /tools/{tool_id}:
    post:
      summary: Use a specific tool
      tags:
        - Tools
      parameters:
        - name: tool_id
          in: path
          required: true
          schema:
            type: string
            enum: [calculator, greet]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ToolRequest'
      responses:
        '200':
          description: Tool execution result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ToolResponse'
        '400':
          description: Missing required parameter
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '404':
          description: Tool not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /memory:
    get:
      summary: List all memory keys
      tags:
        - Memory
      responses:
        '200':
          description: List of memory keys
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryListResponse'
    post:
      summary: Store a key-value pair
      tags:
        - Memory
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/MemoryStoreRequest'
      responses:
        '200':
          description: Successfully stored
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryStoreResponse'
  /memory/{key}:
    get:
      summary: Retrieve a value by key
      tags:
        - Memory
      parameters:
        - name: key
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Retrieved value
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryGetResponse'
    delete:
      summary: Delete a memory key
      tags:
        - Memory
      parameters:
        - name: key
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successfully deleted
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MemoryStoreResponse'
        '404':
          description: Key not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /resources:
    get:
      summary: List available resources
      tags:
        - Resources
      responses:
        '200':
          description: List of resources
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResourcesResponse'
  /resources/{resource_id}:
    get:
      summary: Get a specific resource
      tags:
        - Resources
      parameters:
        - name: resource_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Resource content
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResourceResponse'
        '404':
          description: Resource not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
  /pay:
    post:
      summary: Simulate a payment
      tags:
        - Pay
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/PayRequest'
      responses:
        '200':
          description: Payment simulation result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PayResponse'
components:
  schemas:
    ChatRequest:
      type: object
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/Message'
        model:
          type: string
          nullable: true
      required:
        - messages
    Message:
      type: object
      properties:
        role:
          type: string
          enum: [user, assistant, system]
        content:
          type: string
      required:
        - role
        - content
    ChatResponse:
      type: object
      properties:
        choices:
          type: array
          items:
            type: object
            properties:
              message:
                type: object
                properties:
                  content:
                    type: string
            required:
              - message
      required:
        - choices
    ModelsResponse:
      type: object
      properties:
        models:
          type: array
          items:
            type: string
      required:
        - models
    ToolsResponse:
      type: object
      properties:
        tools:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
              description:
                type: string
            required:
              - id
              - description
      required:
        - tools
    ToolRequest:
      type: object
      properties:
        expression:
          type: string
          nullable: true
        name:
          type: string
          nullable: true
    ToolResponse:
      type: object
      properties:
        result:
          oneOf:
            - type: string
            - type: integer
      required:
        - result
    MemoryStoreRequest:
      type: object
      properties:
        key:
          type: string
        value:
          type: string
      required:
        - key
        - value
    MemoryStoreResponse:
      type: object
      properties:
        status:
          type: string
          enum: [stored, deleted]
      required:
        - status
    MemoryGetResponse:
      type: object
      properties:
        value:
          type: string
          nullable: true
      required:
        - value
    MemoryListResponse:
      type: object
      properties:
        keys:
          type: array
          items:
            type: string
      required:
        - keys
    ResourcesResponse:
      type: object
      properties:
        resources:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
              content:
                type: string
            required:
              - id
              - content
      required:
        - resources
    ResourceResponse:
      type: object
      properties:
        id:
          type: string
        content:
          type: string
      required:
        - id
        - content
    PayRequest:
      type: object
      properties:
        amount:
          type: number
          format: float
      required:
        - amount
    PayResponse:
      type: object
      properties:
        transaction_id:
          type: string
        status:
          type: string
          enum: [success]
      required:
        - transaction_id
        - status
    ErrorResponse:
      type: object
      properties:
        error:
          type: string
      required:
        - error

----------------------
EXAMPLES\STREAMLIT\STREAMLIT_SLOP_WITH_MODELS.PY
----------------------
# streamlit_slop_with_models.py
import streamlit as st
import requests

BASE_URL = "http://localhost:31337"


def main():
    st.title("SLOP Streamlit with Dynamic Models")
    st.markdown(
        "[Explore API Documentation](http://localhost:31337/openapi/)",
        unsafe_allow_html=True,
    )
    page = st.sidebar.selectbox(
        "Choose a feature", ["Chat", "Tools", "Memory", "Resources", "Pay"]
    )
    if page == "Chat":
        chat_interface()
    elif page == "Tools":
        tools_interface()
    elif page == "Memory":
        memory_interface()
    elif page == "Resources":
        resources_interface()
    elif page == "Pay":
        pay_interface()


def chat_interface():
    st.header("Chat")

    try:
        response = requests.get(f"{BASE_URL}/models", timeout=5)
        response.raise_for_status()
        models = response.json()["models"]
    except requests.RequestException as e:
        st.warning(f"Could not fetch models: {str(e)}")
        models = []

    selected_model = st.selectbox(
        "Select Model", models if models else ["No models available"]
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for entry in st.session_state.chat_history:
        st.write(f"**User**: {entry['user']}")
        st.write(f"**Assistant**: {entry['assistant']}")

    with st.form(key="chat_form", clear_on_submit=True):
        message = st.text_area("Enter your message", height=100, key="chat_input")
        submit_button = st.form_submit_button(label="Submit", type="primary")

        st.markdown(
            """
            <script>
            const textarea = document.querySelector('textarea');
            textarea.addEventListener('keydown', function(event) {
                if (event.key === 'Enter' && !event.shiftKey) {
                    event.preventDefault();
                    document.querySelector('button[type="submit"]').click();
                }
            });
            </script>
        """,
            unsafe_allow_html=True,
        )

        if submit_button and message and models:
            try:
                response = requests.post(
                    f"{BASE_URL}/chat",
                    json={
                        "messages": [{"role": "user", "content": message}],
                        "model": selected_model,
                    },
                    timeout=5,
                )
                response.raise_for_status()
                assistant_response = response.json()["choices"][0]["message"]["content"]
                st.session_state.chat_history.append(
                    {"user": message, "assistant": assistant_response}
                )
                st.rerun()
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")


def tools_interface():
    st.header("Tools")
    try:
        response = requests.get(f"{BASE_URL}/tools", timeout=5)
        response.raise_for_status()
        tools = response.json()["tools"]
    except requests.RequestException as e:
        st.warning(f"Could not fetch tools: {str(e)}")
        tools = []

    if not tools:
        st.write("No tools available.")
        return

    tool_id = st.selectbox("Select a tool", [t["id"] for t in tools])

    if tool_id == "calculator":
        expression = st.text_input("Enter expression (e.g., 2 + 2)")
        if st.button("Calculate"):
            try:
                response = requests.post(
                    f"{BASE_URL}/tools/{tool_id}",
                    json={"expression": expression},
                    timeout=5,
                )
                response.raise_for_status()
                st.write(f"Result: {response.json()['result']}")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif tool_id == "greet":
        name = st.text_input("Enter name")
        if st.button("Greet"):
            try:
                response = requests.post(
                    f"{BASE_URL}/tools/{tool_id}", json={"name": name}, timeout=5
                )
                response.raise_for_status()
                st.write(response.json()["result"])
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")


def memory_interface():
    st.header("Memory")
    action = st.radio("Action", ["Store", "Retrieve", "List", "Delete"])

    if action == "Store":
        key = st.text_input("Key")
        value = st.text_input("Value")
        if st.button("Store"):
            try:
                response = requests.post(
                    f"{BASE_URL}/memory", json={"key": key, "value": value}, timeout=5
                )
                response.raise_for_status()
                st.success("Stored successfully!")
                list_response = requests.get(f"{BASE_URL}/memory", timeout=5)
                list_response.raise_for_status()
                keys = list_response.json()["keys"]
                st.write("Current Memory Keys:", ", ".join(keys) if keys else "None")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif action == "Retrieve":
        key = st.text_input("Key to retrieve")
        if st.button("Retrieve"):
            try:
                response = requests.get(f"{BASE_URL}/memory/{key}", timeout=5)
                response.raise_for_status()
                value = response.json()["value"]
                st.write(f"Value: {value if value is not None else 'Not found'}")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif action == "List":
        if st.button("List All Keys"):
            try:
                response = requests.get(f"{BASE_URL}/memory", timeout=5)
                response.raise_for_status()
                keys = response.json()["keys"]
                st.write("Memory Keys:", ", ".join(keys) if keys else "None")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")

    elif action == "Delete":
        key = st.text_input("Key to delete")
        if st.button("Delete"):
            try:
                response = requests.delete(f"{BASE_URL}/memory/{key}", timeout=5)
                response.raise_for_status()
                st.success("Deleted successfully!")
                list_response = requests.get(f"{BASE_URL}/memory", timeout=5)
                list_response.raise_for_status()
                keys = list_response.json()["keys"]
                st.write("Current Memory Keys:", ", ".join(keys) if keys else "None")
            except requests.RequestException as e:
                st.error(f"Error: {str(e)}")


def resources_interface():
    st.header("Resources")
    try:
        response = requests.get(f"{BASE_URL}/resources", timeout=5)
        response.raise_for_status()
        resources = response.json()["resources"]
    except requests.RequestException as e:
        st.warning(f"Could not fetch resources: {str(e)}")
        resources = []

    if not resources:
        st.write("No resources available.")
        return

    resource_id = st.selectbox("Select resource", [r["id"] for r in resources])
    if st.button("Get Resource"):
        try:
            response = requests.get(f"{BASE_URL}/resources/{resource_id}", timeout=5)
            response.raise_for_status()
            st.write(response.json().get("content", response.json()))
        except requests.RequestException as e:
            st.error(f"Error: {str(e)}")


def pay_interface():
    st.header("Pay")
    amount = st.number_input("Amount", min_value=0.0, step=0.01)
    if st.button("Pay"):
        try:
            response = requests.post(
                f"{BASE_URL}/pay", json={"amount": amount}, timeout=5
            )
            response.raise_for_status()
            st.write(f"Transaction ID: {response.json()['transaction_id']}")
            st.write(f"Status: {response.json()['status']}")
        except requests.RequestException as e:
            st.error(f"Error: {str(e)}")


if __name__ == "__main__":
    main()

----------------------
EXAMPLES\STREAMLIT\VARS.SH.EXAMPLE
----------------------
export MODEL_ENDPOINT_1=https://hermes.ai.unturf.com/v1
export MODEL_ENDPOINT_2=https://node2.naptha.ai/inference
export MODEL_ENDPOINT_3=https://node3.naptha.ai/inference

----------------------
EXAMPLES\TYPESCRIPT\DENO.JSON
----------------------
{
  "name": "@phughesmcr/slop",
  "version": "0.0.1",
  "license": "MIT",
  "exports": {
    ".": "./slop.ts",
    "./lib": "./lib/SlopManager.ts"
  },
  "bin": {
    "slop-server": "./local-server.ts"
  },
  "tasks": {
    "start:server": "deno run -A ./local-server.ts",
    "start:client": "deno run -A ./local-client.ts",
    "test:server": "deno test --allow-net ./lib/**/*.test.ts",
    "test": "deno task test:server",
    "precommit": "deno fmt && deno lint --fix && deno check ./slop.ts ./local-server.ts ./local-client.ts ./lib/**/*.ts"
  },
  "include": [
    "slop.ts",
    "local-client.ts",
    "local-server.ts",
    "lib/**/*.ts"
  ],
  "compilerOptions": {
    "strict": true,
    "allowUnreachableCode": false,
    "allowUnusedLabels": false,
    "noImplicitAny": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noImplicitThis": true,
    "noPropertyAccessFromIndexSignature": true,
    "noUncheckedIndexedAccess": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "strictPropertyInitialization": true,
    "strictBindCallApply": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true
  },
  "fmt": {
    "lineWidth": 99,
    "exclude": [
      "**/*.md"
    ]
  },
  "lint": {
    "rules": {
      "tags": [
        "recommended"
      ],
      "exclude": [
        "no-explicit-any"
      ]
    }
  },
  "lock": false
}

----------------------
EXAMPLES\TYPESCRIPT\DOCS\SCOPE_PERMISSIONS.MD
----------------------
# SLOP Enhanced Scope Permission System

The SLOP (Simple Language Open Protocol) framework includes a powerful and flexible permission system based on scopes. This document explains how the enhanced scope system works, including wildcard support and permission hierarchies.

## Basic Concepts

- **Scopes** are strings that define permissions in a hierarchical format
- Format: `resource.identifier.permission`
- Provided in the `X-SLOP-SCOPE` header as a comma-separated list
- Example: `chat.read,tools.calculator.execute,memory.user_preferences.write`

## Resource Types

The SLOP pattern defines five core resource types:

1. **chat** - Messaging and conversation management
2. **tools** - External functionality and integrations
3. **memory** - Key-value storage
4. **resources** - Knowledge and data resources
5. **pay** - Payment processing

## Permission Types

Each resource supports specific permission types:

| Resource Type | Available Permissions |
|---------------|------------------------|
| chat          | read, write            |
| tools         | execute, read, list    |
| memory        | read, write            |
| resources     | read, list             |
| pay           | execute, read          |

## Wildcard Support

The enhanced scope system supports wildcards at different levels:

1. **Top-level wildcards**: `resource.*`
   - Grants all permissions for that resource type
   - Example: `chat.*` grants full access to all chat operations

2. **Resource-specific wildcards**: `resource.identifier.*`
   - Grants all permissions for a specific resource
   - Example: `chat.thread_123.*` grants full access to a specific thread

## Permission Hierarchies

The scope system supports permission inheritance:

1. **Global type permissions**
   - Example: `chat.read` grants read access to all chats
   - This means you don't need to specify `chat.123.read`, `chat.456.read`, etc.

2. **Resource-specific permissions**
   - Example: `tools.calculator.execute` grants execute permission only for the calculator tool

## Special Tools.Safe System

For tools, there's a special "safe" category:

1. **Safe tool designation**
   - Tools can be marked as "safe" to indicate they're low-risk
   - Access can be granted via: `tools.safe.*` or `tools.safe.toolname`

2. **Access paths for tools**
   - A tool can be accessed with any of these permissions:
     - `tools.*` (full access to all tools)
     - `tools.toolname.execute` (specific permission)
     - `tools.safe.*` (if the tool is marked as safe)
     - `tools.safe.toolname` (specific safe tool)

## Usage Examples

Here are some common patterns:

```bash
# Minimal scope for basic read-only access
chat.read,tools.safe.*,memory..read,resources.list.read

# Full access to everything
chat.*,tools.*,memory.*,resources.*,pay.*

# Access to specific resources
chat.thread_abc.read,tools.calculator.execute,memory.user_preferences.write
```

## Handling a Tool Named "Safe"

The enhanced scope system handles tools with potentially conflicting names:

- If a tool is named "safe", it's treated as any other tool ID
- `tools.safe.execute` grants permission to execute the "safe" tool
- `tools.safe.*` grants permission to all tools marked as safe (category)

The system distinguishes between these cases by context and hierarchy.

## Testing Scopes

You can run the scope tests to see examples of how different permissions work:

```bash
deno test lib/tests/ScopeManager.test.ts
```

----------------------
EXAMPLES\TYPESCRIPT\LOCAL-CLIENT.TS
----------------------

----------------------
EXAMPLES\TYPESCRIPT\LOCAL-SERVER.TS
----------------------
#!/usr/bin/env -S deno run -allow-net

/**
 * @module SLOP-TS STANDALONE SERVER
 * @description A standalone Typescript server implementation of the SLOP pattern
 * @author {SLOP-TS} P. Hughes <https://github.com/phughesmcr>
 * @author {SLOP} agnt-gg <https://github.com/agnt-gg>
 * @see https://github.com/agnt-gg/slop
 * @version 0.0.1
 * @license MIT
 * @requires Deno
 *
 * For the SLOP specification, see `./slop.ts`
 *
 * @arg --hostname "<string>" The hostname to listen on (default: localhost)
 * @arg --port <number> The port to listen on (default: 31337)
 * @arg --timeout <number> The timeout in seconds (default: 0)
 */

import { SlopManager } from "./lib/SlopManager.ts";
import type { Resource, Tool } from "./slop.ts";

const exampleTools: Record<string, Tool> = {
  calculator: {
    id: "calculator",
    description: "Performs mathematical calculations",
    example: "Calculate 2 + 2",
    parameters: {
      expression: {
        type: "string",
        description: "The mathematical expression to evaluate (e.g., '2 + 2', '5 * 10')",
      },
    },
    execute: (params: Record<string, unknown>) => {
      // Type check the expression parameter
      const expression = params["expression"];
      if (typeof expression !== "string") {
        throw new Error("Expression must be a string");
      }
      // Safely evaluate the expression (in a real implementation, this would use a safer evaluation method)
      try {
        const result = Function('"use strict";return (' + expression + ")")();
        return { result };
      } catch {
        return { error: "Invalid expression" };
      }
    },
  },
  weather: {
    id: "weather",
    description: "Gets simulated weather information",
    example: "What's the weather in New York?",
    parameters: {
      location: {
        type: "string",
        description: "The location to get weather for (e.g., 'New York', 'London')",
      },
    },
    execute: (params: Record<string, unknown>) => {
      const location = params["location"];
      if (typeof location !== "string") {
        throw new Error("Location must be a string");
      }
      const conditions = ["sunny", "cloudy", "rainy", "snowy"];
      const randomCondition = conditions[Math.floor(Math.random() * conditions.length)];
      const randomTemp = Math.floor(Math.random() * 30) + 5; // 5 to 35 degrees

      return {
        result: {
          location,
          condition: randomCondition,
          temperature: randomTemp,
          units: "celsius",
        },
      };
    },
  },
};

const exampleResources: Record<string, Resource> = {
  "mars-101": {
    id: "mars-101",
    type: "article",
    content:
      "Mars is the fourth planet from the Sun and the second-smallest planet in the Solar System.",
  },
  "solar-system": {
    id: "solar-system",
    type: "article",
    content:
      "The Solar System consists of the Sun and the objects that orbit it, either directly or indirectly.",
  },
};

/**
 * Parse command line arguments with proper type handling
 * @param name The name of the argument (without --)
 * @param defaultValue The default value to use if the argument is not provided
 * @param args The array of command line arguments
 * @returns The parsed value with the same type as defaultValue (string or number)
 */
function parseArg(
  name: string,
  defaultValue: string,
  args: string[],
): string;
function parseArg(
  name: string,
  defaultValue: number,
  args: string[],
): number;
function parseArg(
  name: string,
  defaultValue: string | number,
  args: string[],
): string | number {
  const index = args.indexOf(`--${name}`);
  if (index >= 0 && index < args.length - 1) {
    const argValue = args[index + 1];
    if (typeof defaultValue === "number") {
      const parsedValue = parseInt(argValue ?? "", 10);
      return Number.isNaN(parsedValue) ? defaultValue : parsedValue;
    } else {
      return argValue ?? defaultValue;
    }
  }
  return defaultValue;
}

/**
 * Create and start the SLOP server
 * @returns A server instance and a shutdown function
 */
export function createServer(hostname: string, port: number): {
  server: ReturnType<typeof Deno.serve>;
  shutdown: () => Promise<void>;
} {
  // Create and configure the SLOP server
  const slopManager = new SlopManager();

  // Register example tools
  for (const tool of Object.values(exampleTools)) {
    slopManager.tools.registerTool(tool as Tool);
  }

  // Register example resources
  for (const resource of Object.values(exampleResources)) {
    slopManager.resources.registerResource(resource as Resource, {
      source: "system",
      last_updated: new Date().toISOString(),
    });
  }

  // Use the integrated handler from SlopServer which automatically detects
  // HTTP requests, SSE streams, and WebSocket connections
  const controller = new AbortController();
  const signal = controller.signal;

  // Start the server
  const server = Deno.serve({ hostname, port, signal }, (req) => slopManager.handler(req));

  console.log(`Listening on http://${hostname}:${port}/`);

  return {
    server,
    shutdown: () => {
      controller.abort();
      return server.finished;
    },
  };
}

// If the file is run directly, start the server
if (import.meta.main) {
  try {
    // Parse command line arguments
    const args = Deno.args;
    const hostname = parseArg("hostname", "localhost", args);
    const port = parseArg("port", 31337, args);
    const timeout = parseArg("timeout", 0, args);

    // Create and start the server
    const { server, shutdown } = createServer(hostname, port);
    console.log(`âœ¨ SLOP server running on http://${hostname}:${port}\n`);
    console.log(`Available endpoints:`);
    // chat endpoints
    console.log(`- POST /chat - Send messages to AI`);
    console.log(`- POST /chat/stream - Stream responses (SSE)`);
    console.log(`- POST /chat/ws - Stream responses (WebSocket)`);
    console.log(`- GET /chat/:id - Get a specific chat`);
    console.log(`- GET /chat/thread_:id - Get all messages in a thread`);
    console.log(`- GET /chat - List recent chats`);
    console.log(`- GET /chat?type=threads - List all threads`);
    // tools endpoints
    console.log(`- GET /tools - List available tools`);
    console.log(`- GET /tools/:tool_id - Get tool details`);
    console.log(`- POST /tools/:tool_id - Use a specific tool`);
    // memory endpoints
    console.log(`- POST /memory - Store a key-value pair`);
    console.log(`- GET /memory/:key - Get value by key`);
    console.log(`- GET /memory - List all keys`);
    console.log(`- PUT /memory/:key - Update existing value`);
    console.log(`- DELETE /memory/:key - Delete a key-value pair`);
    console.log(`- POST /memory/query - Search with semantic query`);
    // resources endpoints
    console.log(`- GET /resources - List available resources`);
    console.log(`- GET /resources/:id - Get a specific resource`);
    console.log(`- GET /resources/search?q=query - Search resources`);
    // pay endpoints
    console.log(`- POST /pay - Create a payment`);
    console.log(`- GET /pay/:id - Get payment status`);

    // Set up signal handlers for graceful shutdown
    const handleSignal = async () => {
      console.log("Shutting down server...");
      await shutdown();
      console.log(`âœ¨ SLOP server closed on http://${hostname}:${port}`);
      Deno.exit(0);
    };

    // Handle SIGINT (Ctrl+C) and SIGBREAK (Ctrl+Break)
    Deno.addSignalListener("SIGINT", handleSignal);
    Deno.addSignalListener("SIGBREAK", handleSignal);

    // If timeout is specified, shut down after the timeout
    if (timeout > 0) {
      console.log(`Server will automatically shut down after ${timeout} seconds`);
      setTimeout(async () => {
        console.log(`Timeout of ${timeout} seconds reached, shutting down...`);
        await shutdown();
        console.log(`âœ¨ SLOP server closed on http://${hostname}:${port}`);
        Deno.exit(0);
      }, timeout * 1000);
    }

    // Wait for the server to finish (will only happen if shutdown is called)
    await server.finished;
  } catch (error) {
    console.error("Server runtime error:", error);
    Deno.exit(1);
  }
}

----------------------
EXAMPLES\TYPESCRIPT\README.MD
----------------------
# SLOP-TS (WIP)

An implementation of the [SLOP](https://github.com/agnt-gg/slop) pattern.

- `slop.ts` is pure TS and can be used in any Typescript project (Node, Deno, Bun, etc.)
- `lib/SlopManager.ts` exposes a `SlopManager` class which can be used to build your own SLOP tools.
- `local-client.ts` is an example client. This requires Deno.
- `local-server.ts` is an example server. This requires Deno.

## Quick Start

```bash
# Install Deno
curl -fsSL https://deno.land/install.sh | sh
# or `brew install deno`, or `npm install -g deno`

# Clone the repo
git clone https://github.com/agnt-gg/slop
cd slop/examples/typescript

# Start the server
deno task start:server

# Start the client (for example purposes)
deno task start:client

# Hostname and port can be supplied too:
deno task start:server --hostname "127.0.0.1" --port 31337
deno task start:client --hostname "localhost" --port 1234
```

## Developing

```typescript
import type * as SLOP from "./slop.ts";
import { SlopManager } from "./lib/SlopManager.ts";

// or:
// Run `deno add jsr:@phughesmcr/slop`
// import type * as SLOP from "@phughesmcr/slop";
// import { SlopManager } from "@phughesmcr/slop/server";

const slopManager = new SlopManager();

/**
 * Under the hood SlopManager handles:
 * - HTTP requests
 * - SSE streams
 * - WebSocket connection
 */
Deno.serve((req) => slopManager.handler(req));

// You can manipulate the server directly too, e.g.:
slopManager.memory.clear();
```

## Dependencies

| Files | Dependencies |
| --- | --- |
| `slop.ts` &amp; `SlopManager`| None |
| Local examples | Deno |
| Tests | [Deno's standard library](https://jsr.io/@std/) |

## Learn More

Check out the [main SLOP repository](https://github.com/agnt-gg/slop) for:

- Full specification
- Other language examples
- Core concepts
- Best practices

Remember: SLOP is just a pattern.

----------------------
EXAMPLES\TYPESCRIPT\SLOP.TS
----------------------
/**
 * @module SLOP-TS
 * @description A TypeScript implementation of the SLOP (Simple Language Open Protocol) pattern
 *
 * SLOP is a simple, open pattern for AI APIs with standardized endpoints:
 * - Standard REST API with JSON data
 * - Core endpoints: /chat, /tools, /memory, /resources, /pay
 * - Support for streaming via SSE and WebSockets
 * - Scope-based permission system for security
 *
 * This module provides TypeScript type definitions and constants for implementing
 * SLOP-compatible clients and servers.
 *
 * @author {SLOP-TS} P. Hughes <https://github.com/phughesmcr>
 * @author {SLOP} agnt-gg <https://github.com/agnt-gg>
 * @see https://github.com/agnt-gg/slop
 * @version 0.0.1
 * @license MIT
 *
 * For an example server implementation, see `./local-server.ts`
 * For an example client implementation, see `./local-client.ts`
 */

//#region CONSTANTS

/**
 * Standard HTTP status codes used in SLOP responses
 *
 * These status codes follow standard HTTP conventions and are used
 * to provide consistent error reporting across SLOP implementations.
 */
export const STATUS_CODES = {
  /** 200: Success */
  "OK": 200,
  /** 400: Invalid request format or parameters */
  "BAD_REQUEST": 400,
  /** 401: Authentication required */
  "UNAUTHORIZED": 401,
  /** 403: Valid authentication but insufficient permissions */
  "FORBIDDEN": 403,
  /** 404: Resource not found */
  "NOT_FOUND": 404,
  /** 429: Rate limit exceeded */
  "TOO_MANY_REQUESTS": 429,
  /** 500: Server encountered an error */
  "INTERNAL_SERVER_ERROR": 500,
} as const;

/**
 * Standard HTTP status codes used in SLOP responses
 *
 * These status codes follow standard HTTP conventions and are used
 * to provide consistent error reporting across SLOP implementations.
 */
export const STATUS_ERRORS = {
  200: "OK",
  400: "BAD_REQUEST",
  401: "UNAUTHORIZED",
  403: "FORBIDDEN",
  404: "NOT_FOUND",
  429: "TOO_MANY_REQUESTS",
  500: "INTERNAL_SERVER_ERROR",
} as const;

/**
 * Standard HTTP header key for SLOP scope permissions
 *
 * This header is used to pass permission scopes with requests,
 * allowing fine-grained control over API access.
 *
 * Example: `X-SLOP-SCOPE: chat.read,tools.calculator.execute`
 */
export const SCOPE_KEY = "X-SLOP-SCOPE" as const;

//#endregion

//#region ERRORS

/**
 * Standard SLOP error object structure
 *
 * This type defines the standard format for error objects returned
 * by SLOP endpoints when an error occurs.
 */
export type SlopError = {
  /** Machine-readable error code (e.g., "NOT_FOUND", "INVALID_PARAMETER") */
  code: string;
  /** Human-readable error message */
  message: string;
  /** The HTTP status code associated with this error */
  status: number;
};

/**
 * Standard API error response envelope
 *
 * This interface defines the JSON structure for error responses
 * returned by SLOP endpoints.
 *
 * @example
 * ```json
 * {
 *   "error": {
 *     "code": "INVALID_REQUEST",
 *     "message": "The 'messages' field is required",
 *     "status": 400
 *   }
 * }
 * ```
 */
export interface ErrorResponse {
  error: SlopError;
}

/**
 * Specialized error response for scope permission violations
 *
 * This interface defines the JSON structure returned when a
 * request is made without the required scope permissions.
 *
 * @example
 * ```json
 * {
 *   "error": "Scope violation: tools.system.execute requires explicit permission",
 *   "permitted": false
 * }
 * ```
 */
export interface ScopeErrorResponse {
  /** Human-readable error message explaining the scope violation */
  error: string;
  /** Always false, indicating the request was not permitted due to scope restrictions */
  permitted: false;
}

//#endregion

//#region CHAT

/**
 * A unique identifier for a chat conversation
 *
 * In SLOP, chat IDs follow a standardized format with the 'chat_' prefix
 * followed by a unique string (typically a UUID or similar).
 *
 * @example 'chat_123456789abcdef'
 */
export type ChatId = `chat_${string}`;

/**
 * A unique identifier for a chat message
 *
 * In SLOP, message IDs follow a standardized format with the 'msg_' prefix
 * followed by a unique string (typically a UUID or similar).
 *
 * @example 'msg_123456789abcdef'
 */
export type MessageId = `msg_${string}`;

/**
 * A unique identifier for a chat thread
 *
 * In SLOP, thread IDs follow a standardized format with the 'thread_' prefix
 * followed by a unique string (typically a UUID or similar).
 *
 * @example 'thread_123456789abcdef'
 */
export type ThreadId = `thread_${string}`;

/**
 * URL parameters for GET /chat/:id endpoint
 *
 * Used when retrieving a specific chat by its ID.
 */
export interface ChatGetParams {
  /** The unique identifier of the chat to retrieve */
  id: ChatId;
}

/**
 * URL parameters for GET /chat/thread_:id endpoint
 *
 * Used when retrieving all messages in a specific thread.
 */
export interface ChatThreadGetParams {
  /** The unique identifier of the thread to retrieve */
  id: ThreadId;
}

/**
 * Query parameters for GET /chat endpoint
 *
 * Used to filter the list of chats, for example to retrieve threads instead.
 *
 * @example GET /chat?type=threads
 */
export interface ChatListParams {
  /** When set to "threads", returns a list of threads instead of individual chats */
  type?: "threads";
}

/**
 * Standard chat message roles
 *
 * These roles are compatible with OpenAI-style chat APIs and define
 * the sender of each message in a conversation.
 */
export type ChatCompletionRole =
  /** System instructions or context */
  | "system"
  /** End-user message */
  | "user"
  /** AI assistant response */
  | "assistant"
  /** Message from a developer or administrator */
  | "developer"
  /** Message from a tool or function call */
  | "tool"
  /** Output from a function execution */
  | "function";

/**
 * Standard chat message structure
 *
 * Represents a single message in a chat conversation, compatible with
 * OpenAI-style chat APIs.
 *
 * @example
 * ```json
 * {
 *   "role": "user",
 *   "content": "Hello, what's the weather like today?"
 * }
 * ```
 */
/**
 * Individual content block in a message
 *
 * A content block can be text, image, file, or other media type
 */
export interface ChatContentBlock {
  /** Type of content block */
  type: "text" | "image" | "file" | "code" | "table" | "data" | string;
  /** Text content (for text blocks) */
  text?: string;
  /** Image URL or base64 data (for image blocks) */
  image_url?: string;
  /** File URL or base64 data (for file blocks) */
  file_url?: string;
  /** MIME type of the content */
  mime_type?: string;
  /** Additional attributes for this content block */
  attributes?: Record<string, unknown>;
}

/**
 * Content of a chat message
 *
 * Can be a string, an object with text property, or an array of content blocks
 */
export type MessageContent =
  | string
  | { text: string }
  | { type: string; text?: string; [key: string]: unknown }
  | ChatContentBlock
  | ChatContentBlock[];

export interface ChatMessage {
  /** The role of the message sender */
  role: ChatCompletionRole;
  /**
   * The content of the message, which can be a string or a structured content object
   */
  content: MessageContent;
  /** Optional name identifier for the sender, for OpenAI-type API compatibility */
  name?: string;
}

/**
 * Chat message with additional metadata
 *
 * Extends the basic ChatMessage with server-added metadata like unique ID
 * and creation timestamp. Used in responses that include message history.
 */
export interface ChatMessageWithMetadata extends ChatMessage {
  /** Unique identifier for this specific message */
  id: string;
  /** ISO 8601 timestamp indicating when the message was created */
  created_at: string;
}

/**
 * Chat metadata for list responses
 *
 * Provides a summary of a chat conversation for list views, without
 * including the full message content.
 */
export interface ChatMetadata {
  /** Unique identifier for the chat */
  id: ChatId;
  /** A short preview of the chat content */
  snippet: string;
  /** ISO 8601 timestamp indicating when the chat was created */
  created_at: string;
}

/**
 * Response for GET /chat endpoint
 *
 * Returns a list of recent chat conversations with summary information.
 *
 * @example
 * ```json
 * {
 *   "chats": [
 *     {
 *       "id": "chat_123",
 *       "snippet": "Hello, what's the weather like?",
 *       "created_at": "2023-05-15T10:30:00Z"
 *     }
 *   ]
 * }
 * ```
 */
export interface ChatListResponse {
  /** Array of chat metadata summaries */
  chats: ChatMetadata[];
}

/**
 * Request for POST /chat endpoint
 *
 * Used to send messages to the AI and receive responses.
 *
 * @example
 * ```json
 * {
 *   "messages": [
 *     {"role": "user", "content": "Hello, what's the weather like?"}
 *   ],
 *   "model": "gpt-4"
 * }
 * ```
 */
export interface ChatPostRequest {
  /** Array of messages in the conversation */
  messages: ChatMessage[];
  /** The AI model to use for generating the response */
  model?: string;
  /**
   * Optional thread identifier. If provided, the message will be added to an existing thread
   * or create a new thread with this ID.
   */
  thread_id?: ThreadId;
}

/**
 * Request for POST /chat/stream endpoint
 *
 * Used to request streaming responses from the AI, with responses
 * delivered token-by-token via Server-Sent Events (SSE).
 */
export interface ChatPostStreamRequest extends ChatPostRequest {
  /** Must be set to true to enable streaming */
  stream: true;
}

/**
 * Single token response for streaming
 *
 * Represents a single token in a streaming response.
 */
export interface ChatStreamToken {
  /** The text content of this token */
  content: string;
}

/**
 * Standard streaming response format
 *
 * Used for both SSE and WebSocket streaming responses. During streaming,
 * most responses will only contain the content field, with the ID fields
 * potentially included only in the initial or final messages.
 */
export interface ChatStreamResponse {
  /** Optional chat ID, may only be included in initial or final response */
  id?: ChatId;
  /** Optional thread ID, may only be included in initial or final response */
  thread_id?: ThreadId;
  /** The text content of this token */
  content: string;
}

/**
 * Streaming completion status
 *
 * Indicates that a streaming response has completed. The format varies
 * slightly between SSE (which uses "[DONE]") and WebSocket (which uses
 * a status object).
 */
export interface ChatStreamComplete {
  /**
   * Status indicator:
   * - "complete" is used for WebSocket streams
   * - "done" is used conceptually for SSE, though typically sent as "[DONE]"
   */
  status: "complete" | "done";
}

/**
 * Base response format for chat requests
 *
 * Contains the common fields returned by the POST /chat endpoint.
 */
interface ChatPostResponseBase {
  /** The AI model's response message */
  message: ChatMessage;
}

/**
 * Response for POST /chat (without thread_id)
 *
 * Returned when a new standalone chat is created.
 *
 * @example
 * ```json
 * {
 *   "id": "chat_123",
 *   "message": {
 *     "role": "assistant",
 *     "content": "I don't have real-time weather data."
 *   }
 * }
 * ```
 */
export interface ChatPostResponse extends ChatPostResponseBase {
  /** Unique identifier for the newly created chat */
  id: ChatId;
}

/**
 * Response for GET /chat/:id
 *
 * Returns a complete chat conversation including all messages.
 *
 * @example
 * ```json
 * {
 *   "id": "chat_123",
 *   "messages": [
 *     {"role": "user", "content": "Hello, what's the weather like?"},
 *     {"role": "assistant", "content": "I don't have real-time weather data."}
 *   ],
 *   "created_at": "2023-05-15T10:30:00Z",
 *   "model": "gpt-4"
 * }
 * ```
 */
export interface ChatGetByIdResponse extends ChatPostResponse {
  /** Complete message history for this chat */
  messages: ChatMessageWithMetadata[];
  /** ISO 8601 timestamp of when the chat was created */
  created_at: string;
  /** The AI model used for this chat */
  model: string;
}

/**
 * Response for POST /chat (with thread_id)
 *
 * Returned when a message is added to an existing thread or a new thread is created.
 *
 * @example
 * ```json
 * {
 *   "thread_id": "thread_123",
 *   "message": {
 *     "role": "assistant",
 *     "content": "How can I help you with the project?"
 *   }
 * }
 * ```
 */
export interface ChatPostThreadResponse extends ChatPostResponseBase {
  /** Identifier for the thread this message was added to */
  thread_id: ThreadId;
}

/**
 * Thread summary information
 *
 * Used in list responses to provide an overview of available threads.
 */
export interface ChatThread {
  /** Unique identifier for this thread */
  id: ThreadId;
  /** Human-readable title for the thread, typically derived from the first message */
  title: string;
  /** Preview of the most recent message in the thread */
  last_message: string;
  /** ISO 8601 timestamp of when the thread was created */
  created_at: string;
  /** ISO 8601 timestamp of when the thread was last updated */
  updated_at: string;
}

/**
 * Response for GET /chat?type=threads
 *
 * Returns a list of available conversation threads.
 *
 * @example
 * ```json
 * {
 *   "threads": [
 *     {
 *       "id": "thread_123",
 *       "title": "Project Planning",
 *       "last_message": "What's our next milestone?",
 *       "created_at": "2023-05-15T10:30:00Z",
 *       "updated_at": "2023-05-15T11:45:00Z"
 *     }
 *   ]
 * }
 * ```
 */
export interface ChatThreadListResponse {
  /** Array of thread summaries */
  threads: ChatThread[];
}

/**
 * Response for GET /chat/thread_:id
 *
 * Returns the complete message history for a specific thread.
 *
 * @example
 * ```json
 * {
 *   "thread_id": "thread_123",
 *   "title": "Project Planning",
 *   "messages": [
 *     {"role": "user", "content": "Let's discuss project planning"},
 *     {"role": "assistant", "content": "Sure, what aspects of the project would you like to plan?"}
 *   ],
 *   "model": "gpt-4",
 *   "created_at": "2023-05-15T10:30:00Z",
 *   "updated_at": "2023-05-15T11:45:00Z"
 * }
 * ```
 */
export interface ChatThreadResponse {
  /** Unique identifier for this thread */
  thread_id: ThreadId;
  /** Human-readable title for the thread */
  title: string;
  /** Complete message history for this thread */
  messages: ChatMessageWithMetadata[];
  /** The AI model used for this thread */
  model: string;
  /** ISO 8601 timestamp of when the thread was created */
  created_at: string;
  /** ISO 8601 timestamp of when the thread was last updated */
  updated_at: string;
}

//#endregion

//#region TOOLS

/**
 * A functional tool that can be used in the SLOP pattern
 *
 * Tools provide capabilities for AI assistants to interact with external
 * systems and perform actions on behalf of users.
 */
export interface Tool {
  /** Unique identifier for the tool */
  id: string;
  /** Human-readable description of what the tool does */
  description: string;
  /** Example usage of the tool */
  example?: string;
  /** Parameter definitions for the tool */
  parameters?: Record<string, ToolParameter>;
  /**
   * Function that executes the tool's functionality
   * @param params The parameters passed to the tool
   * @returns Result of the tool execution
   */
  execute: (
    params: Record<string, unknown>,
  ) => Record<string, unknown> | Promise<Record<string, unknown>>;
}

/**
 * URL parameters for GET /tools/:tool_id endpoint
 *
 * Used when retrieving information about a specific tool.
 */
export interface ToolGetParams {
  /** The unique identifier of the tool to retrieve */
  tool_id: string;
}

/**
 * Tool parameter schema definition
 *
 * Defines a single parameter for a tool. Includes type information,
 * validation rules, and description. Compatible with JSON Schema.
 */
export interface ToolParameter {
  /** The expected data type of this parameter */
  type: "string" | "number" | "boolean" | "object" | "array" | "null" | "integer";
  /** Human-readable description of the parameter */
  description: string;
  /** Whether the parameter is required */
  required?: boolean;
  /** Default value if parameter is not provided */
  default?: unknown;
  /** Whether null is an acceptable value */
  nullable?: boolean;

  // String-specific validations
  /** Minimum length for string values */
  minLength?: number;
  /** Maximum length for string values */
  maxLength?: number;
  /** Regular expression pattern for string validation */
  pattern?: string;
  /** Format hint (e.g., "email", "uri", "date-time") */
  format?: string;

  // Number-specific validations
  /** Minimum value for numeric parameters */
  minimum?: number;
  /** Maximum value for numeric parameters */
  maximum?: number;
  /** Whether the minimum value is exclusive */
  exclusiveMinimum?: boolean;
  /** Whether the maximum value is exclusive */
  exclusiveMaximum?: boolean;
  /** Multiple of value (e.g., 5 for multiples of 5) */
  multipleOf?: number;

  // Array-specific validations
  /** Schema for array items */
  items?: ToolParameter;
  /** Minimum number of items in array */
  minItems?: number;
  /** Maximum number of items in array */
  maxItems?: number;
  /** Whether array items must be unique */
  uniqueItems?: boolean;

  // Object-specific validations
  /** Schema for object properties */
  properties?: Record<string, ToolParameter>;
  /** Whether additional properties are allowed */
  additionalProperties?: boolean;
  /** Required properties for objects */
  requiredProperties?: string[];

  // Enum validations (for any type)
  /** List of allowed values */
  enum?: (string | number | boolean)[];
}

/**
 * Tool parameters schema definition
 *
 * Defines the expected parameters for a tool, including their types
 * and descriptions. Compatible with JSON Schema and OpenAI-style function calling.
 */
export type ToolParameters =
  | string // Simple string schema (for backward compatibility)
  | Record<string, ToolParameter>;

/**
 * Tool schema definition for API responses
 *
 * Provides a description of a tool and its expected parameters.
 * Used in responses to the GET /tools and GET /tools/:tool_id endpoints.
 *
 * @example
 * ```json
 * {
 *   "id": "calculator",
 *   "description": "Performs mathematical calculations",
 *   "parameters": {
 *     "expression": {
 *       "type": "string",
 *       "description": "Mathematical expression to evaluate"
 *     }
 *   },
 *   "example": "15 * 7"
 * }
 * ```
 */
export interface ToolSchema {
  /** Unique identifier for the tool */
  id: string;
  /** Human-readable description of what the tool does */
  description?: string;
  /** Schema for the parameters expected by this tool */
  parameters: ToolParameters;
  /** Example usage of the tool */
  example?: string;
}

/**
 * Response for GET /tools endpoint
 *
 * Returns a list of available tools and their schemas.
 *
 * @example
 * ```json
 * {
 *   "tools": [
 *     {
 *       "id": "calculator",
 *       "description": "Performs mathematical calculations",
 *       "parameters": {
 *         "expression": {
 *           "type": "string",
 *           "description": "Mathematical expression to evaluate"
 *         }
 *       }
 *     },
 *     {
 *       "id": "weather",
 *       "description": "Gets current weather",
 *       "parameters": {
 *         "location": {
 *           "type": "string",
 *           "description": "City or location name"
 *         }
 *       }
 *     }
 *   ]
 * }
 * ```
 */
export interface ToolListResponse {
  /** Array of available tools with their schemas */
  tools: ToolSchema[];
}

/**
 * Response for GET /tools/:tool_id endpoint
 *
 * Returns detailed schema information for a specific tool.
 */
export interface ToolResponse extends ToolSchema {}

/**
 * Request for POST /tools/:tool_id endpoint
 *
 * Generic type for tool execution requests. The actual parameters
 * will depend on the specific tool being executed.
 *
 * @example
 * ```json
 * // For calculator tool
 * {
 *   "expression": "15 * 7"
 * }
 * ```
 */
export type ToolExecuteRequest<T extends Record<string, unknown>> = {
  [K in keyof T]: T[K];
};

/**
 * Response for POST /tools/:tool_id endpoint
 *
 * Contains the result of executing a tool. The actual structure
 * of the result depends on the specific tool that was executed.
 *
 * @example
 * ```json
 * {
 *   "result": 105
 * }
 * ```
 */
export interface ToolExecuteResponse {
  /** Result returned by the tool execution */
  result: unknown;
}

//#endregion

//#region MEMORY

/**
 * Status codes for memory operations
 *
 * These status codes indicate the result of operations on memory entries.
 */
export type MemoryResponseStatus =
  /** Entry was successfully created */
  | "stored"
  /** Existing entry was successfully modified */
  | "updated"
  /** Entry was successfully removed */
  | "deleted";

/**
 * Allowed value types for memory storage
 *
 * Memory values can be primitive types or structured objects.
 */
export type MemoryValue =
  | string
  | number
  | boolean
  | null
  | Record<string, unknown>
  | unknown[];

/**
 * Request for POST /memory endpoint
 *
 * Used to store a new key-value pair in memory.
 *
 * @example
 * ```json
 * {
 *   "key": "user_preference",
 *   "value": {
 *     "theme": "dark",
 *     "language": "en"
 *   }
 * }
 * ```
 */
export interface MemoryPostRequest {
  /** The unique key to store the value under */
  key: string;
  /** The value to be stored */
  value: MemoryValue;
}

/**
 * Response for POST /memory endpoint
 *
 * Confirms that a value was successfully stored in memory.
 *
 * @example
 * ```json
 * {
 *   "status": "stored"
 * }
 * ```
 */
export interface MemoryStoreResponse {
  /** Indicates the operation completed successfully */
  status: "stored";
}

/**
 * Response for GET /memory endpoint
 *
 * Returns a list of all keys stored in memory with their creation timestamps.
 *
 * @example
 * ```json
 * {
 *   "keys": [
 *     {
 *       "key": "user_preference",
 *       "created_at": "2023-05-15T10:30:00Z"
 *     },
 *     {
 *       "key": "search_history",
 *       "created_at": "2023-05-14T14:20:00Z"
 *     }
 *   ]
 * }
 * ```
 */
export interface MemoryKeyListResponse {
  /** Array of stored memory keys and their creation times */
  keys: Array<{
    /** The unique key identifier */
    key: string;
    /** ISO 8601 timestamp of when the key was first created */
    created_at: string;
  }>;
}

/**
 * URL parameters for GET /memory/:key endpoint
 *
 * Used when retrieving a specific memory value by its key.
 */
export interface MemoryGetByKeyParams {
  /** The key of the memory value to retrieve */
  key: string;
}

/**
 * Response for GET /memory/:key endpoint
 *
 * Returns a specific memory value and its metadata.
 *
 * @example
 * ```json
 * {
 *   "key": "user_preference",
 *   "value": {
 *     "theme": "dark",
 *     "language": "en"
 *   },
 *   "created_at": "2023-05-15T10:30:00Z",
 *   "updated_at": "2023-05-16T08:45:00Z",
 *   "metadata": {
 *     "source": "user_settings",
 *     "ttl": 86400
 *   }
 * }
 * ```
 */
export interface MemoryValueResponse {
  /** The unique key identifier */
  key: string;
  /** The stored value */
  value: MemoryValue;
  /** ISO 8601 timestamp of when the key was first created */
  created_at: string;
  /** ISO 8601 timestamp of when the key was last updated */
  updated_at?: string;
  /** Optional metadata associated with the value */
  metadata?: Record<string, unknown>;
}

/**
 * Request body for PUT /memory/:key endpoint
 *
 * Used to update an existing memory value.
 *
 * @example
 * ```json
 * {
 *   "value": {
 *     "theme": "light",
 *     "language": "en"
 *   }
 * }
 * ```
 */
export interface MemoryUpdateRequest {
  /** The new value to store under the existing key */
  value: MemoryValue;
}

/**
 * Response for PUT /memory/:key endpoint
 *
 * Confirms that a memory value was updated and returns the previous value.
 *
 * @example
 * ```json
 * {
 *   "status": "updated",
 *   "previous_value": {
 *     "theme": "dark",
 *     "language": "en"
 *   },
 *   "metadata": {
 *     "source": "user_settings",
 *     "ttl": 86400
 *   }
 * }
 * ```
 */
export interface MemoryUpdateResponse {
  /** Indicates the update operation completed successfully */
  status: "updated";
  /** The previous value that was replaced */
  previous_value: MemoryValue;
  /** Optional metadata associated with the value */
  metadata?: Record<string, unknown>;
}

/**
 * URL parameters for DELETE /memory/:key endpoint
 *
 * Used when deleting a specific memory entry.
 */
export interface MemoryDeleteParams {
  /** The key of the memory entry to delete */
  key: string;
}

/**
 * Response for DELETE /memory/:key endpoint
 *
 * Confirms that a memory entry was successfully deleted.
 *
 * @example
 * ```json
 * {
 *   "status": "deleted"
 * }
 * ```
 */
export interface MemoryDeleteResponse {
  /** Indicates the delete operation completed successfully */
  status: "deleted";
}

/**
 * Request for POST /memory/query endpoint
 *
 * Used to search for memory entries using semantic or filtered search.
 *
 * @example
 * ```json
 * {
 *   "query": "What theme settings do I have?",
 *   "limit": 5,
 *   "filter": {
 *     "key_prefix": "user_"
 *   }
 * }
 * ```
 */
export interface MemoryQueryRequest {
  /** The semantic query string to search for */
  query: string;
  /** Maximum number of results to return */
  limit?: number;
  /** Optional filters to apply to the search */
  filter?: {
    /** Only include keys that start with this prefix */
    "key_prefix"?: string;
    /** Only include keys that end with this suffix */
    "key_suffix"?: string;
    /** Only include keys that contain this substring */
    "key_contains"?: string;
    /** Exclude keys that contain this substring */
    "key_not_contains"?: string;
    /** Only include keys that match this regular expression */
    "key_matches"?: string;
  };
}

/**
 * Result entry for memory queries
 *
 * Represents a single memory entry returned from a query operation.
 */
export interface MemoryQueryResult {
  /** The key of the matched memory entry */
  key: string;
  /** The stored value */
  value: MemoryValue;
  /** A relevance score between 0.0 and 1.0, with higher values indicating better matches */
  score: number;
  /** Optional metadata associated with the value */
  metadata?: Record<string, unknown>;
  /** ISO 8601 timestamp of when the key was first created */
  created_at?: string;
  /** ISO 8601 timestamp of when the key was last updated */
  updated_at?: string;
}

/**
 * Response for POST /memory/query endpoint
 *
 * Returns memory entries that match a given query, sorted by relevance.
 *
 * @example
 * ```json
 * {
 *   "results": [
 *     {
 *       "key": "user_preference",
 *       "value": {
 *         "theme": "dark",
 *         "language": "en"
 *       },
 *       "score": 0.92
 *     }
 *   ]
 * }
 * ```
 */
export interface MemoryQueryResponse {
  /** Array of matching memory entries, sorted by relevance */
  results: MemoryQueryResult[];
}

//#endregion

//#region RESOURCES

/**
 * Standard resource types in SLOP
 *
 * Common types include "article", "document", "image", "code", "file", etc.
 * Custom types can also be defined as string literals.
 */
export type ResourceType =
  | "article"
  | "document"
  | "image"
  | "code"
  | "file"
  | "data"
  | "audio"
  | "video"
  | "table"
  | "graph"
  | "web"
  | "text"
  | string;

/**
 * Core resource definition in the SLOP pattern
 *
 * Resources are content or knowledge items that can be accessed by AI assistants
 * to provide information to users. A resource could be an article, document,
 * image, code snippet, or other data.
 */
export interface Resource {
  /** Unique identifier for the resource */
  id: string;
  /** The actual content of the resource */
  content: string;
  /**
   * The type or format of the resource
   * Common types include "article", "document", "image", "code", "file"
   */
  type: ResourceType;
}

/**
 * Metadata for a resource
 *
 * Provides additional information about a resource, such as its origin
 * and last update time.
 */
export interface ResourceMetadata {
  /** Origin or provider of the resource (e.g., "knowledge-base", "web-scrape", "user-upload") */
  source: string;
  /** ISO 8601 timestamp of when the resource was last updated */
  last_updated: string;
}

/**
 * Extended resource schema for API responses
 *
 * Adds optional fields to the base Resource for use in API responses.
 */
export interface ResourceSchema extends Resource {
  /** Optional filename for file-type resources */
  name?: string;
  /** Optional human-readable title for the resource */
  title?: string;
  /** Optional tags for categorization */
  tags?: string[];
  /** Optional description summary */
  description?: string;
  /** Optional format specific to the resource type */
  format?: string;
  /** Optional language code (e.g., "en", "fr") */
  language?: string;
  /** Optional size in bytes for files */
  size?: number;
}

/**
 * Response for GET /resources endpoint
 *
 * Returns a list of available resources with their basic information.
 *
 * @example
 * ```json
 * {
 *   "resources": [
 *     {
 *       "id": "mars-101",
 *       "title": "Mars: The Red Planet",
 *       "type": "article"
 *     },
 *     {
 *       "id": "document-123",
 *       "name": "project_plan.pdf",
 *       "type": "file"
 *     }
 *   ]
 * }
 * ```
 */
export interface ResourceListResponse {
  /** Array of available resources */
  resources: ResourceSchema[];
}

/**
 * URL parameters for GET /resources/:id endpoint
 *
 * Used when retrieving a specific resource by its ID.
 */
export interface ResourceGetParams {
  /** The unique identifier of the resource to retrieve */
  resource_id: string;
}

/**
 * Response for GET /resources/:id endpoint
 *
 * Returns a complete resource including its content and metadata.
 *
 * @example
 * ```json
 * {
 *   "id": "mars-101",
 *   "title": "Mars: The Red Planet",
 *   "type": "article",
 *   "content": "Mars is the fourth planet from the Sun and the second-smallest planet in the Solar System...",
 *   "metadata": {
 *     "source": "astronomy-db",
 *     "last_updated": "2023-05-10"
 *   },
 *   "tags": ["astronomy", "planets", "solar-system"],
 *   "last_accessed": "2023-06-10T15:30:00Z",
 *   "access_count": 42
 * }
 * ```
 */
export interface ResourceResponse extends ResourceSchema {
  /** Additional metadata about the resource */
  metadata: ResourceMetadata;
  /** When the resource was last accessed */
  last_accessed?: string;
  /** Number of times the resource has been accessed */
  access_count?: number;
}

/**
 * Query parameters for GET /resources/search endpoint
 *
 * Used to search for resources by content or metadata.
 */
export interface ResourceSearchParams {
  /** The search query string */
  q: string;
}

/**
 * Response for GET /resources/search endpoint
 *
 * Returns resources that match the search query, sorted by relevance.
 *
 * @example
 * ```json
 * {
 *   "results": [
 *     {
 *       "id": "mars-101",
 *       "title": "Mars: The Red Planet",
 *       "type": "article",
 *       "score": 0.98
 *     },
 *     {
 *       "id": "solar-system",
 *       "title": "Our Solar System",
 *       "type": "article",
 *       "score": 0.75
 *     }
 *   ]
 * }
 * ```
 */
export interface ResourceSearchResponse {
  /**
   * Array of matching resources with relevance scores
   * Higher scores indicate better matches to the search query
   */
  results: Array<
    ResourceSchema & {
      /** Relevance score between 0.0 and 1.0 */
      score: number;
    }
  >;
}

//#endregion

//#region PAY

/**
 * A unique identifier for a payment transaction
 *
 * In SLOP, transaction IDs follow a standardized format with the 'tx_' prefix
 * followed by a unique string (typically a UUID or similar).
 *
 * @example 'tx_123456789abcdef'
 */
export type TransactionId = `tx_${string}`;

/**
 * URL parameters for GET /pay/:id endpoint
 *
 * Used when retrieving information about a specific payment transaction.
 */
export interface PaymentGetParams {
  /** The unique identifier of the transaction to retrieve */
  id: TransactionId;
}

/**
 * Request for POST /pay endpoint
 *
 * Used to create a new payment transaction.
 *
 * @example
 * ```json
 * {
 *   "amount": 5.00,
 *   "currency": "USD",
 *   "description": "API usage - 1000 tokens",
 *   "payment_method": "card_token_123"
 * }
 * ```
 */
export interface PayPostRequest {
  /** The payment amount as a number */
  amount: number;
  /** Three-letter currency code (e.g., "USD", "EUR", "JPY") */
  currency: string;
  /** Human-readable description of what this payment is for */
  description: string;
  /**
   * Identifier for the payment method to use
   * This could be a stored card token, wallet ID, or other payment identifier
   */
  payment_method: string;
}

/**
 * Response for POST /pay endpoint
 *
 * Confirms that a payment transaction was successfully processed.
 *
 * @example
 * ```json
 * {
 *   "transaction_id": "tx_987654",
 *   "status": "success",
 *   "receipt_url": "https://api.example.com/receipts/tx_987654"
 * }
 * ```
 */
export interface PayPostResponse {
  /** Unique identifier for the created transaction */
  transaction_id: TransactionId;
  /**
   * Status of the transaction
   * While currently only "success" is supported, future versions may support
   * additional statuses like "pending" or "failed"
   */
  status: "success";
  /** URL where a receipt or transaction details can be viewed */
  receipt_url: string;
}

/**
 * Response for GET /pay/:id endpoint
 *
 * Returns detailed information about a specific payment transaction.
 *
 * @example
 * ```json
 * {
 *   "transaction_id": "tx_987654",
 *   "amount": 5.00,
 *   "currency": "USD",
 *   "description": "API usage - 1000 tokens",
 *   "status": "success",
 *   "created_at": "2023-05-15T10:30:00Z",
 *   "receipt_url": "https://api.example.com/receipts/tx_987654",
 *   "payment_method": "card_token_123"
 * }
 * ```
 */
export interface PayGetByIdResponse {
  /** Unique identifier for this transaction */
  transaction_id: TransactionId;
  /** The payment amount */
  amount: number;
  /** Three-letter currency code */
  currency: string;
  /** Human-readable description of what this payment was for */
  description: string;
  /** Current status of the transaction */
  status: "success";
  /** ISO 8601 timestamp of when the transaction was created */
  created_at: string;
  /** URL where a receipt or transaction details can be viewed */
  receipt_url: string;
  /** Identifier for the payment method used */
  payment_method: string;
}

//#endregion

//#region SCOPE

/**
 * Top-level scope categories in the SLOP permission system
 *
 * These prefixes represent the major API endpoints and functionality groups
 * that can be controlled via scope permissions.
 */
export type ScopePrefix =
  /** Chat-related permissions */
  | "chat"
  /** Tool-related permissions */
  | "tools"
  /** Memory storage permissions */
  | "memory"
  /** Resource access permissions */
  | "resources"
  /** Payment permissions */
  | "pay";

/**
 * Chat-related scope permissions
 *
 * Controls access to chat history, creation of new chats, and management
 * of chat threads.
 *
 * @examples
 * - "chat.read" - Read access to all chats
 * - "chat.thread_123.read" - Read access to a specific thread
 * - "chat.write" - Permission to create new chats
 * - "chat.*" - Full access to all chat functionality
 */
export type ScopeChatAction =
  /** General read/write permissions for all chats */
  | `chat.${"read" | "write"}`
  /** Permissions for specific chat IDs or thread IDs */
  | `chat.${string}.${"read" | "write"}`
  /** Wildcard for full chat permissions */
  | `chat.*`;

/**
 * Tool-related scope permissions
 *
 * Controls which tools can be executed and viewed. Particularly important
 * for security as tools can perform actions with side effects.
 *
 * @examples
 * - "tools.calculator.execute" - Permission to use the calculator tool
 * - "tools.safe.weather" - Permission to use a tool designated as "safe"
 * - "tools.read" - Permission to list available tools
 * - "tools.*" - Full access to all tools
 */
export type ScopeToolAction =
  /** Permission to execute a specific tool */
  | `tools.${string}.execute`
  /** Permission to use a tool in the "safe" category */
  | `tools.safe.${string}`
  /** Permission to view information about a specific tool */
  | `tools.${string}.read`
  /** Permission to list all available tools */
  | `tools.read`
  /** Wildcard for full tool permissions */
  | `tools.*`;

/**
 * Memory-related scope permissions
 *
 * Controls access to the key-value storage system, allowing
 * fine-grained control over which keys can be read or modified.
 *
 * @examples
 * - "memory.user_preference.read" - Read access to a specific key
 * - "memory.user_preference.write" - Write access to a specific key
 * - "memory..read" - Read-only access to all memory entries
 * - "memory.*" - Full access to all memory operations
 */
export type ScopeMemoryAction =
  /** Read or write access to a specific memory key */
  | `memory.${string}.${"read" | "write"}`
  /** Read-only access to all memory keys */
  | `memory..read`
  /** Wildcard for full memory permissions */
  | `memory.*`;

/**
 * Resource-related scope permissions
 *
 * Controls access to knowledge resources, articles, files, and
 * search functionality.
 *
 * @examples
 * - "resources.mars-101.read" - Read access to a specific resource
 * - "resources.list.read" - Permission to list available resources
 * - "resources.search.read" - Permission to search resources
 * - "resources.*" - Full access to all resources
 */
export type ScopeResourceAction =
  /** Read access to a specific resource */
  | `resources.${string}.read`
  /** Permission to list resources */
  | `resources.list.${string}`
  /** Permission to search resources */
  | `resources.search.${string}`
  /** Wildcard for full resource permissions */
  | `resources.*`;

/**
 * Payment-related scope permissions
 *
 * Controls ability to create payments and view transaction history.
 * Critical for security to prevent unauthorized charges.
 *
 * @examples
 * - "pay.execute" - Permission to create new payments
 * - "pay.tx_123.read" - Permission to view a specific transaction
 * - "pay.*" - Full access to all payment functionality
 */
export type ScopePayAction =
  /** Permission to create new payments */
  | `pay.execute`
  /** Permission to view a specific transaction */
  | `pay.${string}.read`
  /** Wildcard for full payment permissions */
  | `pay.*`;

/**
 * Complete scope permission pattern
 *
 * The union of all possible scope patterns that can be used in the
 * X-SLOP-SCOPE header to control API access permissions.
 *
 * Scope strings should be passed in a comma-separated list, e.g.:
 * "chat.read,tools.calculator.execute,memory.user_preference.read"
 */
export type ScopePattern =
  | ScopeChatAction
  | ScopeToolAction
  | ScopeMemoryAction
  | ScopeResourceAction
  | ScopePayAction;

//#endregion

/**
 * WebSocket chat response message format
 *
 * Response sent from server to client over an established WebSocket connection.
 * During streaming, multiple messages will be sent, one for each token,
 * followed by a final message with status: "complete".
 *
 * @example
 * ```json
 * // Token message
 * {"content": "The "}
 *
 * // Completion message
 * {"status": "complete"}
 *
 * // Error message
 * {"error": "Model not available"}
 * ```
 */
export interface WebSocketChatResponse {
  /** Content of the message token */
  content?: string;
  /** Unique chat ID (typically included only in first or final message) */
  id?: ChatId;
  /** Thread ID if this message is part of a thread */
  thread_id?: ThreadId;
  /**
   * Completion status
   * When included with value "complete", indicates the end of the response stream
   */
  status?: "complete";
  /**
   * Error message if something went wrong
   * Only present in error responses
   */
  error?: string;
}

----------------------
LICENSE
----------------------
MIT License

Copyright (c) 2025 agnt.gg

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

----------------------
README.MD
----------------------
# SLOP: Simple Language Open Protocol

> **Because AI shouldn't be complicated**

### ðŸŽ¯ WHAT SLOP IS:
- A pattern for AI APIs with 5 basic endpoints
- Regular HTTP(S) requests with JSON data
- A standard way to talk to any AI service
- Based on REST: GET and POST what you need

### ðŸš« WHAT SLOP IS NOT:
- A framework or library you install
- A new technology or language
- A specific company's product
- An additional abstraction in any way

> ðŸ’¡ **SLOP simply says:** "AI services should work through plain web requests using patterns we've used for decades."

That's it. Just a pattern. âœ¨

---

## 1. CORE BELIEFS
- Everything is an HTTP request
- Every tool is an API endpoint
- Every AI is accessible
- Every developer is welcome

## 2. MINIMUM VIABLE ENDPOINTS
- `POST /chat` // Talk to AI
- `POST /tools` // Use tools
- `POST /memory` // Remember stuff
- `GET /resources` // Get knowledge/files/data
- `POST /pay` // Handle money

## 3. CONNECTION TYPES
- Standard HTTP/REST Interface For Most Things
- WebSocket Support for Persistent Real-Time Connections
- Server-Sent Events (SSE) for One-Way Real-Time Streaming

## 4. MULTI-AGENT CAPABILITIES
- Route Queries to Specialized Agents Based on Content
- Create Agent Networks with Different Skills and Roles
- Support for Multiple Execution Patterns (Sequential, Parallel, Branching)
- Persistent Memory Allows Seamless Agent Collaboration
- Works for Simple to Complex Use Cases:

  - [Advanced Streaming AI Chat Platform](https://github.com/agnt-gg/slop/tree/main/examples/javascript/advanced-examples/pdf-bot-with-stream)
  - Customer Service Bots with Specialist Routing
  - Research Assistants with Domain-Specific Agents
  - Creative Workflows with Multiple AI Collaborators
  - Game Development with Dynamic NPCs
  - Smart Home Management with Coordinated AI Agents
  - Personal Finance Management with Adaptive Advisors
  - Educational Platforms with Adaptive Learning Agents
  - Multi-Agent Disaster Response Coordination
  - Marketing Automation with Targeted Campaign Agents
  - Health Monitoring Systems with Specialized Health Agents
  - Travel Planning Assistants with Itinerary Optimization
  - E-commerce Platforms with Personalized Shopping Assistants
  - Content Moderation Systems with Specialized Review Agents

---

## ðŸ¤ THE SLOP PROMISE:

### 1. OPEN
- Free to use
- Open source
- No vendor lock
- Community driven
- Use any LLM model

### 2. SIMPLE
- REST based
- JSON only
- Standard HTTP
- Zero dependencies

### 3. FLEXIBLE
- Any AI model
- Any tool
- Any platform

---

## ðŸ“– ENDPOINT OPERATIONS (v0.0.1)

### ðŸ’¬ CHAT
- `POST /chat` - Send messages to AI
- `POST /chat` - Create or continue a thread (with thread_id)
- `GET /chat/:id` - Get a specific chat
- `GET /chat/thread_:id` - Get all messages in a thread
- `GET /chat` - List recent chats
- `GET /chat?type=threads` - List all threads

### ðŸ› ï¸ TOOLS
- `GET /tools` - List available tools
- `POST /tools/:tool_id` - Use a specific tool
- `GET /tools/:tool_id` - Get tool details

### ðŸ§  MEMORY
- `POST /memory` - Store a key-value pair
- `GET /memory/:key` - Get value by key
- `GET /memory` - List all keys
- `PUT /memory/:key` - Update existing value
- `DELETE /memory/:key` - Delete a key-value pair
- `POST /memory/query` - Search with semantic query

### ðŸ“š RESOURCES
- `GET /resources` - List available resources
- `GET /resources/:id` - Get a specific resource
- `GET /resources/search?q=query` - Search resources

### ðŸ’³ PAY
- `POST /pay` - Create a payment
- `GET /pay/:id` - Get payment status

---

## ðŸš€ API EXAMPLES - ALL ENDPOINTS

### ðŸ’¬ CHAT ENDPOINTS

#### POST /chat
```json
// REQUEST
POST /chat
{
  "messages": [
    {"role": "user", "content": "Hello, what's the weather like?"}
  ],
  "model": "any-model-id"
}

// RESPONSE
{
  "id": "chat_123",
  "message": {
    "role": "assistant", 
    "content": "I don't have real-time weather data. You could check a weather service for current conditions."
  }
}
```

#### GET /chat/:id
```json
// REQUEST
GET /chat/chat_123

// RESPONSE
{
  "id": "chat_123",
  "messages": [
    {"role": "user", "content": "Hello, what's the weather like?"},
    {"role": "assistant", "content": "I don't have real-time weather data. You could check a weather service for current conditions."}
  ],
  "model": "any-model-id",
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### Creating a Thread
```json
// REQUEST
POST /chat
{
  "thread_id": "thread_12345",  // Thread identifier
  "messages": [
    {"role": "user", "content": "Let's discuss project planning"}
  ],
  "model": "any-model-id"
}

// RESPONSE
{
  "thread_id": "thread_12345",
  "message": {
    "role": "assistant", 
    "content": "Sure, I'd be happy to discuss project planning. What aspects would you like to focus on?"
  }
}
```

#### Adding to a Thread
```json
// REQUEST
POST /chat
{
  "thread_id": "thread_12345",
  "messages": [
    {"role": "user", "content": "What's our next milestone?"}
  ],
  "model": "any-model-id"
}

// RESPONSE
{
  "thread_id": "thread_12345",
  "message": {
    "role": "assistant", 
    "content": "To determine the next milestone, we should review your project timeline and priorities. What's the current state of your project?"
  }
}
```

#### Listing All Threads
```json
// REQUEST
GET /chat?type=threads

// RESPONSE
{
  "threads": [
    {
      "id": "thread_12345",
      "title": "Project Planning",
      "last_message": "What's our next milestone?",
      "created_at": "2023-05-15T10:30:00Z",
      "updated_at": "2023-05-15T11:45:00Z"
    },
    {
      "id": "thread_67890",
      "title": "Bug Fixes",
      "last_message": "Let's prioritize the login issue",
      "created_at": "2023-05-14T14:20:00Z",
      "updated_at": "2023-05-14T16:30:00Z"
    }
  ]
}
```

#### Getting Thread Messages
```json
// REQUEST
GET /chat/thread_12345

// RESPONSE
{
  "thread_id": "thread_12345",
  "title": "Project Planning",
  "messages": [
    {
      "id": "msg_001",
      "role": "user", 
      "content": "Let's discuss project planning",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "id": "msg_002",
      "role": "assistant", 
      "content": "Sure, what aspects of the project would you like to plan?",
      "created_at": "2023-05-15T10:30:05Z"
    },
    {
      "id": "msg_003",
      "role": "user", 
      "content": "What's our next milestone?",
      "created_at": "2023-05-15T11:45:00Z"
    }
  ],
  "model": "any-model-id",
  "created_at": "2023-05-15T10:30:00Z",
  "updated_at": "2023-05-15T11:45:00Z"
}
```

#### Storing Thread Metadata
```json
// REQUEST
POST /memory
{
  "key": "thread:thread_12345",
  "value": {
    "title": "Project Planning",
    "participants": ["user_1", "user_2"],
    "tags": ["project", "planning", "roadmap"],
    "status": "active"
  }
}

// RESPONSE
{
  "status": "stored"
}
```

#### Searching for Threads
```json
// REQUEST
POST /memory/query
{
  "query": "project planning threads with user_1",
  "filter": {
    "key_prefix": "thread:"
  }
}

// RESPONSE
{
  "results": [
    {
      "key": "thread:thread_12345",
      "value": {
        "title": "Project Planning",
        "participants": ["user_1", "user_2"],
        "tags": ["project", "planning", "roadmap"],
        "status": "active"
      },
      "score": 0.95
    }
  ]
}
```

#### Updating Thread Metadata
```json
// REQUEST
PUT /memory/thread:thread_12345
{
  "value": {
    "title": "Project Planning",
    "participants": ["user_1", "user_2", "user_3"],  // Added new participant
    "tags": ["project", "planning", "roadmap", "active"],
    "status": "in_progress"  // Updated status
  }
}

// RESPONSE
{
  "status": "updated",
  "previous_value": {
    "title": "Project Planning",
    "participants": ["user_1", "user_2"],
    "tags": ["project", "planning", "roadmap"],
    "status": "active"
  }
}
```

#### GET /chat
```json
// REQUEST
GET /chat

// RESPONSE
{
  "chats": [
    {
      "id": "chat_123",
      "snippet": "Hello, what's the weather like?",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "id": "chat_456",
      "snippet": "Tell me about Mars",
      "created_at": "2023-05-14T14:20:00Z"
    }
  ]
}
```

### ðŸ› ï¸ TOOLS ENDPOINTS

#### GET /tools
```json
// REQUEST
GET /tools

// RESPONSE
{
  "tools": [
    {
      "id": "calculator",
      "description": "Performs mathematical calculations",
      "parameters": {
        "expression": "string"
      }
    },
    {
      "id": "weather",
      "description": "Gets current weather",
      "parameters": {
        "location": "string"
      }
    }
  ]
}
```

#### POST /tools/:tool_id
```json
// REQUEST
POST /tools/calculator
{
  "expression": "15 * 7"
}

// RESPONSE
{
  "result": 105
}
```

#### GET /tools/:tool_id
```json
// REQUEST
GET /tools/calculator

// RESPONSE
{
  "id": "calculator",
  "description": "Performs mathematical calculations",
  "parameters": {
    "expression": {
      "type": "string",
      "description": "Mathematical expression to evaluate"
    }
  },
  "example": "15 * 7"
}
```

### ðŸ§  MEMORY ENDPOINTS

#### POST /memory
```json
// REQUEST
POST /memory
{
  "key": "user_preference",
  "value": {
    "theme": "dark",
    "language": "en"
  }
}

// RESPONSE
{
  "status": "stored"
}
```

#### GET /memory/:key
```json
// REQUEST
GET /memory/user_preference

// RESPONSE
{
  "key": "user_preference",
  "value": {
    "theme": "dark",
    "language": "en"
  },
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### GET /memory
```json
// REQUEST
GET /memory

// RESPONSE
{
  "keys": [
    {
      "key": "user_preference",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "key": "search_history",
      "created_at": "2023-05-14T14:20:00Z"
    }
  ]
}
```

#### PUT /memory/:key
```json
// REQUEST
PUT /memory/user_preference
{
  "value": {
    "theme": "light",
    "language": "en"
  }
}

// RESPONSE
{
  "status": "updated",
  "previous_value": {
    "theme": "dark",
    "language": "en"
  }
}
```

#### DELETE /memory/:key
```json
// REQUEST
DELETE /memory/user_preference

// RESPONSE
{
  "status": "deleted"
}
```

#### POST /memory/query
```json
// REQUEST
POST /memory/query
{
  "query": "What theme settings do I have?",
  "limit": 1
}

// RESPONSE
{
  "results": [
    {
      "key": "user_preference",
      "value": {
        "theme": "dark",
        "language": "en"
      },
      "score": 0.92
    }
  ]
}
```

### ðŸ“š RESOURCES ENDPOINTS

#### GET /resources
```json
// REQUEST
GET /resources

// RESPONSE
{
  "resources": [
    {
      "id": "mars-101",
      "title": "Mars: The Red Planet",
      "type": "article"
    },
    {
      "id": "document-123",
      "name": "project_plan.pdf",
      "type": "file"
    }
  ]
}
```

#### GET /resources/:id
```json
// REQUEST
GET /resources/mars-101

// RESPONSE
{
  "id": "mars-101",
  "title": "Mars: The Red Planet",
  "type": "article",
  "content": "Mars is the fourth planet from the Sun and the second-smallest planet in the Solar System...",
  "metadata": {
    "source": "astronomy-db",
    "last_updated": "2023-05-10"
  }
}
```

#### GET /resources/search
```json
// REQUEST
GET /resources/search?q=mars

// RESPONSE
{
  "results": [
    {
      "id": "mars-101",
      "title": "Mars: The Red Planet",
      "type": "article",
      "score": 0.98
    },
    {
      "id": "solar-system",
      "title": "Our Solar System",
      "type": "article",
      "score": 0.75
    }
  ]
}
```

### ðŸ’³ PAY ENDPOINTS

#### POST /pay
```json
// REQUEST
POST /pay
{
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage - 1000 tokens",
  "payment_method": "card_token_123"
}

// RESPONSE
{
  "transaction_id": "tx_987654",
  "status": "success",
  "receipt_url": "https://api.example.com/receipts/tx_987654"
}
```

#### GET /pay/:id
```json
// REQUEST
GET /pay/tx_987654

// RESPONSE
{
  "transaction_id": "tx_987654",
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage - 1000 tokens",
  "status": "success",
  "created_at": "2023-05-15T10:30:00Z",
  "receipt_url": "https://api.example.com/receipts/tx_987654"
}
```

### ðŸ” AUTH EXAMPLES

Authentication in SLOP uses standard HTTP headers. Here are examples in both JavaScript and Python:

#### JavaScript Example
```javascript
// Using fetch
const callSlop = async (endpoint, data) => {
  const response = await fetch(`https://api.example.com${endpoint}`, {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer your-token-here',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
  });
  return response.json();
};

// Using axios
const axios = require('axios');
const api = axios.create({
  baseURL: 'https://api.example.com',
  headers: {
    'Authorization': 'Bearer your-token-here'
  }
});

// Make authenticated requests
await api.post('/chat', {
  messages: [{ content: 'Hello!' }]
});
```

#### Python Example
```python
import requests

# Using requests
headers = {
    'Authorization': 'Bearer your-token-here',
    'Content-Type': 'application/json'
}

# Function to make authenticated requests
def call_slop(endpoint, data=None):
    base_url = 'https://api.example.com'
    method = 'GET' if data is None else 'POST'
    response = requests.request(
        method=method,
        url=f'{base_url}{endpoint}',
        headers=headers,
        json=data
    )
    return response.json()

# Make authenticated requests
chat_response = call_slop('/chat', {
    'messages': [{'content': 'Hello!'}]
})
```

Remember: SLOP uses standard HTTP auth - no special endpoints needed! ðŸ”‘

### ðŸ›¡ï¸ SCOPE HEADERS FOR LIMITING AI SCOPE

SLOP uses standard HTTP headers to control AI safety and permissions:

```http
X-SLOP-Scope: chat.read,tools.calculator,memory.user.read
```

#### Common Scopes

chat.read # Read chat history
chat.write # Send messages
tools.* # Access all tools
tools.safe.* # Access only safe tools
memory.user.* # Full user memory access
memory..read # Read-only memory access


#### Examples

```http
# Safe: Calculator within scope
POST /tools/calculator
X-SLOP-Scope: tools.calculator.execute
{
    "expression": "2 + 2"
}

# Blocked: No execute permission
POST /tools/system-cmd
X-SLOP-Scope: tools.calculator.execute
{
    "cmd": "rm -rf /"
}

// RESPONSE
{
    "error": "Scope violation: tools.execute-code requires explicit permission",
    "permitted": false
}
```

Remember: Security through simplicity! ðŸ”’

---


## ðŸ”„ SSE STREAMING IN SLOP

SLOP supports streaming responses through Server-Sent Events (SSE) - perfect for token-by-token AI outputs:

### Adding SSE to Your SLOP Implementation

#### JavaScript Example
```javascript
// Add this streaming endpoint to your SLOP implementation
app.post('/chat/stream', async (req, res) => {
  const { messages } = req.body;
  const userQuery = messages[0].content;
  
  // Set SSE headers
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache');
  res.setHeader('Connection', 'keep-alive');
  
  // Create streaming response
  const stream = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: userQuery }
    ],
    stream: true
  });
  
  // Send tokens as they arrive
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || '';
    if (content) {
      res.write(`data: ${JSON.stringify({ content })}\n\n`);
    }
  }
  res.write('data: [DONE]\n\n');
  res.end();
});
```

#### Python Example
```python
@app.route('/chat/stream', methods=['POST'])
def chat_stream():
    data = request.json
    user_query = data['messages'][0]['content']
    
    def generate():
        stream = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": user_query}
            ],
            stream=True
        )
        for chunk in stream:
            content = chunk.choices[0].delta.content or ''
            if content:
                yield f"data: {json.dumps({'content': content})}\n\n"
        yield "data: [DONE]\n\n"
    
    return Response(generate(), content_type='text/event-stream')
```

#### Client Consumption
```javascript
// Browser JavaScript to consume the stream
const eventSource = new EventSource('/chat/stream');
eventSource.onmessage = (event) => {
  if (event.data === '[DONE]') {
    eventSource.close();
    return;
  }
  const data = JSON.parse(event.data);
  // Append incoming token to UI
  document.getElementById('response').innerHTML += data.content;
};
```

### Why SSE is SLOP-Friendly:
- Uses standard HTTP - no new protocols
- Works with existing authentication
- Simple implementation - minimal code
- Compatible with all HTTP clients
- Lower overhead than WebSockets

Remember: Add `/stream` suffix to endpoints that support streaming! ðŸš¿

## ðŸ”Œ WEBSOCKET STREAMING IN SLOP

SLOP also supports WebSocket for bidirectional streaming - ideal for real-time AI interactions:

### Adding WebSocket to Your SLOP Implementation

#### JavaScript Example (Node.js with ws)
```javascript
// Server-side WebSocket implementation
const WebSocket = require('ws');
const wss = new WebSocket.Server({ port: 8080 });

wss.on('connection', (ws) => {
  ws.on('message', async (message) => {
    try {
      const data = JSON.parse(message);
      const { messages } = data;
      const userQuery = messages[0].content;
      
      // Create streaming response
      const stream = await openai.chat.completions.create({
        model: "gpt-4",
        messages: [
          { role: "system", content: "You are a helpful assistant." },
          { role: "user", content: userQuery }
        ],
        stream: true
      });
      
      // Send tokens as they arrive
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ content }));
        }
      }
      
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ status: "complete" }));
      }
    } catch (error) {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ error: error.message }));
      }
    }
  });
});
```

#### Python Example (with FastAPI and websockets)
```python
from fastapi import FastAPI, WebSocket
import json
import openai

app = FastAPI()

@app.websocket("/chat/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    try:
        while True:
            data = await websocket.receive_text()
            data_json = json.loads(data)
            user_query = data_json['messages'][0]['content']
            
            stream = openai.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": user_query}
                ],
                stream=True
            )
            
            for chunk in stream:
                content = chunk.choices[0].delta.content or ''
                if content:
                    await websocket.send_text(json.dumps({"content": content}))
            
            await websocket.send_text(json.dumps({"status": "complete"}))
    
    except Exception as e:
        await websocket.send_text(json.dumps({"error": str(e)}))
```

#### Client Consumption
```javascript
// Browser JavaScript to connect to WebSocket
const socket = new WebSocket('ws://localhost:8080');
let responseText = '';

// Send a message when connection is open
socket.onopen = function(event) {
  socket.send(JSON.stringify({
    messages: [{ role: 'user', content: 'Tell me about SLOP protocol' }]
  }));
};

// Listen for messages
socket.onmessage = function(event) {
  const data = JSON.parse(event.data);
  
  if (data.content) {
    responseText += data.content;
    document.getElementById('response').innerText = responseText;
  }
  
  if (data.status === 'complete') {
    console.log('Response complete');
  }
  
  if (data.error) {
    console.error('Error:', data.error);
  }
};

// Handle errors
socket.onerror = function(error) {
  console.error('WebSocket Error:', error);
};

// Clean up on close
socket.onclose = function(event) {
  console.log('Connection closed');
};
```

### Why WebSockets for SLOP:
- Bidirectional communication for complex interactions
- Persistent connection for multiple exchanges
- Real-time feedback and typing indicators
- Supports advanced features like user interruptions
- Ideal for chat applications and interactive AI assistants

Remember: Use `/ws` suffix to indicate WebSocket endpoints in your SLOP implementation! ðŸ”Œ

---

Let's collab! SLOP Discord: https://discord.com/invite/nwXJMnHmXP

ðŸŽ‰ **Enjoy using SLOP!** ðŸŽ‰ 

SLOP is an open sourced protocol launched under the MIT license by [@NathanWilbanks](https://discord.com/invite/nwXJMnHmXP) of the AGNT.gg open source agent building platform.
----------------------
SPEC.MD
----------------------
# RFC Specification for Simple Language Open Protocol (SLOP)
Version: 1.0.0
Status: Draft
Date: 2025-03-08

## Abstract

This document specifies the Simple Language Open Protocol (SLOP), a minimal HTTP-based protocol for AI agent interoperability. There are exactly five core endpoints with standard request/response formats. Nothing more. The spec is intentionally minimal to maximize adoption and implementation speed while ensuring interoperability.

## 1. Introduction

### 1.1 Purpose

SLOP establishes a common "handshake" pattern for AI systems. We define only what's necessary for interoperability. Everything else is left to the implementer.

### 1.2 Design Philosophy

Three principles:

1. **Simplicity Over Complexity**: HTTP requests. JSON responses. That's it.
2. **Concrete Over Abstract**: Examples with actual code, not just theory.
3. **Zero-Cost When Unused**: Implement only what you need. No overhead.

## 2. Terminology

"MUST", "SHOULD", and other key terms follow [RFC2119](https://www.ietf.org/rfc/rfc2119.txt).

- **Agent**: System that processes requests and generates responses.
- **Endpoint**: URL path for interaction.
- **Thread**: Sequence of related messages.
- **Tool**: Function that an agent provides.
- **Resource**: Data or knowledge available to agents.

## 3. Conformance Requirements

You are SLOP-compliant if you:

1. Implement ANY ONE of the five core endpoints
2. Follow the JSON formats exactly as shown in examples
3. Return error responses as specified
4. Use standard HTTP status codes correctly

That's it. No hidden requirements.

## 4. Core Endpoints

SLOP has exactly five endpoints. Implementation must match example request/response formats precisely for the endpoints you choose to implement.

### 4.1 Chat Endpoint

#### 4.1.1 POST /chat

```
REQUEST:
POST /chat
Content-Type: application/json

{
  "messages": [
    {"role": "user", "content": "Hello world"}
  ],
  "thread_id": "thread_12345"  // Optional
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "message": {
    "role": "assistant",
    "content": "Hello! How can I help you today?"
  },
  "thread_id": "thread_12345"
}
```

#### 4.1.2 GET /chat/:id

```
REQUEST:
GET /chat/chat_123
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "id": "chat_123",
  "messages": [
    {"role": "user", "content": "Hello world"},
    {"role": "assistant", "content": "Hello! How can I help you today?"}
  ],
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### 4.1.3 GET /chat/thread_:id

```
REQUEST:
GET /chat/thread_12345
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "thread_id": "thread_12345",
  "messages": [
    {
      "id": "msg_001",
      "role": "user", 
      "content": "Hello world",
      "created_at": "2023-05-15T10:30:00Z"
    },
    {
      "id": "msg_002",
      "role": "assistant", 
      "content": "Hello! How can I help you today?",
      "created_at": "2023-05-15T10:30:05Z"
    }
  ],
  "created_at": "2023-05-15T10:30:00Z"
}
```

### 4.2 Tools Endpoint

#### 4.2.1 GET /tools

```
REQUEST:
GET /tools
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "tools": [
    {
      "id": "calculator",
      "description": "Performs mathematical calculations",
      "parameters": {
        "expression": {
          "type": "string",
          "description": "Mathematical expression to evaluate"
        }
      }
    }
  ]
}
```

#### 4.2.2 POST /tools/:tool_id

```
REQUEST:
POST /tools/calculator
Content-Type: application/json

{
  "expression": "2 + 2"
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "result": 4
}
```

### 4.3 Memory Endpoint

#### 4.3.1 POST /memory

```
REQUEST:
POST /memory
Content-Type: application/json

{
  "key": "user_preference",
  "value": {
    "theme": "dark"
  }
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "status": "stored"
}
```

#### 4.3.2 GET /memory/:key

```
REQUEST:
GET /memory/user_preference
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "key": "user_preference",
  "value": {
    "theme": "dark"
  },
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### 4.3.3 PUT /memory/:key

```
REQUEST:
PUT /memory/user_preference
Content-Type: application/json

{
  "value": {
    "theme": "light"
  }
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "status": "updated",
  "previous_value": {
    "theme": "dark"
  }
}
```

#### 4.3.4 DELETE /memory/:key

```
REQUEST:
DELETE /memory/user_preference

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "status": "deleted"
}
```

### 4.4 Resources Endpoint

#### 4.4.1 GET /resources

```
REQUEST:
GET /resources
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "resources": [
    {
      "id": "weather-api",
      "title": "Weather API Documentation",
      "type": "document"
    }
  ]
}
```

#### 4.4.2 GET /resources/:id

```
REQUEST:
GET /resources/weather-api
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "id": "weather-api",
  "title": "Weather API Documentation",
  "content": "The Weather API provides current weather data...",
  "type": "document",
  "created_at": "2023-05-15T10:30:00Z"
}
```

### 4.5 Pay Endpoint

#### 4.5.1 POST /pay

```
REQUEST:
POST /pay
Content-Type: application/json

{
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage"
}

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "transaction_id": "tx_987654",
  "status": "success",
  "created_at": "2023-05-15T10:30:00Z"
}
```

#### 4.5.2 GET /pay/:id

```
REQUEST:
GET /pay/tx_987654
Accept: application/json

RESPONSE:
HTTP/1.1 200 OK
Content-Type: application/json

{
  "transaction_id": "tx_987654",
  "amount": 5.00,
  "currency": "USD",
  "description": "API usage",
  "status": "success",
  "created_at": "2023-05-15T10:30:00Z"
}
```

## 5. Error Handling

All errors MUST use standard HTTP status codes with consistent JSON responses.

```
EXAMPLE ERROR RESPONSE:
HTTP/1.1 400 Bad Request
Content-Type: application/json

{
  "error": {
    "code": "invalid_request",
    "message": "Missing required field: messages",
    "status": 400
  }
}
```

Status codes:
- `400`: Bad request - client error
- `401`: Authentication required
- `403`: Permission denied
- `404`: Not found
- `429`: Rate limit exceeded
- `500`: Server error

## 6. Connection Types

### 6.1 HTTP/REST

Standard request/response for most operations.

### 6.2 SSE for Streaming

Append `/stream` to endpoints for Server-Sent Events streaming:

```
REQUEST:
GET /chat/stream
Accept: text/event-stream

RESPONSE:
HTTP/1.1 200 OK
Content-Type: text/event-stream

data: {"content": "Hello"}
data: {"content": " world"}
data: [DONE]
```

### 6.3 WebSockets

Append `/ws` to endpoints for WebSocket connections:

```
ws://example.com/chat/ws
```

## 7. Authentication and Security

### 7.1 Bearer Token Authentication

```
Authorization: Bearer <token>
```

### 7.2 Scope Control

```
X-SLOP-Scope: chat.read,tools.execute
```

Common scopes:
- `chat.read`: Read chat messages
- `chat.write`: Send chat messages
- `tools.*`: Access all tools
- `memory.user.*`: Full user memory access

### 7.3 Security Requirements

- HTTPS always
- Input validation against schemas
- Output sanitization
- Rate limiting

## 8. Minimal Reference Implementations

### 8.1 Node.js Example (50 lines)

```javascript
const express = require('express');
const app = express();
app.use(express.json());

// Memory storage
const memory = new Map();

// CHAT endpoint
app.post('/chat', (req, res) => {
  const message = req.body.messages?.[0]?.content || '';
  res.json({
    message: {
      role: 'assistant',
      content: `You said: ${message}`
    },
    thread_id: req.body.thread_id
  });
});

// TOOLS endpoint
app.get('/tools', (_, res) => res.json({
  tools: [{id: 'echo', description: 'Echoes input'}]
}));
app.post('/tools/:id', (req, res) => {
  if (req.params.id === 'echo') {
    return res.json({result: req.body.text});
  }
  res.status(404).json({error: {code: 'not_found'}});
});

// MEMORY endpoint
app.post('/memory', (req, res) => {
  memory.set(req.body.key, req.body.value);
  res.json({status: 'stored'});
});
app.get('/memory/:key', (req, res) => {
  res.json({value: memory.get(req.params.key)});
});

app.listen(3000);
```

### 8.2 Python Example (50 lines)

```python
from flask import Flask, request, jsonify

app = Flask(__name__)
memory = {}

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    message = data.get('messages', [{}])[0].get('content', '')
    return jsonify({
        'message': {
            'role': 'assistant',
            'content': f'You said: {message}'
        },
        'thread_id': data.get('thread_id')
    })

@app.route('/tools', methods=['GET'])
def list_tools():
    return jsonify({'tools': [{'id': 'echo', 'description': 'Echoes input'}]})

@app.route('/tools/<tool_id>', methods=['POST'])
def use_tool(tool_id):
    if tool_id == 'echo':
        return jsonify({'result': request.json.get('text', '')})
    return jsonify({'error': {'code': 'not_found'}}), 404

@app.route('/memory', methods=['POST'])
def store_memory():
    data = request.json
    memory[data['key']] = data['value']
    return jsonify({'status': 'stored'})

@app.route('/memory/<key>', methods=['GET'])
def get_memory(key):
    return jsonify({'value': memory.get(key)})

if __name__ == '__main__':
    app.run(port=3000)
```

## 9. Integration Patterns

### 9.1 Sequential

Agent A â†’ Agent B â†’ Agent C, with each output feeding into the next input.

### 9.2 Parallel

Multiple agents process the same input simultaneously with results combined later.

### 9.3 Branching

A router agent directs requests to specialized agents based on content analysis.

## 10. References

- [RFC2119: Key Words](https://www.ietf.org/rfc/rfc2119.txt)
- [RFC9110: HTTP Semantics](https://www.rfc-editor.org/rfc/rfc9110.html)
- [RFC8259: JSON Format](https://www.rfc-editor.org/rfc/rfc8259.html)
- [Server-Sent Events Standard](https://html.spec.whatwg.org/multipage/server-sent-events.html)
- [RFC6455: WebSockets](https://www.rfc-editor.org/rfc/rfc6455.html)

## 11. Acknowledgments

SLOP is MIT-licensed and maintained by the community. Contributions welcome at [GitHub](https://github.com/agnt-gg/slop).

